\section{Evaluation}
We ran our algorithm on tests validating our ability to handle regular
expression equivalences, tests derived from the Augeus test suite, and from
tests derived from the FlashFill tests.
The values presented are the arithmetic means of 10 test runs.
The tests were run on a 2.5 GHz Intel Core i7 processor, with
16 GB of 1600 MHz DDR3, running Mac OS X Yosemite.

\begin{figure*}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\bfseries Test & \bfseries ForceExpandTime & \bfseries ForceExpandExamplesRequired
& \bfseries Computation Time & \bfseries Examples Required
\csvreader[head to column names]{generated-data/data.csv}{}
{\\\hline\Test & \ForceExpandTime & \ForceExpandExamplesRequired & \ComputationTime & \ExamplesRequired}
\\\hline
\end{tabular}

\end{figure*}

% fig:runtimes-table
\begin{figure}
\centering
%\begin{tabular}{|l|c|}

\csvreader[tabular=|l|l|,
    table head=\hline\textbf{Test} & \textbf{Time (s)} \\\hline,
    late after line = \\\hline]
{generated-data/data.csv}{Test=\Test,ComputationTime=\ComputationTime}
{\Test{} & \ComputationTime{}}

%\hline\textbf{Test} & \textbf{Examples Required}
%\\\hline\hline
%\csvreader[head to column names]{generated-data/data.csv}{}
%{\Test& \ExamplesRequired\\\hline}
%\end{tabular}
\caption{Runtime Table\bcp{Hard to read, with all the zeros.  Maybe better
    to display as a (log-scale) graph?  More seriously, we'll need to
    explain the examples someplace, say why we chose them, maybe group them
    in some way, ...  Why ws this the right set of tests?}}
\label{fig:runtimes-table}
\end{figure}

\subsection{Speed}
Figure~\ref{fig:runtimes-table} provides the runtime of our algorithm on our
test suite.
In this figure, we want to minimize runtime, as a smaller runtime means we were
able to synthesize very efficiently.
We found that, on many of our difficult examples, our algorithm was able to find
the appropriate lens very quickly.

However, we can also see where the strengths and weaknesses are in our approach.
In particular, our synthesis strategy does quite well on problems that only
include a small number of transformations, even if the number of clauses is
decently large.
This is as expected, for after the appropriate transformations have been found,
the problem of finding the lens between the resulting DNF Regular Expressions
is merely as difficult as ordering the clauses.

For example, the address problem is the second slowest lens to synthesize.
This is because there is a large number of required expansions of user defined
data types, and there are multiple required star transformations.
Furthermore, there are a large number of potential star transformations because
of the large number of stars.
In addition to requiring a relatively deep search, this search is made much
more difficult because of the breadth of the search.
This shows us where our algorithm can hit issues.
When there are a large number of potential transformations, and there are a
large number of required transformations, our search gets more complicated,
and things slow down.

Another place where our synthesis algorithm preforms badly is where there is not
only a large number of clauses generated, but they also have a non-identity
lens between them.
For example, the double capitalization problem is another slowest test, despite
being an intuitively easy function to figure out, looking at it as a human.
This is because the algorithm problem has an exponential blow up in terms
of the number of clauses, when there are many regular expressions +d together.
If we take this problem to the logical extremes, we see that the the triple
capitalization problem takes 6.974 seconds, and the quadruple capitalization
problem takes 33 minutes and 54.730 seconds.

\subsection{Importance of Examples}
We wanted to see how many examples were required to synthesize the correct
bijective lens.
However, because of our implicit understanding of the algorithm, we fear we may
choose examples that we know will work well with the synthesis algorithm,
instead of choosing examples that users are likely to.
Because of that, we test the number of examples that it takes to generate the
correct lens, with randomly generated examples.

% fig:examples-required-table
\begin{figure}
\centering
%\begin{tabular}{|l|c|}

\csvreader[tabular=|l|l|,
    table head=\hline\textbf{Test} & \textbf{Example Count} \\\hline,
    late after line = \\\hline]%
{generated-data/data.csv}{Test=\Test,ExamplesRequired=\ExamplesRequired}%
{\Test{} & \ExamplesRequired{}}%

%\hline\textbf{Test} & \textbf{Examples Required}
%\\\hline\hline
%\csvreader[head to column names]{generated-data/data.csv}{}
%{\Test& \ExamplesRequired\\\hline}
%\end{tabular}
\caption{Examples Required Table\bcp{Is this table showing us that the
    examples we chose are mostly not very interesting?}}
\label{fig:examples-required-table}
\end{figure}

As we see in Figure~\ref{fig:examples-required-table}, examples are not too
important for synthesizing bijective lenses.\bcp{If that's really the
  conclusion, then maybe we should have written a paper about synthesizing
  bijective lenses {\em without} examples!  But I don't think we can
  actually conclude this from the examples we have.  }
Because bijective lenses have very few well typed programs, compared to the
number of functions, oftentimes just a few examples is sufficient.
As would be expected, the functions that have to make choices about the
locations of where data goes are those that require more examples.
In particular, the address problem requires more examples, because it must make
choices of where information goes, like which name is the a person's first name,
and which is their last.

% fig:expanded-time-table
\begin{figure}
\centering
%\begin{tabular}{|l|c|}

\csvreader[tabular=|l|l|,
    table head=\hline\textbf{Test} & \textbf{Time (s)} \\\hline,
    late after line = \\\hline]%
{generated-data/data.csv}{Test=\Test,ForceExpandTime=\ForceExpandTime}%
{\Test{} & \ForceExpandTime{}}%

%\hline\textbf{Test} & \textbf{Examples Required}
%\\\hline\hline
%\csvreader[head to column names]{generated-data/data.csv}{}
%{\Test& \ExamplesRequired\\\hline}
%\end{tabular}
\caption{Expanded Regexp Runtime Table}
\label{fig:expanded-time-table}
\end{figure}
\subsection{Importance of User Defined Data Types}

