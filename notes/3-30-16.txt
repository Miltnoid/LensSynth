Went over a bit of how the code works.
	Create a random permutation, use that permutation to determine
	  what subgoals need to be solved

Made some example problems and solved them as proof of concepts
	Can't handle huge problems, perhaps we can use some of Sumit's DAG
	  stuff?

Creating a random permutation and testing, what are some ways to speed it up?
	Maybe we can sort them, if we give a total order, then we just go
	  through it linearly and check if each matches up
		Maybe we order into buckets of things that are equal in order,
			Maybe order isn't correct, but rather merely a hash?
				We don't care as much about <=, more about
				  ability to map between them
	Can we use examples more?
		Huge potential for examples helping in unions.
		Concats are harder, use information about same substring being
		  on one side or another?
	Instead of O(2^n) try all permutations, instead see which subproblems
	  can go to which, and then use greedy algorithm to assign them.
		Is greedy algorithm sufficiently efficient?

We have a capacity to solve problems, but to what extent is this capacity
  useful?
	Go through boomerang and steal some of their examples.
	Gives us a understanding of where we are, and what needs to be solved

Some possible future directions
	Use of existing lenses for synthesis of new ones?  Libraries?
	Partially specified regex
		Generalization of both regex given, and only 1 regex given
		  problems
	Stinks to have to give full strings for some problems, perhaps give
	  some sort of way to say *random stuff*(portion of string i want to
	  specify)*random stuff*, so they only have to specify some of it.

TODOs for next week
	Figure out how to try fewer permutations
		Try ordering, matching and greedy, using examples
	Go through boomerang and see which benchmarks can be lifted out
	Look through Sumit's papers, and look to see what can be used
		FlashFill has the DAG stuff, read through that super carefully
