\documentclass[12pt]{article}

\newif\ifdraft\drafttrue  % set true to show comments
% \newif\ifdraft\draftfalse  % set true to show comments
\newif\ifanon\anonfalse    % set true to suppress names, etc.
\newif\ifappendices\appendicesfalse

%\PassOptionsToPackage{usenames,dvipsnames,svgnames,table}{xcolor}

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{amsmath}
\usepackage[capitalise]{cleveref}
\usepackage{makecell}%To keep spacing of text in tables
\usepackage{nccmath}
\usepackage{mathtools}
\usepackage{bussproofs}
\usepackage{varwidth}
\usepackage{amsthm}
\usepackage{csvsimple}
\usepackage{thmtools,thm-restate}
\usepackage{changepage}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multirow,bigdelim}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage{listings}
\usepackage{letltxmacro}
\usepackage{sansmath}
\usepackage{url}
\usepackage{flushend}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage{mathpartir}
\usepackage{empheq}
\usepackage{array}
\usepackage{pgfplots}
\usepackage{stmaryrd}
\usepackage{courier}
\usepackage{qtree}
\usepackage[normalem]{ulem}
\usepackage{relsize}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{tabularx}
\usepackage{stackengine}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{remreset}
\usepackage{tabulary}
\usepackage{xspace}
\usepackage{bbm}

\newtheorem*{theorem*}{Theorem}
\newenvironment{centermath}
 {\begin{center}$\displaystyle}
 {$\end{center}}
\setcellgapes{4pt}%parameter for the spacing

\lstset{ language=Caml, basicstyle=\upshape\sffamily,
keywordstyle=\upshape\sffamily\color{dkpurple}, keepspaces=true,
framexleftmargin=1ex, framexrightmargin=1ex, showstringspaces=true,
commentstyle=\itshape\rmfamily,
emph={rep,iterate,synth,collapse,perm,squash,normalize,using,ins,del,lens,let,get,put,rquot,lquot,id,swap,concat,or,disconnect,merge_left,merge_right,const},
emphstyle=\upshape\sffamily\color{dkpurple}, 
columns=fullflexible,
mathescape, 
xleftmargin=1.5em,
% BCP: I find this distracting:
stringstyle=\sffamily\color{dkblue},
}
\makeatletter
     \let\lst@oldvisiblespace\lst@visiblespace
     \def\lst@visiblespace{\,\lst@oldvisiblespace\,}
\makeatother

\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

\usetikzlibrary{
  er,
  matrix,
  shapes,
  arrows,
  positioning,
  fit,
  calc,
  pgfplots.groupplots,
  arrows.meta
}
\tikzset{>={Latex}}

%%%% Hyperlinks â€“ must come late!
%\usepackage[pdftex,%
%            pdfpagelabels,%
%            linkcolor=blue,%
%            citecolor=blue,%
%            filecolor=blue,%
%            urlcolor=blue]
%           {hyperref}

\input{macros}

\begin{document}

\pagestyle{empty}

\begin{center}

  \large \textbf{Synthesizing Data Wranglers\\\vspace{1cm} FA8750-17-2-0028}

  \vspace{1in}

  \normalsize
  %\begin{tabular}{rl}
  Kathleen Fisher (Tufts University) \\
  Benjamin Pierce  (University of Pennsylvania) \\
  David Walker (Princeton University) \\
  Steve Zdancewic (University of Pennsylvania)
 %\end{tabular}
  \vspace{1in}

  Final Report

\end{center}

\newpage
\pagestyle{plain}

\renewcommand{\thepage}{\roman{page}}% Roman numerals for page count
\setcounter{page}{1}% Start page number with 2

\tableofcontents
\newpage

\listoffigures
\newpage

\renewcommand{\thepage}{\arabic{page}}% Arabic numerals for page counter
\setcounter{page}{1}% Start page number with 2

\section{Summary}



\section{Introduction}

Building information-processing systems and maintaining them over a long
period of time is a tedious, labor-intensive process.  One key challenge is
that such systems must often interact with a large number of
\emph{ad hoc data sources}---partially structured data sources represented
in non-standard formats.  Ad hoc data sources include various
different kinds of system log files as well as scientific data sources
generated by experiments.  These ad hoc data sources are often
produced by other automated systems, and each requires custom tools.
Over time, the data sources tend to evolve---fields are added,
removed, or co-opted, variants are added, etc.  Today, to manage these
changes, engineers must manually re-code parsers and/or insert
adaptors while maintaining the desired semantics.  Such manual work is
not only time-consuming, but exceedingly error-prone.  Moreover,
errors in environment-facing interfaces can not only lead to
corruption of important data, but also to significant security
vulnerabilities.  In order to design and implement survivable,
long-lived, complex software systems that are robust to changes 
in their operational environment---the vision of
DARPA's BRASS program---it is necessary to develop new, easier-to-use
and more robust programming systems for managing these ad hoc data
sources as they evolve.

To help alleviate this problem, we studied algorithms 
for automatically synthesizing adaptors between related data
sources, given (i) the \emph{type} of each
source, as well as (ii) a small collection of
representative \emph{examples} of the desired translation.  The
adaptors we synthesize are \emph{bidirectional}, meaning
that we synthesize transformations that may be applied both
backwards and forwards (from source A to B as well as B back to A).
Such bidirectional transformations may help faciliate evolution and
maintainence of long-lived systems by making it possible to upgrade
one component of a (possibly distributed) system, while it continues
to interact correctly with other components and with its environment.
The bidirectional transformations will be guaranteed to preserve
strong invertability laws, thereby reducing the likelihood of
inadvertant data corruption.  In addition, parsing components
will be synthesized by a compiler rather than being manually coded,
thereby reducing the likelihood of the buffer overruns that lead to
many security vulnerabilities.

The core result of our research is a new algorithm for
the synthesis of \emph{bijective string lenses}.  Bijective string lenses (\emph{i.e.,}
bidirectional transformations) define a limited set of
transformations between strings.  The domain and range of such
transformations are determined by regular expressions ({\emph{i.e.,}
  regular expressions serve as the types of these transformations).
 In addition, as their name suggests, these transformations are
 \emph{bijections}.
 In other words, the information content of source A is preserved (though usually
rearranged) when data is translated to target B, and vice versa when B
is translated back to A.  Such transformations can rearrange fields of
a record or insert new kinds of syntactic separators (\emph{e.g.,} replacing a
comma with a vertical bar, or the name of one HTML tag with another)
but they cannot implement more general transformations that elide
irrelevant details, such as the amount of whitespace that separates
two tokens.

Despite their limitations, bijections and bijective synthesis form a
useful foundation on top which more general transformations between
data sets may be built.  Hence, in the second half of our of project,
we extended the regular expression-based specifications of data types
with \emph{isomorphisms} between strings, also known as
\emph{quotients}.  To synthesize transformations between sets of
strings modulo isomorphisms, we generate canonizing functions followed
by bijections (using the original bijective synthesis algorithm).  The
so-called \emph{quotient lenses}~\cite{Foster:quotient-lenses}we generate are capable of handling
``irrelevant'' differences between structures such as white space or
permutations of items in a row of data set and hence expand the set of
transformations our system can define significantly.  Finally, we explored the
synthesis of \emph{symmetric lenses}~\cite{hofmann+:lenses} , again building upon the
bijective platform that we started with.  Symmetric lenses are able to
ignore arbitrary chunks of data in A when generating target data B,
and vice-versa.  For example, a serial number specific to one data set
may be ignored when we translate to a second.  Symmetric lenses
further expand the set of allowed transformations.

We measured the effectiveness of our algorithms on a set of
benchmarks drawn from the Augeas system~\cite{augeas}---a system for
transforming and editing Linux configuration files.  Past synthesis
tools, such as FlashFill~\cite{flashfill} were unable to translate
most Augeas file formats.  However, our synthesis toolkit was able to
transform all 40 of the Augeas file formats that we analyzed.

We have written three academic papers~\cite{?}
describing and evaluating our algorithms and produced open-source our code.

\section{Methods, Assumptions, and Procedures}

\section{Results and Discussion}

Reffing a \Cref{fig:eg}.

\begin{figure}
  a picture is here
  \caption{An example figure}
  \label{fig:eg}
\end{figure}

\section{Conclusions}

During the course of this project, we have designed, analyzed and implemented algorithms that demonstrate it is possible to synthesize three classes of bidirectional transformations:  (1) pure bijective transformations, (2) bijections modulo equivalences classes and (3) bijections modulo projections.  The synthesis algorithms we have designed take inputs that include a format specification (which includes specification of equivalence classes) and a collection of examples.  As the class of transformations becomes richer, the number of potential programs grows dramatically.  As a result, the corresponding inference algorithm slows and its ability to guess the transformation desired by the user decreases, leading to reduced accuracy.  We found that it was possible to overcome such challenges through new heuristics that use information theory to help guide the search for program transformations.  In addition, we found the use of compositional synthesis, which is the process of breaking down a complex synthesis task into smaller, more mangeable subtasks critical when attempting to scale our prototype system up to be able to handle larger transformation task.

\bibliographystyle{apalike}
\bibliography{local.bib,bcp.bib}

\section{List of Symbols, Abbreviations, and Acronyms}
\begin{tabular}{ll}
  DARPA & Defense Advanced Research Project Agency \\
\end{tabular}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
