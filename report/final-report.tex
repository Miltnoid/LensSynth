\documentclass[12pt]{article}

\newif\ifdraft\drafttrue  % set true to show comments
% \newif\ifdraft\draftfalse  % set true to show comments
\newif\ifanon\anonfalse    % set true to suppress names, etc.
\newif\ifappendices\appendicesfalse

%\PassOptionsToPackage{usenames,dvipsnames,svgnames,table}{xcolor}

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{amsmath}
\usepackage[capitalise]{cleveref}
\usepackage{makecell}%To keep spacing of text in tables
\usepackage{nccmath}
\usepackage{mathtools}
\usepackage{bussproofs}
\usepackage{varwidth}
\usepackage{amsthm}
\usepackage{csvsimple}
\usepackage{thmtools,thm-restate}
\usepackage{changepage}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multirow,bigdelim}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage{listings}
\usepackage{letltxmacro}
\usepackage{sansmath}
\usepackage{url}
\usepackage{flushend}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage{mathpartir}
\usepackage{empheq}
\usepackage{array}
\usepackage{pgfplots}
\usepackage{stmaryrd}
\usepackage{courier}
\usepackage{qtree}
\usepackage[normalem]{ulem}
\usepackage{relsize}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{tabularx}
\usepackage{stackengine}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{remreset}
\usepackage{tabulary}
\usepackage{xspace}
\usepackage{bbm}
\usepackage{fullpage}
\usepackage[explicit]{titlesec}

% \renewcommand*\thesection{\arabic{section}.0}
% \renewcommand*\thesubsection{\arabic{section}.\arabic{subsection}}


\newtheorem*{theorem*}{Theorem}
\newenvironment{centermath}
 {\begin{center}$\displaystyle}
 {$\end{center}}
\setcellgapes{4pt}%parameter for the spacing

\lstset{ language=Caml, basicstyle=\upshape\sffamily,
keywordstyle=\upshape\sffamily\color{dkpurple}, keepspaces=true,
framexleftmargin=1ex, framexrightmargin=1ex, showstringspaces=true,
commentstyle=\itshape\rmfamily,
emph={rep,iterate,synth,collapse,perm,squash,normalize,using,ins,del,lens,let,get,put,rquot,lquot,id,swap,concat,or,disconnect,merge_left,merge_right,const},
emphstyle=\upshape\sffamily\color{dkpurple}, 
columns=fullflexible,
mathescape, 
xleftmargin=1.5em,
% BCP: I find this distracting:
stringstyle=\sffamily\color{dkblue},
}
\makeatletter
     \let\lst@oldvisiblespace\lst@visiblespace
     \def\lst@visiblespace{\,\lst@oldvisiblespace\,}
\makeatother

\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

\usetikzlibrary{
  er,
  matrix,
  shapes,
  arrows,
  positioning,
  fit,
  calc,
  pgfplots.groupplots,
  arrows.meta
}
\tikzset{>={Latex}}

%%%% Hyperlinks â€“ must come late!
%\usepackage[pdftex,%
%            pdfpagelabels,%
%            linkcolor=blue,%
%            citecolor=blue,%
%            filecolor=blue,%
%            urlcolor=blue]
%           {hyperref}

\input{macros}

\begin{document}

\pagestyle{empty}

\begin{center}

  \large \textbf{Synthesizing Data Wranglers\\\vspace{1cm} FA8750-17-2-0028}

  \vspace{1in}

  \normalsize
  %\begin{tabular}{rl}
  Kathleen Fisher (Tufts University) \\
  Benjamin Pierce  (University of Pennsylvania) \\
  David Walker (Princeton University) \\
  Steve Zdancewic (University of Pennsylvania)
 %\end{tabular}
  \vspace{1in}

  Final Report

\end{center}

\newpage
\pagestyle{plain}

\renewcommand{\thepage}{\roman{page}}% Roman numerals for page count
\setcounter{page}{1}% Start page number with 2

\tableofcontents
\newpage

\listoffigures
\newpage

\renewcommand{\thepage}{\arabic{page}}% Arabic numerals for page counter
\setcounter{page}{1}% Start page number with 2

\section{SUMMARY}



\section{INTRODUCTION}

Building information-processing systems and maintaining them over a long
period of time is a tedious, labor-intensive process.  One key challenge is
that such systems must often interact with a large number of
\emph{ad hoc data sources}---partially structured data sources represented
in non-standard formats.  Ad hoc data sources include various
different kinds of system log files as well as scientific data sources
generated by experiments.  These ad hoc data sources are often
produced by other automated systems, and each requires custom tools.
Over time, the data sources tend to evolve---fields are added,
removed, or co-opted, variants are added, etc.  Today, to manage these
changes, engineers must manually re-code parsers and/or insert
adaptors while maintaining the desired semantics.  Such manual work is
not only time-consuming, but exceedingly error-prone.  Moreover,
errors in environment-facing interfaces can not only lead to
corruption of important data, but also to significant security
vulnerabilities.  In order to design and implement survivable,
long-lived, complex software systems that are robust to changes 
in their operational environment---the vision of
DARPA's BRASS program---it is necessary to develop new, easier-to-use
and more robust programming systems for managing these ad hoc data
sources as they evolve.

To help alleviate this problem, we studied algorithms 
for automatically synthesizing adaptors between related data
sources, given (i) the \emph{type} of each
source, as well as (ii) a small collection of
representative \emph{examples} of the desired translation.  The
adaptors we synthesize are \emph{bidirectional}, meaning
that we synthesize transformations that may be applied both
backwards and forwards (from source A to B as well as B back to A).
Such bidirectional transformations may help faciliate evolution and
maintainence of long-lived systems by making it possible to upgrade
one component of a (possibly distributed) system, while it continues
to interact correctly with other components and with its environment.
The bidirectional transformations will be guaranteed to preserve
strong invertability laws, thereby reducing the likelihood of
inadvertant data corruption.  In addition, parsing components
will be synthesized by a compiler rather than being manually coded,
thereby reducing the likelihood of the buffer overruns that lead to
many security vulnerabilities.

The core result of our research is a new algorithm for
the synthesis of \emph{bijective string lenses}.  Bijective string lenses (\emph{i.e.,}
bidirectional transformations) define a limited set of
transformations between strings.  The domain and range of such
transformations are determined by regular expressions ({\emph{i.e.,}
  regular expressions serve as the types of these transformations).
 In addition, as their name suggests, these transformations are
 \emph{bijections}.
 In other words, the information content of source A is preserved (though usually
rearranged) when data is translated to target B, and vice versa when B
is translated back to A.  Such transformations can rearrange fields of
a record or insert new kinds of syntactic separators (\emph{e.g.,} replacing a
comma with a vertical bar, or the name of one HTML tag with another)
but they cannot implement more general transformations that elide
irrelevant details, such as the amount of whitespace that separates
two tokens.

Despite their limitations, bijections and bijective synthesis form a
useful foundation on top which more general transformations between
data sets may be built.  Hence, in the second half of our of project,
we extended the regular expression-based specifications of data types
with \emph{isomorphisms} between strings, also known as
\emph{quotients}.  To synthesize transformations between sets of
strings modulo isomorphisms, we generate canonizing functions followed
by bijections (using the original bijective synthesis algorithm).  The
so-called \emph{quotient lenses}~\cite{Foster:quotient-lenses}we generate are capable of handling
``irrelevant'' differences between structures such as white space or
permutations of items in a row of data set and hence expand the set of
transformations our system can define significantly.  Finally, we explored the
synthesis of \emph{symmetric lenses}~\cite{hofmann+:lenses} , again building upon the
bijective platform that we started with.  Symmetric lenses are able to
ignore arbitrary chunks of data in A when generating target data B,
and vice-versa.  For example, a serial number specific to one data set
may be ignored when we translate to a second.  Symmetric lenses
further expand the set of allowed transformations.

We measured the effectiveness of our algorithms on a set of
benchmarks drawn from the Augeas system~\cite{augeas}---a system for
transforming and editing Linux configuration files.  Past synthesis
tools, such as FlashFill~\cite{flashfill} were unable to translate
most Augeas file formats.  However, our synthesis toolkit was able to
transform all 40 of the Augeas file formats that we analyzed.

We have written three academic papers~\cite{?}
describing and evaluating our algorithms and produced open-source our code that
implements those algorithms.

\section{METHODS, ASSUMPTIONS, AND PROCEDURES}

Our approach combines two strategies.  We use \textit{domain-specific programming
  language}, specifically, the Boomerang~\cite{boomerang, Matching10} language,
which is designed for writing bidirectional string transformations.  We also exploit
\textit{type- and example-directed program synthesis}, which uses enumerative
techniques to search a space of candidate solutions.  The search is constrained
by the type information about the program, as well as by example instances
provided by the user.

\subsection{Lenses and lens domain-specific programming languages}

A lens comprises two functions,
\emph{get} and \emph{put}.  The \emph{get} function translates
source data into the target format.  If the target data is updated, the
\emph{put} function translates this edited data back into the
source format.  
A benefit of lens-based languages is that they use a single term
to express both 
\emph{get} and \emph{put}.
Furthermore, well-typed lenses give rise to 
\emph{get} and \emph{put} functions 
guaranteed to satisfy desirable invertibility properties.

Lens-based languages are present in variety of tools and have found mainstream
industrial use.
Boomerang~\cite{boomerang, Matching10} lenses provide
guarantees on transformations between {\em ad hoc} string document formats.
Augeas~\cite{augeas}, a popular tool that reads Linux system configuration
files, uses the \emph{get} part of a lens to transform configuration
files into a canonical tree representation that users can edit
either manually or 
programmatically.  It uses the lens's \emph{put} to merge the edited
results back into the original string format.  Other lens-based languages and
tools include 
%
GRoundTram~\cite{Hidaka2011GRoundTramAI},
%
BiFluX~\cite{DBLP:conf/ppdp/PachecoZH14}, 
%
BiYacc~\cite{DBLP:conf/staf/ZhuK0SH15},
%
Brul~\cite{DBLP:conf/etaps/ZanLKH16},
%
BiGUL \cite{DBLP:conf/pepm/KoZH16}, 
%
bidirectional variants of 
relational algebra~\cite{BohannonPierceVaughan},
spreadsheet formulas~\cite{DBLP:conf/vl/MacedoPSC14},
graph query languages~\cite{DBLP:conf/icfp/HidakaHIKMN10},
and
XML transformation languages~\cite{DBLP:conf/pepm/LiuHT07}.


\subsection{Bijective lens synthesis}

As inputs, our bijective synthesis procedure takes regular expressions specifying the
source, $S$, and
target, $T$, formats, plus a collection of concrete examples of the desired 
transformation.  Format specifications are supplied as ordinary regular
expressions.
Because regular expressions are so widely understood, we anticipate such
inputs will be substantially easier for everyday programmers to work with
than the unfamiliar syntax of lenses.
Moreover, these format descriptions communicate a
great deal of information to the synthesis system.  Thus, requiring user input
of regular expressions makes synthesis robust, 
helps the system scale to large and complex data sources, and 
constrains the search space sufficiently that the user typically needs
to give very few, if any, examples.

The goal of the synthesis algorithm is to find a lens
$\ell : S \Leftrightarrow T$ that corresponds to a bijection from the language
of a source regular expression $S$ to a target language of a target regular
expression $T$.   Such a lens should satisfy the \textit{bijective lens laws}:

\begin{equation}\label{bijectivelenslaws} \ell.\get \;
  (\ell.\lput \; t) = t \text{, and } \ell.\lput \; (\ell.\get \; s) = s
\end{equation}

\begin{figure}
  \centering
  \small 
  \begin{tikzpicture}[auto,node distance=1.5cm]
    \node[text width=1.5cm,minimum height=.6cm,align=center,draw,rectangle] (todnfregex) {\ToDNFRegex{}};
    
    \node[align=right, anchor=east] (regex1) [left = .6cm of todnfregex.north west]{\Regex{}};
    \node[align=right, anchor=east] (regex2) [left = .6cm of todnfregex.south west]{\RegexAlt{}};
    \node[align=right, anchor=east] (exs) [below = .2cm of regex2]{ \Examples{} };
    
    \node[align=center] (dnfregex1) [right = .4cm of todnfregex.north east]{\DNFRegex{}};
    \node[align=center] (dnfregex2) [right = .4cm of todnfregex.south east]{\DNFRegexAlt{}};

    \node[text width=2.3cm,minimum height=.6cm,align=center,draw,rectangle] [right = 1.45cm of todnfregex.east] (synthdnflens) {\SynthDNFLens{}};
    \node[align=center] [above = .7cm of synthdnflens] (optician) {\Optician{}};
    
    \node[align=center] [right = .4cm of synthdnflens] (dnflens) {\DNFLens{}};
    
    \node[text width=1.5cm,minimum height=.6cm,align=center,draw,rectangle] [right = .4cm of dnflens] (tolens) {\ToLens{}};
    
    \node[align=center] [right = .6cm of tolens] (lens) {\Lens{}};
    
    
    \path[->] (regex1.east) edge (todnfregex.north west);
    \path[->] (regex2.east) edge (todnfregex.south west);
    
    \path[->] (todnfregex.north east) edge (dnfregex1.west);
    \path[->] (todnfregex.south east) edge (dnfregex2.west);
    
    \path[->] (dnfregex1.east) edge (synthdnflens.north west);
    \path[->] (dnfregex2.east) edge (synthdnflens.south west);
    
    \path[->] (synthdnflens) edge (dnflens);
    
    \path[->] (dnflens) edge (tolens);
    
    \path[->] (tolens) edge (lens);
    \draw[->] ($(exs.east)+(-3pt,0)$) -| node(exsedge) {} (synthdnflens);
    \node[fit={($(todnfregex.west)+(-4pt,0)$) ($(tolens.east)+(4pt,0)$) (exsedge) (dnfregex1) (optician) (dnfregex2)},draw] (surrounding) {};
    % Now place a relation (ID=rel1)
    %\node[text width=2cm,align=center,draw, rectangle] (sketch-gen) [right = .75cm of spec] {\TypeProp{}};
    %\node (below-gen) [below=.5cm of sketch-gen] {};
    %\node[text width=2cm,align=center,draw, rectangle] (sketch-compl)
    %     [right = .25cm of sketch-gen] {\RigidSynth{}};
    %\node (below-compl) [below=.5cm of sketch-compl] {};
    %\node[align=center] (lens) [right = .75cm of sketch-compl] {Lens}; 
    %% Draw an edge between rel1 and node1; rel1 and node2
    %\path[->] (spec) edge node (start-alg) {} (sketch-gen);
    %\path[->] (sketch-gen) edge node(middle) {} (sketch-compl);
    %\path[->] (sketch-compl) edge node[near start](success) {\Success{}} (lens);
    %\draw[<-] (sketch-gen.south) -- +(0,-.5) -| node[above left](failure){\Failure{}} (sketch-compl.south);

    %\node (synth-name) [above=.5cm of middle] {\Optician{}};
    %
    %\node[fit=(sketch-gen) (sketch-compl) (start-alg) (synth-name) (failure)
    %(success) ,draw] (surrounding) {};

  \end{tikzpicture}
  \caption{Schematic Diagram for \Optician{}.  Regular expressions, \Regex{} and
    \RegexAlt{}, and examples, \Examples{}, are given as input.
    First, the function \ToDNFRegex{} converts \Regex{} and \RegexAlt{} into
    their respective DNF forms, \DNFRegex{} and \DNFRegexAlt{}.
    Next, \SynthDNFLens{} synthesizes a DNF lens, \DNFLens{}, from \Regex{},
    \RegexAlt{}, and \Examples{}.
    Finally, \ToLens{} converts \DNFLens{} into \Lens{}, a lens in Boomerang
    that is equivalent to \DNFLens{}.}
  \label{fig:schematic-diagram-synthesis}
\end{figure}

Figure~\Cref{fig:schematic-diagram-synthesis} shows a high-level,
schematic diagram for \Optician{}.
First, \Optician{} uses the function \ToDNFRegex{} to convert the input
regular expressions into DNF regular expressions.  Next,
\SynthDNFLens{} performs type-directed synthesis on these DNF regular
expressions and the input examples to synthesize a DNF lens.  Finally, this DNF lens is
converted back into a regular lens with the function \ToLens{}, and returned to the user.


\subsection{Quotient lens synthesis}

Quotient lenses are lenses in which the lens laws are
loosened so that they hold modulo an equivalence relation on the source and
target data respectively; as above, we are concerned with {\em bijective
quotient lenses} which are lenses for which Equation \ref{bijectivelenslaws}
holds modulo equivalence relations $\equiv_S$ and $\equiv_T$ defined on the source
and target data respectively:

\begin{equation}\label{quotientlenslaws}
\ell.\get \; (\ell.\lput \; t) \equiv_T t \text{, and } \ell.\lput \; (\ell.\get
\; s) \equiv_S s
\end{equation}

The inputs to the quotient lens synthesis problem, as in the bijective case,
include source and target regular expressions $S$ and $T$ and a set of example
instances.  The equivalence relations $\equiv_S$ and $\equiv_T$ are also given
as inputs to the synthesis algorithm.  As we describe below, one result of our
work is a language of \textit{quotient regular expressions} that concisely
specifies $S$ and $\equiv_S$ simultaneously.

\section{RESULTS AND DISCUSSION}

Reffing a \Cref{fig:eg}.

\begin{figure}
  a picture is here
  \caption{An example figure}
  \label{fig:eg}
\end{figure}

\section{CONCLUSIONS}

During the course of this project, we have designed, analyzed and implemented algorithms that demonstrate it is possible to synthesize three classes of bidirectional transformations:  (1) pure bijective transformations, (2) bijections modulo equivalences classes and (3) bijections modulo projections.  The synthesis algorithms we have designed take inputs that include a format specification (which includes specification of equivalence classes) and a collection of examples.  As the class of transformations becomes richer, the number of potential programs grows dramatically.  As a result, the corresponding inference algorithm slows and its ability to guess the transformation desired by the user decreases, leading to reduced accuracy.  We found that it was possible to overcome such challenges through new heuristics that use information theory to help guide the search for program transformations.  In addition, we found the use of compositional synthesis, which is the process of breaking down a complex synthesis task into smaller, more mangeable subtasks critical when attempting to scale our prototype system up to be able to handle larger transformation task.

\bibliographystyle{apalike}
\bibliography{local.bib,bcp.bib}

\section{List of Symbols, Abbreviations, and Acronyms}
\begin{tabular}{ll}
  DARPA & Defense Advanced Research Project Agency \\
\end{tabular}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
