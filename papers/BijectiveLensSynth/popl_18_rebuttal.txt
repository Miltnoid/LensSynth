Thank you for your comments!

We begin with brief responses to the most significant concerns, followed by
a (long and very optional) appendix addressing all questions in detail.

                                -------------

     - What is the difference in expressiveness between our work and
        existing algorithms like FlashFill?

Formally, they are incomparable: each can synthesize some transformations
that the other cannot.

Since we restrict ourselves to bijections, we are unable to express functions
that
don't preserve data, such as
  - mapping from a format with whitespace to one without whitespace,
  - turning a mix of uppercase and lowercase characters into purely
    uppercase characters, and
  - extracting a file name from a file path.
FlashFill can express all these.

Conversely, our "Optician" algorithm can solve some classes of problems that
existing synthesis systems cannot.  In particular, techniques that only use
input-output examples are unable to synthesize programs with nested loops.
We note that FlashFill's DSL does permit nested
loops, but for efficiency reasons the algorithm only synthesizes
programs with no nesting (this is discussed at the end of section 4.4 of
"Automating String Processing in Spreadsheets Using Input-Output
Examples", POPL '11).  

While a single nesting of loops seems to be sufficient for FlashFill's intended 
uses, our benchmark suite (based on
real-world uses of the Augeas tool) includes many more complex formats and
transformations.  In particular, these formats tend to have deep layers of
iterated data, with complex transformations at each layer, requiring the
synthesis of many layers of nested loops.  FlashFill cannot handle such
examples.  Our experiments demonstrate this fact by showing that FlashFill
only succeeds on 3 out of our 39 benchmarks, whereas our system succeeds on
all our benchmarks.


     - What modifications did we need to make to examples in the Augeas and
       FlashFill benchmark suite to make them bijective?

We changed some formats in our benchmark suite to handle two forms of non-bijectivity:
1) Whitespace present in one format but not the other.
2) Useful information projected away when going from one format to the other.

Category 1 was by far the most common, applying to many of the Augeas
examples.  To handle it, we added additional whitespace to the other format,
where typically whitespace is unnecessary.

Category 2 was less prevalent, but occurred, typically in the FlashFill
examples.  To address this category, we added the projected information to the end
of the format missing the information.


     - The restriction to bijective lenses is not fully justified

There are many formats kept in bijective correspondence with each other, like
those present at https://www.data.gov/ .

There are lens theories developed to handle synchronization tasks for data
formats not kept in bijective correspondence (quotient lenses to handle Category
1 non-bijectivity, and symmetric lenses to handle Category 2 non-bijectivity).
These theories have a bijective core, surrounded by either canonizers (for
quotient lenses) or projections (for symmetric lenses).  We believe that our
system can be used as a drop-in component for synthesis algorithms on these more
complex lens structures.

Reviewer 1 asked us directly about the potential for future work.
Along those lines, we have already implemented a system that
synthesizes quotient lenses from regular expressions augmented with equivalence
relations that solve the whitespace bijection problem.  This system
uses the algorithm provided in this paper as a drop-in component without change.
We conjecture the system could be augmented in a similar way with projections as
well.  We are not suggesting adding more results of this form to the current paper
because it is already very dense.  


     - After having written the regular expressions, is it very difficult
       for users to then write the lens?  Are we saving anybody any
       significant effort?

Engineering best practices dictate that we annotate the lenses with their
types.  While Boomerang does not need these annotations - being able to
infer the types from the terms - the types of the term serve as
documentation for future programmers to understand what formats the lens
maps between.  Furthermore, the types provide resilience in the face of future
lens modifications, as they validate that the lens maps exactly
between strings of the provided formats. Invalid inputs are not accepted
nor are the outputs ever invalid.  In this way, we are not requiring
additional work; we are saving programmers from the difficulties of 
writing the lens by leveraging the work they should already be performing.

A few more reasons why programming with regular expressions is easier
than programming with lenses:

* Regular expressions are widely understood.  Few programmers know about
  programming with lenses.

* A regular expression describes one data format, while lenses deal with two
  at the same time.

* In the (common) case where the two formats have kleene stars in different
  places, manual lens programming requires mentally transforming both to a
  common "aligned" form.  Our synthesis algorithm does this alignment
  automatically.


===========================================================================
===========================================================================
Detailed responses to individual questions in the reviews follow...


===========================================================================
Review #18A

                                -------------

     - Restriction of focus to bijective "lenses" not clearly justified

See general responses.

                                -------------

     - Important parts of algorithm not explained (regarding how examples are
       used)

We omitted the formal description of these orderings for space.  A full
description of the algorithm is present in algorithm 4 in the appendix (see the
supplemental pdf submitted with the paper) on page 119, with the orderings
defined in Definition 33 on page 118 (the definitions of related structures
begin at page 115).  We embed the parse trees of the examples into the DNF
regular expressions, and make an ordering on the DNF regular expression with
embedded parse trees.  We would be happy to rewrite the paper to include
whatever information the reviewer believes is most important.

                                -------------

     - Not clear how much work it is to adapt examples to be suitable for
       bijective lens synthesis, or how useful the results are w.r.t. the
       original task

See general responses.

                                -------------

     - But the main part of the paper is not self-contained - for example the
       algorithm description relies on (example-dependent) orderings of
       sequences and atoms that are not described; this is a key part of the
       algorithm since it is where the provided examples are actually used.

See above.

                                -------------

     - I also have a concern: since the approach is
       limited to bijective lenses, but many of the test examples were not
       bijective, how much work was it to modify the examples
       and how easy is it to manually hack the resulting bijective
       lenses to make them work on the real data?  Is there any chance of
       automating this or generalizing to handle non-bijective lenses
       (perhaps with this algorithm as a subroutine)?

See general responses.

For Category 1 non-bijectivity, instead of changing the formats, we could have
placed canonizers on the edges of formats with large amounts of whitespace.
Canonizers can normalize an arbitrarily long sequence of whitespace to a single
space.  Canonizers also can be used to handle casing issues: normalizing a
sequence of uppercase and lowercase characters into purely uppercase characters.
In this manner, whitespace (or casing) information can be normalized before
synthesis, and no longer would need to be propagated to the target format. We
have recently developed a framework to annotate a regular expression with
canonizing information, allowing for a single term to represent an arbitrary
sequence of whitespace and a means to normalize it to a single space.  Using
this framework, we easily can generate non-bijective lenses using our framework,
as long as the canonized forms of their source and target types are in bijective
correspondence.

For Category 2 non-bijectivity, we could compose the generated lens (that has
projected information at the end) with one that deletes that information at the
tail of the file, when going left to right, and restores that information when
going back. This wrapper is not difficult to write, and we think that
discovering this projection automatically is possible, but we have not yet done
it.

                                -------------

     - I could see future work building on this to handle the non-bijective
       case being a separate (and also interesting) paper.  But I would want
       the algorithm to be described more clearly and more caveats about the
       examples.

We agree the non-bijective case would also be an interesting paper.  We can
provide additional caveats about the examples and a better description of the
algorithm in the final version of this paper.

                                -------------

     - p12 fig 6. I'm not sure how ule "DNF structural rewrite" could be
       applied as the LHS uses the operators defined in fig. 5, rather than
       syntax

We merely wrote the rule with operators as a means to make the derivation more
readable.  One can evaluate those operators, and it will be an arbitrary
DNF regular expression, we just use the operators to show the relationship
between the atom involved in the structural rewrite, and what it is
rewritten to.

                                -------------

     - p17.  The desription of RigidSynth is incomplete.  It mentions orders
       $\leq_{Seq}$ and $\leq_{Atom}$ (and variants that use the examples) that
       do not appear to be defined.  What happens if there is ambiguity?  for
       example what if we are trying to infer a lens of type (a | b | c) <->
       (d|e|f) and we only have one example that says a <-> c?  If these
       orderings are standard things then please give a reference.  If not,
       they really need to be described in the paper.  The way examples are
       used to align parts of regular expressions seems really critical to
       this approach and is hardly explained.

First, we think the reviewer intended to write "we have only one example that
says a <-> d".  We see two cases for this scenario.
Case 1: The structure of the other two determines where they must map
Case 2: The structure does not determine where they must mapped

For Case 1, consider the scenario where
b = Name
c = Name*
e = Name*
f = Name
The structures of b, c, e, and f determine where they will be mapped: b <-> f
and c <-> e.  In particular, RigidSynth will order them as:
[a;b;c]
[d;f;e]
that then creates the maps previously provided.

For Case 2, consider the scenario where
b = Name
c = Name
e = Name
f = Name
In this case, the structures do not determine where they will be mapped.
The maps (a <-> d , b <-> e , c <-> f)
     and (a <-> d , b <-> f , c <-> e) are both valid.  In this situation, the
one we choose is based on a heuristic that minimizes swaps.  In particular,
Rigidsynth will order them as:
[a;b;c]
[d;e;f]
that creates the maps (a <-> d , b <-> e , c <-> f).

                                -------------

     - p18: AllSome (alg. 3): I assume this is the obvious function of type
       'a option list -> 'a list option (that is None if there is a None in
       the list or Some [a1..an] if the list is [Some a1...Some an]) but
       please clarify

This is correct.

                                -------------

     - p19: "easy to understand" - can you present any evidence for this?
       Easy for whom?

We feel that they are easy to understand because they look similar to how we
would handwrite the lenses, but we have not done any user studies to justify
that they are easy to understand.  Evidence to the fact that they are easier to
understand than non-pretty printed versions is given by the sizes of the
generated lenses.  Without minimization, the lenses sizes average at 424 AST
nodes, whereas minimization made the sizes average at 276 AST nodes.
In the general response, we show what a minimized vs handwritten lens look like.
Below we show the difference between a non-minimized title field and a minimized
title field for a work item.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (Id("")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.
Furthermore, when const(s,s) is present, it is converted into Id(s).

                                -------------

     - p20: "We adapted these examples" please say mor about how many of the
       examples needed to be adapted (all? a handful?) and how much work it
       was, and how useful the resulting isomorphic lenses were w.r.t the
       original data / how much additional work was needed to adapt them.

See above.

                                -------------

     - p20: "We developed a series of optimizations" - clarify that the
       algorithm already described includes all of these, and what you are
       going to do is disable them, rather than add more optimizations that
       weren't discussed earlier.  Might be helpful to signpost what parts of
       the algorithm are the "basic" algorithm and what parts are optional
       optimizations.

The algorithm described includes all but compositional synthesis, which uses
predefined lenses.  To use a predefined lens, l : A <-> B, the implementation
develops equivalence classes between user defined data types with lenses between
them (in the above example, A and B would be placed in the same equivalence
class).  Next, a representative element of each equivalence class is chosen.
All user defined data types are then transformed into their representative, and
the string examples are converted into examples in the language of the
representative.

                                -------------

     - p21: Fig 9 "Number of expansions" --> "Number of solutions"??

Number of expansions is the correct phrase.  Figure 9 shows how much random
search through expansions is required before RigidSynth terminates.  In
particular, this shows that full expansion inference performs significantly
better than the partial one that only performs the expansions it knows it must
perform.

                                -------------

     - p21.  Also interesting to evaluate would be how time / number of
       solutions varies (e.g. for the full algorithm) as the number of
       examples provided varies.  Is the number of examples small?

The number of examples provided doesn't typically have an impact on runspeed,
only correctness.  The number of valid solutions does vary with the number of
examples provided.  Typically, a small number of examples can greatly reduce the
number of possible solutions.  The number of examples is indeed small, as is
shown in Figure 11.

For example, there are an average of 2709 solutions with 0 randomly generated
examples, 2016 with 2 randomly generated examples, and 755 with 5 randomly
generated examples.  We are omitting the data from aug/bbhosts, whose number of
possible solutions (in the 10^17 range) overwhelmed all other data.

                                -------------

     - p24: "because our types do not have full canonical forms" - this is
       the case for the equations presented in the paper, but what about
       e.g. translating to automata and minimizing?

This is an interesting idea.  It is unclear how an automataton for a type
can be used to direct synthesis.  Nevertheless, this may lead to interesting
research.



===========================================================================
Review #18B

                                -------------

     - However, I’m not sure what exact advantage the proposed approach brings
       to the table. In particular, the user is still required to write exact
       input and output types of the transformations via regular expressions.
       How hard is to write lenses after one has such expressions? ...
       In the reviewer’s opinion, the specification mechanism is not very
       natural and it’s unclear whether it actually simplifies writing
       bijective transformations. This aspect is not evaluated and it would be
       nice to at least see the difference in sizes between the domain/range
       regexes vs the Boomerang lenses. In general, there is no report of the
       sizes of benchmarks.

See general response.  We provide an example program (and specification) below:

      typedef WSP = (" " | "\t" | "\n")+;;
      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au_synthesized_result
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

Even the relatively simple lens that permutes the 3 elements needed for
single_author_convert is fairly complex.  The complexity becomes even more
apparent when working with large lenses comprised of many sub-lenses (though
for brevity we give here the more minimal example above).  Lenses provide
great power with their invertibility guarantees, but they come at the cost
of thinking about many fiddly details when writing the terms.  Worrying
about these fiddly details while ALSO thinking about unambiguity
restrictions is a very difficult task!

We also provide data on the sizes below:

|-------------------------------------------------------------|
| Test                | SpecSize | LensAndTypeSize | LensSize |
|-------------------------------------------------------------|
| cust/date-probs     | 85       | 97              | 79       |
| cust/cap-prob       | 112      | 169             | 108      |
| cust/2-cap-prob     | 122      | 188             | 66       |
| ff/extr-fname-err   | 143      | 172             | 151      |
| ff/extr-fname       | 149      | 195             | 168      |
| ff/extr-quant       | 150      | 161             | 145      |
| ff/extr-num         | 171      | 186             | 166      |
| aug/activemq        | 194      | 204             | 184      |
| cust/bib-prob       | 202      | 265             | 181      |
| cust/workitem-probs | 221      | 330             | 252      |
| aug/xml-l1          | 235      | 301             | 214      |
| cust/addr-probs     | 244      | 308             | 239      |
| aug/aptcrngsec      | 265      | 336             | 204      |
| aug/alias           | 271      | 348             | 210      |
| aug/backuppchosts   | 272      | 318             | 249      |
| aug/approx          | 277      | 345             | 264      |
| aug/apt-upd-mgr     | 278      | 355             | 210      |
| aug/aptsources      | 278      | 351             | 238      |
| aug/cachefilesd     | 294      | 368             | 233      |
| aug/aptprefs        | 297      | 409             | 280      |
| aug/afs-cellalias   | 298      | 370             | 246      |
| aug/avahi           | 301      | 370             | 234      |
| aug/chrony          | 308      | 331             | 289      |
| aug/xml             | 311      | 546             | 383      |
| aug/carbon          | 325      | 507             | 377      |
| aug/access          | 335      | 436             | 253      |
| aug/anacron         | 342      | 447             | 315      |
| aug/hosts           | 343      | 449             | 328      |
| aug/bootconf        | 350      | 457             | 271      |
| aug/auth-keys       | 354      | 553             | 424      |
| aug/cgrules         | 378      | 487             | 295      |
| aug/cgconfig        | 415      | 612             | 347      |
| aug/automaster      | 475      | 621             | 377      |
| aug/cron            | 475      | 667             | 414      |
| aug/channels        | 512      | 682             | 367      |
| aug/automounter     | 535      | 710             | 432      |
| aug/aptconf         | 540      | 700             | 450      |
| aug/aptconf-l1      | 564      | 777             | 503      |
| aug/bbhosts         | 670      | 1041            | 651      |
|-------------------------------------------------------------|
| average             | 310      | 414             | 277      |
|-------------------------------------------------------------|

We can make sure we can provide at a description of the sizes of specs and
lenses in the final version of the paper.

                                -------------

     - Very limited DSL for transformations. The proposed DSL can only describe
       transformations that use identities and constant functions over input
       subparts. For example, one cannot synthesize the function toUpperCase,
       which I imagine could be useful for the kind of transformations
       appearing in the motivation.

We can convert between all uppercase and all lowercase.  Quotient lenses can be
used to normalize a format (or portions of a format) into fully uppercase or
fully lowercase data.  We believe quotient lenses have a bijective core, so our
synthesis engine for bijective lenses can be used as a plug-in component for
tasks (like to_upper) requiring quotient lenses.

                                -------------

     - Moreover, the functions can use each word in the input only once: one
       cannot express the transformation abc->abcabc. Most bijective functions I
       can think of (string encoders, compression algorithms, encryption
       algorithms) require complex transformations over the input that go
       beyond identities.

See general response.

                                -------------

     - On this note, there was a paper this year at PLDI on inverting string
       encoders (Automatic program inversion using symbolic transducers, by Hu
       et al.), a topic which seems very related, but for which I couldn’t find
       a citation.

Our DSL contains transformations that cannot be expressed by Extended Symbolic
Finite Transducers.  The finite lookahead does not allow for transformations
that swap data of indeterminite size, a common pattern and important pattern in
Boomerang lenses. We will add a citation to this work and a comment detailing
the restrictions of extended symbolic finite transducers.

                                -------------

     - Somewhat limited evaluation. The evaluation is performed on two families
       of benchmarks. The first family is an adaptation of format translation
       problems from Augeas a tool for configuration editing and the second
       family is from FlashFill a tool for synthesis of string transformations.
       All the benchmarks presented are “adaptation” and it’s unclear whether
       the authors only picked benchmarks for which they knew a priori a
       program in their DSL existed. Based on the presented data, I cannot
       assess how often the presented technique could be applied.

See general response.

                                -------------

     - Next, the comparison with the tool FlashFill/FlashExtract is somewhat
       confusing. I suspect the authors had to provide some domain and range
       regular expressions for the flash fill benchmarks, but this aspect,
       which is crucial to help the search, is not mentioned.

We do require regular expressions describing the input of FlashFill specs (we
require them for all), we will make sure that is more explicitly stated in the
paper.

                                -------------

     - What happens if someone provides Sigma* and Sigma* as domains and ranges to
       Optician.

If someone provides Sigma* and Sigma* as domains and ranges to optician it
will merely return the identity between those two.  If a user presents Sigma*
and Sigma* with some examples, we expect it will unroll the iterations until
the number of characters in the largest example has been enumerated, and
return something close to identity, but performing differently on those
examples, and some others to handle the readjustment.

                                -------------

     - Also, a better explanation of the difference between the DSLs of Lenses
       and Flash fill is required. For example, FlashFill can reverse a string,
       but the proposed language can’t.

Boomerang doesn't currently provide such capabilities.  However, there is no
technical reason this can't be done by adding in a reverse-and-iterate
operator to Boomerang.  Only a slight adjustment to the synthesis algorithm
would be needed to incorporate this into the algorithm.

                                -------------

     - What is the difference in size between the regexes for domain/range spec
       and the full lenses?

On average, the domain and range specs are slightly larger than the lens itself.
See above for the chart and a commentary explaining why we believe writing
lenses is harder than writing regular expressions, despite the fact that lenses
alone are sometimes shorter than regular expression specifications.

                                -------------

     - What is the difference in size between manually written lenses and
       synthesized ones?

We have not manually written lenses for all our benchmarks.  We find the sizes
are fairly comparable, but the hand-written lenses are more modular: with common
portions taken out and given good names.

                                -------------

     - Clarify how the benchmarks were selected and whether any were not
       selected a priori. Especially the flash* ones. Did you omit those that
       used character transformations such as upper-case?

We used benchmarks from three sources: Augeas benchmarks, FlashFill benchmarks,
and custom benchmarks.  We used Augeas benchmarks because it is a lens-based
tool that has seen industrial use.  We used FlashFill benchmarks because it is
a well-known and popular string transformation synthesis system.
We used custom benchmarks to find good uses for the tool in areas not previously
explored (like converting user address information from a CSV format into a
letter format).

For our Augeas benchmarks, we began synthesizing lenses for arbitrary problems
in the directory.  After a few of these, to show we weren't cherry-picking
lenses that our system could handle, we began turning the lenses into synthesis
problems alphabetically - first the As, then the Bs.

We chose the first three FlashFill benchmarks (extr-fname, extr-fname-err and
extr-quant) because they corresponded to the first two examples in the
paper. The problem extr-fname only allowed input paths with a file at the end,
where extr-fname-err provided an error message if no file was present.
The final example, extr-num was used because extracting a phone number was used
as an extended example, so we used it.  We could not find any examples in the
paper that applied a to_upper conversion.

                                -------------

     - Can the proposed DSL express any transformation that FlashFill can’t and
       vice-versa?

See the general response.

                                -------------

     - P19: maximally factors the concats and ors. What does this mean? Regex
       minimization is a hard problem, what is that one factors exactly? I
       think it would help to show one example of fully synthesized lens in the
       paper.

Agreed, we will finish our extended example to include a fully synthesized
title field lens.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (Id("")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.
Furthermore, when const(s,s) is present, it is converted into Id(s).

                                -------------

     - Eval the text says Full synthesized 49 benchmarks, but the plot in fig 8
       only shows 38/39?

Thank you for pointing out this typo, there are only 39 benchmarks.


===========================================================================
Review #18C

                                -------------

     - Overall, this paper looks like a solid and useful contribution to the
       lens literature. However, this reviewer has never used, let alone
       designed, a lens library. As such, I found the paper very hard to read
       and assess. I would have liked to see a clear problem statement (such as
       an example where it's annoying to write the Boomerang code but easy to
       synthesize the lens using your approach

We provide an example program below.

      typedef WSP = (" " | "\t" | "\n")+;;
      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au_synthesized_result
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

Even the relatively simple lens that permutes the 3 elements needed for
single_author_convert is fairly complex.  The complexity becomes even more
apparent when working with large lenses comprised of many sub-lenses (though
for brevity we give here the more minimal example above).  Lenses provide
great power with their invertibility guarantees, but they come at the cost
of thinking about many fiddly details when writing the terms.  Worrying
about these fiddly details while ALSO thinking about unambiguity
restrictions is a very difficult task!

We will make the problem statement more clear in the final version.

                                -------------

     - why is there no Boomerang code for your example in Sec. 3?).

We can include example code like we did above to highlight the frustrations a
lens programmer must encounter while writing their programs.

                                -------------

     - It was also not very clear to me what subset of Boomerang your approach
       supports. The introduction says it is a "useful subset of Boomerang" -
       but what does that mean?

We support the bijective subset given by the combinators in Section 2.  See the
general responses for a discussion on the usefulness of these combinators.

                                -------------

     - I was also a bit confused about the preliminaries in Sec. 2. In
       particular, it is not clear whether all or most of those preliminaries
       are from related work (but there are no references) or whether they are
       contributions of this paper.

The preliminaries define a specific subset of Boomerang that we aim to
synthesize.  Boomerang supports a variety of lenses - asymmetric lenses,
quotient lenses, and alignment lenses defined over a series of papers
[Combinators for bi-directional tree transformations: a linguistic approach to
the view update problem, POPL 2005; Boomerang: Resourceful Lenses for String
Data, POPL 2008; Quotient Lenses, ICFP 2008].  In the preliminaries, we define
which subset of Boomerang we aim to synthesize. While this language does not
appear verbatim in a prior paper, it is a natural core language for string
lenses.

                                -------------

     - p.4, "naively using it in the context of lens synthesis presents several
       problems"? Which problems? At this point I have no clue what "using it"
       may even mean. The "big picture" is not clear at all.

The big picture is: we are trying to carve out a core, bijective subset of
Boomerang to synthesize.  We want to find a subset that is
sufficiently expressive, but also permits an efficient synthesis algorithm.

For this subset to be sufficiently expressive, it is important to have a type
equivalence rule, where a regular expression type can be substituted for an
equivalent one.  However, we choose to use a notion of equivalence that is finer
than language equivalence: star semiring equivalence.  The reasons we choose to
use star semiring equivalence instead of language equivalence are detailed on
pages 8 through 10.

                                -------------

     - p. 3, "We have ommitted these theorems for space..." - maybe you mean
       "proofs"?

Correct, thank you.

                                -------------

     - p. 7, "instead of maintaining server code for each endpoint, we
       envision..." but surely the changes to an API involve more than just
       data format changes. For instance, single calls may have to be split
       into multiple calls. Hence it does not seem to be realistic to maintain
       the old API using _only_ synthesized lenses.

Yes, there are certainly times where more than lenses need to be added,
though lenses still solve part of this problem. The specific instance of
single calls being split into multiple calls can be handled by this paradigm
if the server allows for batch requests.  In particular, in the APIs of the
running example we use, the modern format does have batching capabilities,
https://www.visualstudio.com/en-us/docs/integrate/api/wit/batch .

