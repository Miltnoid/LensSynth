We thank the reviewers for their feedback.

*Talk about where we and FlashFill are different in expressivity of DSL*
*Talk about how we are /BETTER/ than them*

First, we detail the differences between the DSL of FlashFill and our DSL.
FlashFill allows for non-bijective transformations, which lets it express
transformations which project information.

Our DSL is less expressive than Flash Fill, but encodes reverse transformations
as well.  Furthermore, while our DSL is less expressive, we are able to
synthesize significantly more transformations than Flash Fill.  In particular,
Flash Fill has difficulties synthesizing transformations with nested iterations.
In the original Flash Fill paper, the tool does not even attempt to synthesize
terms with nested iterations for performance reasons (the last sentence of
Section 4.4).  We could not find documentation detailing whether the same
restriction of non-nested iterations is present in the version of Flash Fill
bundled in the Prose API.  While the language detailed in the Flash Fill can
express nested iterations we found it could not synthesize any, significantly
limiting its capabilities for synthesizing the types of transformations we
encountered in Augeas.

*Talk about why bijective restriction is not an issue slash did we scam
reviewers*
We simplified our task to handling bijective lenses as this is an initial
approach into this area.  This restriction did require some alterations of the
benchmarks.  These alterations fall in 2 major categories:
1) Whitespace was present in one format but not the other.
2) Information was projected away in the original example.

Category 1 was by far the most prevalent, and encountered in many of the Augeas
examples.  To handle this, we added additional whitespace in the other format.
However, this process can be automated using quotient lenses.  Quotient lenses
canonize strings into representative elements: a large amount of whitespace
would be canonized into a single whitespace character.  Putting these canonizers
at the edges would allow us to not need to put the additional whitespace
information in the target language.  We have since developed a language to
express canonizers within regular expressions, providing the ability to write a
"whitespace token" that allows for whitespace to be input, but also canonizes
that whitespace intended format.

Category 2 was less prevalent, but still present, typically in the FlashFill
examples.  To address this category, we added additional information to the end
of the target format containing the projected information.  Composing this
generated lens with one that deletes that information at the tail of the file,
when going left to right, and restores that information going back would provide
the full lens.  This wrapper is not very difficult to write, and we think that
discovering this projection automatically is possible, but we still need to do
the research on it.

This research we believe can be used in future work to solve these problems.
This was our primary motivation to solving this first, if we can solve this
problem we can use the generalize to more complex problems, but this step
is an important one in making those more general problems more tractable.

*Talk about how writing down the regular expressions is easier than writing down
the lenses (for B and C)*

*Discuss future work, how do we disambiguate, that makes it easier*

Thinking about the ambiguity of concatenations and unions of the languages is
hard to think about.  
One example of this is highlighted in the BibTeX to EndNote author fields.

      let bibtex_to_endnote_au
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

...

Detailed Responses to individual questions by the reviewers follow below.


Review #18A
===========================================================================

Strengths/weaknesses

- Restriction of focus to bijective "lenses" not clearly justified

The focus on bijective lenses is twofold.  Firstly, there are a large number of
formats which are in bijective correspondence: for example https://www.data.gov/
provides data in a variety of formats in bijective correspondence with each
other.  Secondly, bijective lenses can be viewed as the core of many other types
of lenses.  For example, standard lenses can be viewed in two parts: a bijective
part that moves the location of data around and adds in boilerplate, and a
projecting part that removes data in one direction, and adds it back in when
transforming in the reverse direction.  This approach can further be extended to
symmetric lenses by having that projection component on each side of the
transformation.  Quotient lenses can also be viewed in two parts: a
transformation component and a canonizing component.  This transformation
component could be a bijective core that is transformed, and the canonizing
component appears surrounding it.  In this way, finding a synthesis algorithm
for bijective lenses provides great progress in synthesizing more complex
lenses, it can be plugged into other systems in a principled way to extend the
algorithm to more general lens forms.


- Important parts of algorithm not explained (regarding how examples are used)

We omitted the formal description of these orderings for space.  A full
description of the algorithm is present in algorithm 4 in the appendix, on page
119, with the orderings defined in Definition 33 on page 118 (the definitions of
related structures begin at page 115).  We embed the parse trees of the examples
into the DNF regular expressions, and make an ordering on the DNF regular
expression with embedded parse trees.


- Not clear how much work it is to adapt examples to be suitable for bijective
  lens synthesis, or how useful the results are w.r.t. the original task

We simplified our task to handling bijective lenses as this is an initial
approach into this area.  This restriction did require some alterations of the
benchmarks.  The alterations were adding data into the target format that wasn't
there originally.  These alterations fall in 2 major categories:
1) Whitespace was present in one format but not the other.
2) Information was projected away in the original example.

Category 1 was by far the most prevalent, and encountered in many of the Augeas
examples.  To handle this, we added additional whitespace in the other format.
However, this process can be automated using quotient lenses.  Quotient lenses
canonize strings into representative elements: a large amount of whitespace
would be canonized into a single whitespace character.  Putting these canonizers
at the edges would allow us to not need to put the additional whitespace
information in the target language.  We have since developed a language to
express canonizers within regular expressions, providing the ability to write a
"whitespace token" that allows for whitespace to be input, but also canonizes
that whitespace intended format.

Category 2 was less prevalent, but still present, typically in the FlashFill
examples.  To address this category, we added additional information to the end
of the target format containing the projected information.  Composing this
generated lens with one that deletes that information at the tail of the file,
when going left to right, and restores that information going back would provide
the full lens.  This wrapper is not very difficult to write, and we think that
discovering this projection automatically is possible, but we still need to do
the research on it.


- But the main part of the paper is not self-contained - for example the
  algorithm description relies on (example-dependent) orderings of sequences and
  atoms that are not described; this is a key part of the algorithm since it is
  where the provided examples are actually used.

See above

- I also have a concern: sicne the approach is
  limited to bijective lenses, but many of the test examples were not
  bijective, how much work was it to modify the examples
  and how easy is it to manually hack the resulting bijective
  lenses to make them work on the real data?  Is there any chance of
  automating this or generalizing to handle non-bijective lenses
  (perhaps with this algorithm as a subroutine)?

See above

- I could see future work building on this to handle the non-bijective case 
  being a separate (and also interesting) paper.  But I would want the algorithm
  to be described more clearly and more caveats about the examples.

It is difficult to go into more formal detail about the orderings within the
page limits.  We will provide a more detailed informal description, and include
an explicit reference to the extended version in the final paper.


- p12 fig 6. I'm not sure how ule "DNF structural rewrite" could be
  applied as the LHS uses the operators defined in fig. 5, rather than syntax

We merely included that syntax as a means to make the derivation more
readable.  One can evaluate those operators, and it will be an arbitrary
DNF regular expression, we just use the operators to show the relationship
between the atom involved in the structural rewrite, and what it is
rewritten to.


- p17.  The desription of RigidSynth is incomplete.  It mentions orders
  $\leq_{Seq}$ and $\leq_{Atom}$ (and variants that use the examples) that do
  not appear to be defined.  What happens if there is ambiguity?  for
  example what if we are trying to infer a lens of type (a | b | c) <->
  (d|e|f) and we only have one example that says a <-> c?  If these
  orderings are standard things then please give a reference.  If not,
  they really need to be described in the paper.  The way examples are
  used to align parts of regular expressions seems really critical to
  this approach and is hardly explained.

We can go into more detail in the paper on this.  If two subcomponents can each
map to two subcomponents on the opposite side, a permutation which does not swap
the order of those subcomponents is best.


- p18: AllSome (alg. 3): I assume this is the obvious function of type
  'a option list -> 'a list option (that is None if there is a None in
  the list or Some [a1..an] if the list is [Some a1...Some an]) but
  please clarify

This is correct.


- p19: "easy to understand" - can you present any evidence for this?
  Easy for whom?

We feel that they are easy to understand because they look similar to how we
would handwrite the lenses,
but we have not done any user studies to justify that
they are easy to understand.  Evidence to the fact that they are easier to
understand than non-pretty printed versions is given by the sizes of the
generated lenses.  Without minimization, the lenses sizes averaged at (SIZE)
AST nodes, whereas minimization made the sizes average at (SIZE) ast nodes.


- p20: "We adapted these examples" please say mor about how many of the
  examples needed to be adapted (all? a handful?) and how much work it
  was, and how useful the resulting isomorphic lenses were w.r.t the
  original data / how much additional work was needed to adapt them.

All of the examples taken from existing programs needed to be adapted in some
way.  In particular, while there were many examples that didn't have projected
information that would have necessitated projection aspects of lens
capabilities, those examples all used whitespace.


- p20: "We developed a series of optimizations" - clarify that the
  algorithm already described includes all of these, and what you are
  going to do is disable them, rather than add more optimizations that
  weren't discussed earlier.  Might be helpful to signpost what parts of
  the algorithm are the "basic" algorithm and what parts are optional
  optimizations.

The algorithm described includes all but compositional synthesis.  We don't
include in the formal algorithm the means to which we use previously defined
lenses to synthesize new ones.  The way we do it is we develop equivalence
classes between user defined data types that have lenses, choose a
representative, and transform the user defined data types into that
representative, and convert the strings into elements of that representative
data type.


- p21: Fig 9 "Number of expansions" --> "Number of solutions"??

Number of expansions is the correct phrase.  Figure 9 shows how much random
search through expansions is required before RigidSynth terminates.  In
particular, this shows that full expansion inference performs significantly
better than the partial one that only performs the expansions it knows it must
perform.


- p21.  Also interesting to evaluate would be how time / number of
  solutions varies (e.g. for the full algorithm) as the number of
  examples provided varies.  Is the number of examples small? An active
  approach where the algorithm asks the user for examples might also be
  worth exploring (future work).

The number of examples provided doesn't typically have an impact on runspeed,
only correctness.  The number of valid solutions does vary with the number of
examples provided.  Typically, a small number of examples can greatly reduce the
number of possible solutions (TODO data).  The number of examples is indeed
small, as is shown in Figure 11.  An active approach we agree is an
interesting one, and one we too have considered.


- p24: "because our types do not have full canonical forms" - this is
  the case for the equations presented in the paper, but what about
  e.g. translating to automata and minimizing?

You are correct, regular expressions do have canonical forms in that manner.
We will change the phrasing to more accurately represent our meaning.



Review #18B
===========================================================================
Paper summary
-------------

- However, I’m not sure what exact advantage the proposed approach brings to the
  table. In particular, the user is still required to write exact input and output
  types of the transformations via regular expressions. How hard is to write
  lenses after one has such expressions? ...
  In the reviewer’s opinion, the specification mechanism is not very natural and
  it’s unclear whether it actually simplifies writing bijective transformations.
  This aspect is not evaluated and it would be nice to at least see the difference
  in sizes between the domain/range regexes vs the Boomerang lenses. In general,
  there is no report of the sizes of benchmarks.

We provide an example below on mapping the author field of BibTeX to EndNote:

      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au_synthed =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

We feel the specification is easier to read and write than the explicit lens.
Furthermore, even the relatively simple permutation of only 3 elements needed
for single_author_convert is fairly complex.  Beyond this, we find it is best
practices to include the type explicitly when writing the lens, both as
documentation and as additional assurance to correctness.  As we already spend
the effort writing these types manually for these benefits, there is no
additional work needed to use our synthesis algorithm, there is instead only
saved effort.

We provide the size of specifications and lenses below:

--------------------------------------------
|Test                | SpecSize | LensSize |
|------------------------------------------|
|cust/date-probs     | 85       | 79       |
|cust/cap-prob       | 112      | 108      |
|cust/2-cap-prob     | 122      | 66       |
|ff/extr-fname-err   | 143      | 151      |
|ff/extr-fname       | 149      | 168      |
|ff/extr-quant       | 150      | 145      |
|ff/extr-num         | 171      | 166      |
|aug/activemq        | 194      | 184      |
|cust/bib-prob       | 202      | 181      |
|cust/workitem-probs | 221      | 252      |
|aug/xml-l1          | 235      | 214      |
|cust/addr-probs     | 244      | 239      |
|aug/aptcrngsec      | 265      | 204      |
|aug/alias           | 271      | 210      |
|aug/backuppchosts   | 272      | 249      |
|aug/approx          | 277      | 264      |
|aug/apt-upd-mgr     | 278      | 210      |
|aug/aptsources      | 278      | 238      |
|aug/cachefilesd     | 294      | 233      |
|aug/aptprefs        | 297      | 280      |
|aug/afs-cellalias   | 298      | 246      |
|aug/avahi           | 301      | 234      |
|aug/chrony          | 308      | 289      |
|aug/xml             | 311      | 383      |
|aug/carbon          | 325      | 377      |
|aug/access          | 335      | 253      |
|aug/anacron         | 342      | 315      |
|aug/hosts           | 343      | 328      |
|aug/bootconf        | 350      | 271      |
|aug/auth-keys       | 354      | 424      |
|aug/cgrules         | 378      | 295      |
|aug/cgconfig        | 415      | 347      |
|aug/automaster      | 475      | 377      |
|aug/cron            | 475      | 414      |
|aug/channels        | 512      | 367      |
|aug/automounter     | 535      | 432      |
|aug/aptconf         | 540      | 450      |
|aug/aptconf-l1      | 564      | 503      |
|aug/bbhosts         | 670      | 651      |
--------------------------------------------

We can make sure we can provide at least some description of the sizes of specs
and lenses in the paper.


- Very limited DSL for transformations. The proposed DSL can only describe
  transformations that use identities and constant functions over input subparts.
  For example, one cannot synthesize the function toUpperCase, which I imagine
  could be useful for the kind of transformations appearing in the motivation.
  Moreover, the functions can use each word in the input only once: one cannot
  express the transformation abc->abcabc. Most bijective functions I can think of
  (string encoders, compression algorithms, encryption algorithms) require complex
  transformations over the input that go beyond identities. On this note, there
  was a paper this year at PLDI on inverting string encoders (Automatic program
  inversion using symbolic transducers, by Hu et al.), a topic which seems very
  related, but for which I couldn’t find a citation.

Our DSL contains transformations that cannot be expressed by Extended Symbolic
Finite Transducers.  The finite lookahead does not allow for transformations
which swaps the locations of data, a common pattern in Boomerang lenses.
We will add a citation to this work and a comment detailing the restrictions
extended symbolic finite transducers put in place.


- Somewhat limited evaluation. The evaluation is performed on two families of
  benchmarks. The first family is an adaptation of format translation problems
  from Augeas a tool for configuration editing and the second family is from
  FlashFill a tool for synthesis of string transformations. All the benchmarks
  presented are “adaptation” and it’s unclear whether the authors only picked
  benchmarks for which they knew a priori a program in their DSL existed. Based
  on the presented data, I cannot assess how often the presented technique could
  be applied.


- Next, the comparison with the tool FlashFill/FlashExtract is somewhat
  confusing. I suspect the authors had to provide some domain and range regular
  expressions for the flash fill benchmarks, but this aspect, which is crucial to
  help the search, is not mentioned.

  We do require regular expressions describing the input of FlashFill specs, we
  will make sure that is more explicitly stated in the paper.


- What happens if someone provides Sigma* and Sigma* as domains and ranges to
  Optician.

If someone provides Sigma* and Sigma* as domains and ranges to optician it
will merely return the identity between those two.  If a user presents Sigma*
and Sigma* with some examples, we expect it will unroll the iterations until
the number of characters in the largest example has been enumerated, and
return something close to identity, but performing differently on those
examples, and some others to handle the readjustment.

Optician is meant to work on finding mappings between the regular expressions
specified.  It is not intended to find subsets of the provided regular
expressions that can be mapped.


- Also, a better explanation of the
  difference between the DSLs of Lenses and Flash fill is required. For example,
  FlashFill can reverse a string, but the proposed language can’t.

Boomerang doesn't currently provide such capabilities.  However, there is no
technical reason this can't be done by adding in a reverse-and-iterate
operator to Boomerang.  Only a slight adjustment to the synthesis algorithm
would be needed to incorporate this into the algorithm.


- What is the difference in size between the regexes for domain/range spec and
  the full lenses?

On average, the domain and range specs are slightly larger than the lens itself.

We do not think that this means the work is useless, but rather it is used to
alleviate the pain of reasoning about nested swaps and concatenations, allow for
more simple maintenance of the code.

We provide an example below on mapping the author field of BibTeX to EndNote:

      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au_synthed =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

We feel the specification is easier to read and write than the explicit lens.
Furthermore, even the relatively simple permutation of only 3 elements needed
for single_author_convert is fairly complex.  Beyond this, we find it is best
practices to include the type explicitly when writing the lens, both as
documentation and as additional assurance to correctness.  As we already spend
the effort writing these types manually for these benefits, there is no
additional work needed to use our synthesis algorithm, there is instead only
saved effort.


- What is the difference in size between manually written lenses and synthesized
  ones?

We have not manually written lenses for all our benchmarks.  We find the sizes
are fairly comparable, but the hand-written lenses are more modular: with common
portions taken out and given good names.


- Clarify how the benchmarks were selected and whether any were not selected a
  priori. Especially the flash* ones. Did you omit those that used character
  transformations such as upper-case?

The first three (extr-fname, extr-fname-err and extr-quant) we chose because
they corresponded to the first two examples in the paper.
The problem extr-fname only allowed input paths with a file at the end, where
extr-fname-err provided an error message if no file was present.
The final example, extr-num was used because extracting a phone number was used
as an extended example.  We could not find any examples in the paper which
applied a to_upper conversion.


- Can the proposed DSL express any transformation that FlashFill can’t and
  vice-versa?

While Flash Fill's DSL permits nested iterations, for performance reasons Flash
Fill only synthesizes a single nesting of loops.  While this is sufficient for
the types of applications present in an Excel file, the examples we found in
Augeas were significantly more complex, requiring complex transformations with 
many nested iterations.

Flash Fill can express many transformation our DSL cannot.  For example, we
currently cannot handle losing information, which prevents us from projecting
information.


- P19: maximally factors the concats and ors. What does this mean? Regex
  minimization is a hard problem, what is that one factors exactly? I think it
  would help to show one example of fully synthesized lens in the paper.

Agreed, we will finish our extended example to include a fully synthesized
title field lens.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (const("","")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.

Minor:
- Eval the text says Full synthesized 49 benchmarks, but the plot in fig 8 only
  shows 38/39?

The text is wrong, there are only 39 benchmarks.





Review #18C
===========================================================================

- Overall, this paper looks like a solid and useful contribution to the lens
  literature. However, this reviewer has never used, let alone designed, a lens
  library. As such, I found the paper very hard to read and assess. I would have
  liked to see a clear problem statement (such as an example where it's annoying
  to write the Boomerang code but easy to synthesize the lens using your approach

We provide an example below on mapping the author field of BibTeX to EndNote:

      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au_synthed =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

We feel the specification is easier to read and write than the explicit lens.
Furthermore, even the relatively simple permutation of only 3 elements needed
for single_author_convert is fairly complex.  Beyond this, we find it is best
practices to include the type explicitly when writing the lens, both as
documentation and as additional assurance to correctness.  As we already spend
the effort writing these types manually for these benefits, there is no
additional work needed to use our synthesis algorithm, there is instead only
saved effort.


- why is there no Boomerang code for your example in Sec. 3?).

We can include example code like this to highlight the frustrations a lens
programmer must encounter while writing their programs.


- It was also not very clear to me what subset of Boomerang your approach
  supports. The introduction says it is a "useful subset of Boomerang" - but
  what does that mean?

The subset our approach supports are the bijective lenses where all regular
expression equivalences used in the typing derivation can be proven with
the star-semiring equivalence rules.  We find this useful in that all lenses can
easily be converted into a bijective lens, and we could not find a lens that
requires a courser notion of equivalence than star-semiring equivalence.


- I was also a bit confused about the preliminaries in Sec. 2. In particular, it
  is not clear whether all or most of those preliminaries are from related work
  (but there are no references) or whether they are contributions of this paper.

The preliminaries are us defining a specific subset of Boomerang that we focus
on.  Boomerang supports a variety of lenses - asymmetric lenses, quotient
lenses, and alignment lenses.  We define which subset of Boomerang we aim to
support.


- p.4, "naively using it in the context of lens synthesis presents several
  problems"? Which problems? At this point I have no clue what "using it" may
  even mean. The "big picture" is not clear at all.

In this context, "using it" refers to allowing retyping on the specified
equivalences.  We are trying to carve out a specific subset of Boomerang that
we want to synthesize, and are not allowing that subset to be included.
The problems with including full language equivalence is detailed on pages 8
through 10.


- p. 3, "We have ommitted these theorems for space..." - maybe you mean
  "proofs"?

Correct


- p. 7, "instead of maintaining server code for each endpoint, we envision..."
  but surely the changes to an API involve more than just data format changes.
  For instance, single calls may have to be split into multiple calls. Hence it
  does not seem to be realistic to maintain the old API using _only_ synthesized
  lenses.

    Yes, there are certainly times where more than lenses needs to be added.
    The specific instance of single calls being split into multiple
    calls can be handled by this paradigm if the server allows for batch
    requests.  In particular, APIs of the running example we use, the modern
    format does have batching capabilities,
    https://www.visualstudio.com/en-us/docs/integrate/api/wit/batch .

