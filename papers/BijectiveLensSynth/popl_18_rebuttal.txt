Thank you for your comments!

We begin with brief responses to the most significant concerns, followed by
a (long and very optional) appendix addressing all questions in detail.

                                -------------

      - What is the difference in expressiveness between our work and
        existing algorithms like FlashFill?

Formally, they are incomparable: each can synthesize some transformations
that the other cannot.

Since we restrict to bijections, we are unable to express functions that
don't preserve data, such as
  - mapping from a format with whitespace to one without whitespace,
  - turning a mix of uppercase and lowercase characters into purely
    uppercase characters, and
  - extracting a file name from a file path.
FlashFill can express all these.

Conversely, our "Optician" algorithm can solve some classes of problems that
existing synthesis systems cannot.  In particular, techniques that only use
input-output examples are unable to synthesize programs with nested loops.

One more technical note about point: FlashFill's DSL does permit nested
loops, but for efficiency reasons the synthesis algorithm only synthesizes
programs with no nesting (this is discussed at the end of section 4.4 of
"Automating String Processing in Spreadsheets Using Input-Output
Examples", POPL '11).  While a single nesting of loops seems to be
sufficient FlashFIll's intended uses, our benchmark suite (based on
real-world uses of the Augeas tool) includes many more complex formats and
transformations.  In particular, these formats tend to have deep layers of
nested transformations, with complex transformations at each layer.
FlashFill cannot handle such examples.

[BCP: Deep layers of transformations?  Or of stars (which is the issue we
started with)?  The last sentence or two are not convincing yet!

                                -------------

     - What modifications did we need to make to examples in the Augeas
       benchmark suite to make them bijective?

[BCP: Open by reminding the reader (who has probably forgotten, or who may
not even have read the paper yet!) what the question/issue in the reviews
was...]

The changes we made to the benchmark suite were of two forms:
1) Whitespace was present in one format but not the other.
2) Useful information was projected away going from one format to the other.

Category 1 was by far the most common, applying to many of the Augeas
examples.  To handle this, we added additional whitespace to the other format,
where typically whitespace is unnecessary.

Instead of changing the formats, we could have extended the system to
involve canonizers.  Canonizers can be placed on the ends of lenses to
normalize the input data.  Canonizers can normalize an arbitrarily long
sequence of whitespace to a single space.  Canonizers also can be used to
handle casing issues: normalizing a sequence of uppercase and lowercase
characters into purely uppercase characters.  We have recently developed a
framework to annotate a regular expression with canonizing information,
allowing for a single term to represent an arbitrary sequence of whitespace
and a means to normalize it to a single space.  Using this framework, we can
generate non-bijective lenses using our framework, as long as the canonized
forms of their source and target types are in bijective correspondence.

Category 2 was less prevalent, but still present, typically in the FlashFill
examples.  To address this category, we added additional information to the end
of the target format containing the projected information.  Composing this
generated lens with one that deletes that information at the tail of the
file, when going left to right, and restores that information going back
would provide the full lens.  This wrapper is not difficult to write, and we
think that discovering this projection automatically is possible, but we
have not yet done it.

There are a large number of formats that are in bijective
correspondence. For example https://www.data.gov/ provides data in a variety
of formats in bijective correspondence with each other.  Many of the formats
present in existing lens libraries use either canonizers or projections.
The theories developed to handle synchronization tasks for real world
data (quotient lenses for Category 1, and symmetric lenses for Category 2),
have a bijective core, surrounded by either canonizers or projections.  We
believe that our system can be used as a drop-in component for synthesis
algorithms on these more complex lens structures.

                                -------------

     - After having written the regular expressions, is it very difficult
       for users to then write the lens?  Are we saving anybody any
       significant effort?

Engineering best practices dictate that we annotate the lenses with their
types.  While Boomerang does not need these annotations - being able to
infer the types from the terms - the types of the term serve as
documentation for future programmers to understand what formats the lens
maps between.  Furthermore, it provides an additional resilience to future
modifications of the lens, as it validates that the lens maps exactly
between strings of the provided formats - invalid inputs are not accepted
nor are the outputs ever invalid.  In this way, we are not requiring
additional work by the programmer to use our system; we are allowing the
programmer to save the difficulties of writing the term by using work they
should already be performing.  To highlight these difficulties, we show an
example program for mapping the author field of a BibTeX entry:

      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au_synthesized_result
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

Even the relatively simple lens that permuts the 3 elements needed for
single_author_convert is fairly complex.  The complexity becomes even more
apparent when working with large lenses comprised of many sub-lenses (though
for brevity we give here the more minimal example above).  Lenses provide
great power with their invertibility guarantees, but they come at the cost
of thinking about many fiddly details when writing the terms.  Worrying
about these fiddly details while ALSO thinking about unambiguity
restrictions is a very difficult task!

Optician is aimed at different audiences than existing string transformation
tools.  While existing tools allow the average end-user to generalize their
examples to programs, Optician allows programmers to get the benefits of a
powerful language while avoiding much of the complexity of programming in
that language.  This paradigm allows for more complex programs to be
synthesized, the types of programs that necessitate programming in such a
DSL, but also provide a burden on the user.  However, this burden is already
one incured by programmers using best practices, so we are merely saving
them the time spent on tedious work.


===========================================================================
===========================================================================
Detailed responses to individual questions in the reviews follow...

[BCP: In the "appendix" I think it's important to quote the reviews
verbatim, so that reviewers can see what they said rather than our
paraphrase of it.] [AFM: Quoted but will add in quotes to make it explicit]
[BCP: I see -- I was misreading (in part because of "Strengths/weaknesses",
which comes from the review but is not "quoted").  No need to add in quotes.
But maybe indenting the comments more will separate them better, visually.
Let's also clean up the spacing.]


Review #18A

Strengths/weaknesses

- Restriction of focus to bijective "lenses" not clearly justified

See general responses.


- Important parts of algorithm not explained (regarding how examples are used)

We omitted the formal description of these orderings for space.  A full
description of the algorithm is present in algorithm 4 in the appendix (see the
supplemental pdf submitted with the paper), on page
119, with the orderings defined in Definition 33 on page 118 (the definitions of
related structures begin at page 115).  We embed the parse trees of the examples
into the DNF regular expressions, and make an ordering on the DNF regular
expression with embedded parse trees.  We would be happy to rewrite the paper to
include whatever information the reviewer believes is most important.


- Not clear how much work it is to adapt examples to be suitable for bijective
  lens synthesis, or how useful the results are w.r.t. the original task

See general responses.


- But the main part of the paper is not self-contained - for example the
  algorithm description relies on (example-dependent) orderings of sequences and
  atoms that are not described; this is a key part of the algorithm since it is
  where the provided examples are actually used.

See above.

- I also have a concern: since the approach is
  limited to bijective lenses, but many of the test examples were not
  bijective, how much work was it to modify the examples
  and how easy is it to manually hack the resulting bijective
  lenses to make them work on the real data?  Is there any chance of
  automating this or generalizing to handle non-bijective lenses
  (perhaps with this algorithm as a subroutine)?

See above.

- I could see future work building on this to handle the non-bijective case 
  being a separate (and also interesting) paper.  But I would want the algorithm
  to be described more clearly and more caveats about the examples.

We agree the non-bijective case would also be an interesting paper.  We can
provide additional caveats about the examples and a better description of the
algorithm in the final version of this paper.


- p12 fig 6. I'm not sure how ule "DNF structural rewrite" could be
  applied as the LHS uses the operators defined in fig. 5, rather than syntax

We merely wrote the rule with operators as a means to make the derivation more
readable.  One can evaluate those operators, and it will be an arbitrary
DNF regular expression, we just use the operators to show the relationship
between the atom involved in the structural rewrite, and what it is
rewritten to.


- p17.  The desription of RigidSynth is incomplete.  It mentions orders
  $\leq_{Seq}$ and $\leq_{Atom}$ (and variants that use the examples) that do
  not appear to be defined.  What happens if there is ambiguity?  for
  example what if we are trying to infer a lens of type (a | b | c) <->
  (d|e|f) and we only have one example that says a <-> c?  If these
  orderings are standard things then please give a reference.  If not,
  they really need to be described in the paper.  The way examples are
  used to align parts of regular expressions seems really critical to
  this approach and is hardly explained.

First, we think the reviewer intended to write "we have only one example that
says a <-> d".  We see two cases for this scenario.
Case 1: The structure of the other two determines where they must map
Case 2: The structure does not determine where they must mapped

For Case 1, consider the scenario where
b = Name
c = Name*
e = Name*
f = Name
The structures of b, c, e, and f determine where they will be mapped: b <-> f
and c <-> e.  In particular, RigidSynth will order them as:
[a;b;c]
[d;f;e]
that then creates the maps previously provided.

For Case 2, consider the scenario where
b = Name
c = Name
e = Name
f = Name
In this case, the structures do not determine where they will be mapped.
The maps (a <-> d , b <-> e , c <-> f)
     and (a <-> d , b <-> f , c <-> e) are both valid.  In this situation, the
one we choose is based on a heuristic that minimizes swaps.  In particular,
Rigidsynth will order them as:
[a;b;c]
[d;e;f]
that creates the maps (a <-> d , b <-> e , c <-> f).


- p18: AllSome (alg. 3): I assume this is the obvious function of type
  'a option list -> 'a list option (that is None if there is a None in
  the list or Some [a1..an] if the list is [Some a1...Some an]) but
  please clarify

This is correct.


- p19: "easy to understand" - can you present any evidence for this?
  Easy for whom?

We feel that they are easy to understand because they look similar to how we
would handwrite the lenses,
but we have not done any user studies to justify that
they are easy to understand.  Evidence to the fact that they are easier to
understand than non-pretty printed versions is given by the sizes of the
generated lenses.  Without minimization, the lenses sizes average at (SIZE)
AST nodes, whereas minimization made the sizes average at (SIZE) ast nodes.
In the general response, we show what a minimized vs handwritten lens look like.
Below we show the difference between a non-minimized title field and a minimized
title field for a work item.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (Id("")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.
Furthermore, when const(s,s) is present, it is converted into Id(s).


- p20: "We adapted these examples" please say mor about how many of the
  examples needed to be adapted (all? a handful?) and how much work it
  was, and how useful the resulting isomorphic lenses were w.r.t the
  original data / how much additional work was needed to adapt them.

See general response.


- p20: "We developed a series of optimizations" - clarify that the
  algorithm already described includes all of these, and what you are
  going to do is disable them, rather than add more optimizations that
  weren't discussed earlier.  Might be helpful to signpost what parts of
  the algorithm are the "basic" algorithm and what parts are optional
  optimizations.

The algorithm described includes all but compositional synthesis, which uses
predefined lenses.  To use a predefined lens, l : A <-> B, the implementation
develops equivalence classes between user defined data types with lenses between
them (in the above example, A and B would be placed in the same equivalence
class).  Next, a representative element of each equivalence class is chosen.
All user defined data types are then transformed into their representative, and
the string examples are converted into examples in the language of the
representative.


equivalence classes between user defined data types that have lenses, choose a
representative, and transform the user defined data types into that
representative, and convert the strings into elements of that representative
data type.  Then we proceed with synthesis as described by the formal algorithm.


- p21: Fig 9 "Number of expansions" --> "Number of solutions"??

Number of expansions is the correct phrase.  Figure 9 shows how much random
search through expansions is required before RigidSynth terminates.  In
particular, this shows that full expansion inference performs significantly
better than the partial one that only performs the expansions it knows it must
perform.


- p21.  Also interesting to evaluate would be how time / number of
  solutions varies (e.g. for the full algorithm) as the number of
  examples provided varies.  Is the number of examples small?

The number of examples provided doesn't typically have an impact on runspeed,
only correctness.  The number of valid solutions does vary with the number of
examples provided.  Typically, a small number of examples can greatly reduce the
number of possible solutions (TODO data).  The number of examples is indeed
small, as is shown in Figure 11.


- p24: "because our types do not have full canonical forms" - this is
  the case for the equations presented in the paper, but what about
  e.g. translating to automata and minimizing?

This is an interesting idea.  It is unclear how an automataton for a type
can be used to direct synthesis.  Nevertheless, this may lead to interesting
research.



===========================================================================
Review #18B

Paper summary
-------------

- However, I’m not sure what exact advantage the proposed approach brings to the
  table. In particular, the user is still required to write exact input and output
  types of the transformations via regular expressions. How hard is to write
  lenses after one has such expressions? ...
  In the reviewer’s opinion, the specification mechanism is not very natural and
  it’s unclear whether it actually simplifies writing bijective transformations.
  This aspect is not evaluated and it would be nice to at least see the difference
  in sizes between the domain/range regexes vs the Boomerang lenses. In general,
  there is no report of the sizes of benchmarks.

See general response.  We also provide data on the sizes below.  However, we
do not think that purely lines of code is the best metric for our data, as our
system provides benefits beyond saving keystrokes for the programmer, detailed
below:

* Regular expressions are common - almost every programmer has a firm grip on
regular expressions.  In contrast, almost _no_ programmers know anything about
programming with lenses.

* A regular expression describes one piece of data.  When writing a lens, one
must think about both pieces of data at the same time, and simultaneously
translate back and forth between them.

* One must sometimes compute in their own head how to unroll or transform the
regular expression into the right form.

|-------------------------------------------------------------|
| Test                | SpecSize | LensAndTypeSize | LensSize |
|-------------------------------------------------------------|
| cust/date-probs     | 85       | 97              | 79       |
| cust/cap-prob       | 112      | 169             | 108      |
| cust/2-cap-prob     | 122      | 188             | 66       |
| ff/extr-fname-err   | 143      | 172             | 151      |
| ff/extr-fname       | 149      | 195             | 168      |
| ff/extr-quant       | 150      | 161             | 145      |
| ff/extr-num         | 171      | 186             | 166      |
| aug/activemq        | 194      | 204             | 184      |
| cust/bib-prob       | 202      | 265             | 181      |
| cust/workitem-probs | 221      | 330             | 252      |
| aug/xml-l1          | 235      | 301             | 214      |
| cust/addr-probs     | 244      | 308             | 239      |
| aug/aptcrngsec      | 265      | 336             | 204      |
| aug/alias           | 271      | 348             | 210      |
| aug/backuppchosts   | 272      | 318             | 249      |
| aug/approx          | 277      | 345             | 264      |
| aug/apt-upd-mgr     | 278      | 355             | 210      |
| aug/aptsources      | 278      | 351             | 238      |
| aug/cachefilesd     | 294      | 368             | 233      |
| aug/aptprefs        | 297      | 409             | 280      |
| aug/afs-cellalias   | 298      | 370             | 246      |
| aug/avahi           | 301      | 370             | 234      |
| aug/chrony          | 308      | 331             | 289      |
| aug/xml             | 311      | 546             | 383      |
| aug/carbon          | 325      | 507             | 377      |
| aug/access          | 335      | 436             | 253      |
| aug/anacron         | 342      | 447             | 315      |
| aug/hosts           | 343      | 449             | 328      |
| aug/bootconf        | 350      | 457             | 271      |
| aug/auth-keys       | 354      | 553             | 424      |
| aug/cgrules         | 378      | 487             | 295      |
| aug/cgconfig        | 415      | 612             | 347      |
| aug/automaster      | 475      | 621             | 377      |
| aug/cron            | 475      | 667             | 414      |
| aug/channels        | 512      | 682             | 367      |
| aug/automounter     | 535      | 710             | 432      |
| aug/aptconf         | 540      | 700             | 450      |
| aug/aptconf-l1      | 564      | 777             | 503      |
| aug/bbhosts         | 670      | 1041            | 651      |
|-------------------------------------------------------------|
| average             | 310      | 414             | 277      |
|-------------------------------------------------------------|

We can make sure we can provide at least some description of the sizes of specs
and lenses in the final version of the paper.


- Very limited DSL for transformations. The proposed DSL can only describe
  transformations that use identities and constant functions over input subparts.
  For example, one cannot synthesize the function toUpperCase, which I imagine
  could be useful for the kind of transformations appearing in the motivation.

We can convert between all uppercase and all lowercase.  Quotient lenses can be
used to normalize a format (or portions of a format) into fully uppercase or
fully lowercase data.


- Moreover, the functions can use each word in the input only once: one cannot
  express the transformation abc->abcabc. Most bijective functions I can think of
  (string encoders, compression algorithms, encryption algorithms) require complex
  transformations over the input that go beyond identities. 

See general response for more detailed information about the bijective
restriction.
- On this note, there was a paper this year at PLDI on inverting string encoders
  (Automatic program inversion using symbolic transducers, by Hu et al.), a
  topic which seems very related, but for which I couldn’t find a citation.

Our DSL contains transformations that cannot be expressed by Extended Symbolic
Finite Transducers.  The finite lookahead does not allow for transformations
that swap data, a common pattern and important pattern in Boomerang lenses. We
will add a citation to this work and a comment detailing the restrictions of
symbolic finite transducers.


- Somewhat limited evaluation. The evaluation is performed on two families of
  benchmarks. The first family is an adaptation of format translation problems
  from Augeas a tool for configuration editing and the second family is from
  FlashFill a tool for synthesis of string transformations. All the benchmarks
  presented are “adaptation” and it’s unclear whether the authors only picked
  benchmarks for which they knew a priori a program in their DSL existed. Based
  on the presented data, I cannot assess how often the presented technique could
  be applied.

See general response.


- Next, the comparison with the tool FlashFill/FlashExtract is somewhat
  confusing. I suspect the authors had to provide some domain and range regular
  expressions for the flash fill benchmarks, but this aspect, which is crucial to
  help the search, is not mentioned.

We do require regular expressions describing the input of FlashFill specs (we
require them for all), we will make sure that is more explicitly stated in the
paper.


- What happens if someone provides Sigma* and Sigma* as domains and ranges to
  Optician.

If someone provides Sigma* and Sigma* as domains and ranges to optician it
will merely return the identity between those two.  If a user presents Sigma*
and Sigma* with some examples, we expect it will unroll the iterations until
the number of characters in the largest example has been enumerated, and
return something close to identity, but performing differently on those
examples, and some others to handle the readjustment.


- Also, a better explanation of the
  difference between the DSLs of Lenses and Flash fill is required. For example,
  FlashFill can reverse a string, but the proposed language can’t.

Boomerang doesn't currently provide such capabilities.  However, there is no
technical reason this can't be done by adding in a reverse-and-iterate
operator to Boomerang.  Only a slight adjustment to the synthesis algorithm
would be needed to incorporate this into the algorithm.


- What is the difference in size between the regexes for domain/range spec and
  the full lenses?

On average, the domain and range specs are slightly larger than the lens itself.
See the above chart.  See the general response for a detailed commentary
explaining why we believe writing lenses is harder than writing regular
expressions, despite the fact that lenses alone are sometimes shorter than
regular expression specifications.


- What is the difference in size between manually written lenses and synthesized
  ones?

We have not manually written lenses for all our benchmarks.  We find the sizes
are fairly comparable, but the hand-written lenses are more modular: with common
portions taken out and given good names.


- Clarify how the benchmarks were selected and whether any were not selected a
  priori. Especially the flash* ones. Did you omit those that used character
  transformations such as upper-case?

We used benchmarks from three sources: Augeas benchmarks, FlashFill benchmarks,
and custom benchmarks.  We used Augeas benchmarks because it is a lens-based
tool that has seen industrial use.  We used FlashFill benchmarks because it is
a well-known and popular string transformation synthesis system.
We used custom benchmarks to find good uses for the tool in areas not previously
explored (like converting user address information from a CSV format into a
letter format).

For our Augeas benchmarks, we began synthesizing lenses for arbitrary problems
in the directory.  After a few of these, to show we weren't cherry-picking
lenses that our system could handle, we began turning the lenses into synthesis
problems alphabetically - first the As, then the Bs.

We chose the first three FlashFill benchmarks (extr-fname, extr-fname-err and
extr-quant) because they corresponded to the first two examples in the
paper. The problem extr-fname only allowed input paths with a file at the end,
where extr-fname-err provided an error message if no file was present.
The final example, extr-num was used because extracting a phone number was used
as an extended example, so we used it.  We could not find any examples in the
paper that applied a to_upper conversion.


- Can the proposed DSL express any transformation that FlashFill can’t and
  vice-versa?

See the general response.


- P19: maximally factors the concats and ors. What does this mean? Regex
  minimization is a hard problem, what is that one factors exactly? I think it
  would help to show one example of fully synthesized lens in the paper.

Agreed, we will finish our extended example to include a fully synthesized
title field lens.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (Id("")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.
Furthermore, when const(s,s) is present, it is converted into Id(s).

Minor:
- Eval the text says Full synthesized 49 benchmarks, but the plot in fig 8 only
  shows 38/39?

Thank you for pointing out this typo, there are only 39 benchmarks.


===========================================================================
Review #18C

- Overall, this paper looks like a solid and useful contribution to the lens
  literature. However, this reviewer has never used, let alone designed, a lens
  library. As such, I found the paper very hard to read and assess. I would have
  liked to see a clear problem statement (such as an example where it's annoying
  to write the Boomerang code but easy to synthesize the lens using your approach

We provide an extended example in the general response.  We will make the
problem statement more clear in the final version.


- why is there no Boomerang code for your example in Sec. 3?).

We can include example code like this to highlight the frustrations a lens
programmer must encounter while writing their programs.


- It was also not very clear to me what subset of Boomerang your approach
  supports. The introduction says it is a "useful subset of Boomerang" - but
  what does that mean?

We support the bijective subset given by the combinators in Section 2.  See the
general responses for a discussion on the usefulness of these combinators.

The subset our approach supports are the bijective lenses where all regular
expression equivalences used in the typing derivation can be proven with
the star-semiring equivalence rules.  We find this useful in that all lenses can
easily be converted into a bijective lens, and we could not find a lens in
Boomerang or Augeas that requires a courser notion of equivalence than
star-semiring equivalence.


- I was also a bit confused about the preliminaries in Sec. 2. In particular, it
  is not clear whether all or most of those preliminaries are from related work
  (but there are no references) or whether they are contributions of this paper.

The preliminaries define a specific subset of Boomerang that we aim to
synthesize.  Boomerang supports a variety of lenses - asymmetric lenses,
quotient lenses, and alignment lenses defined over a series of papers
[Combinators for bi-directional tree transformations: a linguistic approach to
the view update problem, POPL 2005; Boomerang: Resourceful Lenses for String
Data, POPL 2008; Quotient Lenses, ICFP 2008].  In the preliminaries, we define
which subset of Boomerang we aim to synthesize. While this language does not
appear verbatim in a prior paper, it is a natural core language for string
lenses.


- p.4, "naively using it in the context of lens synthesis presents several
  problems"? Which problems? At this point I have no clue what "using it" may
  even mean. The "big picture" is not clear at all.

In this context, "using it" refers to allowing retyping on the specified
equivalences.  We are trying to carve out a specific subset of Boomerang that
we want to synthesize, and are not allowing the subset requiring a courser
notion of equivalence to be included. The problems with including full language
equivalence is detailed on pages 8 through 10.


- p. 3, "We have ommitted these theorems for space..." - maybe you mean
  "proofs"?

Correct


- p. 7, "instead of maintaining server code for each endpoint, we envision..."
  but surely the changes to an API involve more than just data format changes.
  For instance, single calls may have to be split into multiple calls. Hence it
  does not seem to be realistic to maintain the old API using _only_ synthesized
  lenses.

    Yes, there are certainly times where more than lenses need to be added,
    though lenses still solve part of this problem. The specific instance of
    single calls being split into multiple calls can be handled by this paradigm
    if the server allows for batch requests.  In particular, APIs of the running
    example we use, the modern format does have batching capabilities,
    https://www.visualstudio.com/en-us/docs/integrate/api/wit/batch .

