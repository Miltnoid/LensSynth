We thank the reviewers for their feedback.  We will provide a common rebuttal
to address concerns common to many reviewers, and will then have an appendix
addressing specific concerns.

- What is the difference between our work and existing work, like Flash Fill,
  in terms of expressivity?

We are able to synthesize some transformations that Flash Fill cannot, and
Flash Fill is able to synthesize some transformations that we cannot.
In particular, by restricting ourselves to bijections, we are unable to express
a large class of functions.  In alternative string synthesis systems, this
bijective restriction is not in place, and additional strings can be
synthesized.  However, we do not see this as a failure, but as a design choice.
Our system is not targeting single direction transformations: we feel
programmers already have the tools they need to write these by hand.  Instead,
we are aiming to alleviate the difficulties in programming bidirectional
transformations, which have languages that are very difficult to write in.

However, Optician can still solve certain classes of problems other string
synthesis systems cannot.  In particular, existing techniques that only use
input-output examples are unable to synthesize programs with nested loops.
In particular, while Flash Fill's DSL does permit nested loops, for efficiency
reasons, the synthesis algorithm only synthesizes programs with no nesting (this
is stated at the end of section 4.4).  While a single nesting of loops is
sufficient for the types of problems encountered in transforming Excel
spreadsheet data, our tool is aimed at building large transformations between
highly complex formats.  The types of formats Augeas is built to handle have
many deep layers of nesting, with very complex transformations at each layer.
Nested iteration is necessary for these types of transformations, and existing
techniques are insufficient for synthesizing them.


- Why did we make the bijective restriction, and what transformations did we
  make to our benchmark suite to make them bijective.

We simplified our task to handling bijective lenses as this is an initial
approach into this research.  There are a large number of
formats which are in bijective correspondence: for example https://www.data.gov/
provides data in a variety of formats in bijective correspondence with each
other.  However, we began with synthesizing bijective
lenses primarily because we believe this bijective core can be extended in a
principled way to handle more complex lenses.

Many of our transformations were nearly bijective, but had unnecessary
information, like whitespace or casing, that prevented them from being bijective.
Quotient lenses provide the capabilities to ignore unnecessary information like
whitespace.  While the combinators for quotient lenses, canonizers, can be
intermixed with basic lenses in the original paper, we believe that a
"canonizers-at-the-edge" approach is just as expressive.  In particular,
we can express a transformation that is bijective up to a quotient by having a
bijective lens core, with a canonizer at each side that normalizes the input.
Indeed, we already have a prototype that does this, allowing specialized
tokens that encodes both the full description of viable inpout as well as the
information on how to canonize the data.

The remaining transformations that needed to be altered were also nearly
bijective, but projected away useful information, and this projection prevented
them from being bijective.  Unlike with quotient lenses, we do not want to
remove this information - we want the information to be preserved through
round-trips.  Furthermore, there are formats where each format contains
information not present in the other format.  Symmetric lenses provide the
capabilities for writing such transformations.  Similarly to quotient lenses,
projection combinators can be intermixed with bijection capabilities,
but we can view symmetric lenses as having a bijective core with a projection
combinator on each side that removes data in one direction, and restores it in
the other.

While we simplified our task to bijective lenses, we did this because we felt
a synthesis algorithm for bijective lenses could form the core of a synthesis
algorithm for other types of lenses.  We agree this motivation looking towards
future work is currently lacking in the paper, and we can add this in for the
final version.

The changes we put on our benchmark suite fall in 2 major categories that mirror
the intended extensions to our system.
1) Whitespace was present in one format but not the other.
2) Useful information was projected away going from one format to the other.

Category 1 was by far the most prevalent, and encountered in many of the Augeas
examples.  To handle this, we added additional whitespace to the other format,
where typically whitespace is unnecessary.
This can be solved by using quotients on the side with whitespace.  We think the
strategy of using specialized tokens to represent both a language and a
canonizer can solve this problem.

Category 2 was less prevalent, but still present, typically in the FlashFill
examples.  To address this category, we added additional information to the end
of the target format containing the projected information.  Composing this
generated lens with one that deletes that information at the tail of the file,
when going left to right, and restores that information going back would provide
the full lens.  This wrapper is not very difficult to write, and we think that
discovering this projection automatically is possible, but we still need to do
the research on it.


- After having written the regular expressions, is it very difficult for users
  to then write the lens.  Are we saving anybody any significant effort.

Engineering best practices dictate that we annotate the lenses with their types.
While Boomerang does not need these annotations - being able to infer the types
from the terms - the types of the term serve as documentation for
future programmers to understand what formats the lens maps between.
Furthermore, it provides an additional resilience to future modifications of the
lens, as it validates that the lens maps exactly between strings of the provided
formats - invalid inputs are not accepted nor are the outputs ever invalid.
In this way, we are not requiring additional work by the programmer to use our
system; we are allowing the programmer to save the difficulties of
writing the term by using work they should already be performing.  To highlight
these difficulties, we show an example program for mapping the author field of
a BibTeX entry.

      typedef NAME = UPPERCASE (LOWERCASE)*;;

      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef STARTTOEND = (NAME WSP)* NAME;;
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;

      let bibtex_to_endnote_au =
        synth
          BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS

      let bibtex_to_endnote_au_synthesized_result
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        del "author={"
          . ins "au - "
          . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
          . (del " and "
               . ins "\n au - "
               . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
          . del "}" 

      let bibtex_to_endnote_au_human_written
        : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
        let single_author_convert =
          ins " au - "
            . lens_swap
                (NAME . del ",")
                (lens_swap WSP NAME)*
        in
        del "author={"
          . single_author_convert
          . (del " and "
               . ins "\n"
               . single_author_convert)* 
          . del "}" 

Even the relatively simple permutation of only 3 elements needed for
single_author_convert is fairly complex.  These becomes even more apparent when
working with large lenses comprised of many sub-lenses being permuted (though
we prefer to use a more minimal example).  Lenses provide great power with their
invertibility guarantees, but they come at the cost of thinking about many
fiddly details when writing the terms.  Worrying about these fiddly details
while ALSO thinking about unambiguity restrictions is a very difficult task!

This tool is aimed at different audiences than existing string transformation
tools.  While existing tools allow the average end-user to generalize their
examples to programs, Optician allows programmers to get the benefits of a
powerful language while avoiding much of the complexity of programming in that
language.  This paradigm allows for more complex programs to be able to be
synthesized, the types of programs that necessitate programming in such a DSL,
but also provide a burden on the user.  However, this burden is already one
incured by programmers using best practices, so we are merely saving them the
time spent on tedious work.



Detailed Responses to individual questions by the reviewers follow below.


Review #18A
===========================================================================

Strengths/weaknesses

- Restriction of focus to bijective "lenses" not clearly justified

See general responses.


- Important parts of algorithm not explained (regarding how examples are used)

We omitted the formal description of these orderings for space.  A full
description of the algorithm is present in algorithm 4 in the appendix, on page
119, with the orderings defined in Definition 33 on page 118 (the definitions of
related structures begin at page 115).  We embed the parse trees of the examples
into the DNF regular expressions, and make an ordering on the DNF regular
expression with embedded parse trees.  While we think the formal description of
these orderings is too long to be included in the paper, we can provide a more
involved informal description in the text, and provide a reference to an
extended version with the formal descriptions of the orderings.


- Not clear how much work it is to adapt examples to be suitable for bijective
  lens synthesis, or how useful the results are w.r.t. the original task

See general responses.


- But the main part of the paper is not self-contained - for example the
  algorithm description relies on (example-dependent) orderings of sequences and
  atoms that are not described; this is a key part of the algorithm since it is
  where the provided examples are actually used.

See above.

- I also have a concern: sicne the approach is
  limited to bijective lenses, but many of the test examples were not
  bijective, how much work was it to modify the examples
  and how easy is it to manually hack the resulting bijective
  lenses to make them work on the real data?  Is there any chance of
  automating this or generalizing to handle non-bijective lenses
  (perhaps with this algorithm as a subroutine)?

See above.

- I could see future work building on this to handle the non-bijective case 
  being a separate (and also interesting) paper.  But I would want the algorithm
  to be described more clearly and more caveats about the examples.

We agree the non-bijective case would also be an interesting paper.  We can
provide additional caveats about the examples and a better description of the
algorithm in the final version of this paper.


- p12 fig 6. I'm not sure how ule "DNF structural rewrite" could be
  applied as the LHS uses the operators defined in fig. 5, rather than syntax

We merely included that syntax as a means to make the derivation more
readable.  One can evaluate those operators, and it will be an arbitrary
DNF regular expression, we just use the operators to show the relationship
between the atom involved in the structural rewrite, and what it is
rewritten to.


- p17.  The desription of RigidSynth is incomplete.  It mentions orders
  $\leq_{Seq}$ and $\leq_{Atom}$ (and variants that use the examples) that do
  not appear to be defined.  What happens if there is ambiguity?  for
  example what if we are trying to infer a lens of type (a | b | c) <->
  (d|e|f) and we only have one example that says a <-> c?  If these
  orderings are standard things then please give a reference.  If not,
  they really need to be described in the paper.  The way examples are
  used to align parts of regular expressions seems really critical to
  this approach and is hardly explained.

We can go into more detail in the paper on this.  Intuitively,
we group the subcomponents of a DNF regular expression into equivalence classes
based on if they can map to the same subcomponents of the DNF regular expression
on the other side.  Then, no swaps are performed within subcomponents of the
same equivalence class, they are merely swapped with subcomponents of different
equivalence classes, if one removed all other subcomponents, the orderings would
be merely the identity.

For example, in the provided scenario (caveat, I think the reviewer intended to
say an example that says a <-> e) the example makes a map to e, so the
equivalence classes are:

{a}, {b,c} on the left
{d,f}, {e} on the right

Then, the algorithm will sort these equivalence classes

{a}, {b,c}
{e}, {d,f}

and the equivalence classes will be mapped to each other through zipping

a <-> e, b <-> d, c <-> f


- p18: AllSome (alg. 3): I assume this is the obvious function of type
  'a option list -> 'a list option (that is None if there is a None in
  the list or Some [a1..an] if the list is [Some a1...Some an]) but
  please clarify

This is correct.


- p19: "easy to understand" - can you present any evidence for this?
  Easy for whom?

We feel that they are easy to understand because they look similar to how we
would handwrite the lenses,
but we have not done any user studies to justify that
they are easy to understand.  Evidence to the fact that they are easier to
understand than non-pretty printed versions is given by the sizes of the
generated lenses.  Without minimization, the lenses sizes average at (SIZE)
AST nodes, whereas minimization made the sizes average at (SIZE) ast nodes.
In the general response, we show what a minimized vs handwritten lens look like.
Below we the difference between a non-minimized title field and a minimized
title field for a work item.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (Id("")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.
Furthermore, when const(s,s) is present, it is converted into Id(s).


- p20: "We adapted these examples" please say mor about how many of the
  examples needed to be adapted (all? a handful?) and how much work it
  was, and how useful the resulting isomorphic lenses were w.r.t the
  original data / how much additional work was needed to adapt them.

See general response.


- p20: "We developed a series of optimizations" - clarify that the
  algorithm already described includes all of these, and what you are
  going to do is disable them, rather than add more optimizations that
  weren't discussed earlier.  Might be helpful to signpost what parts of
  the algorithm are the "basic" algorithm and what parts are optional
  optimizations.

The algorithm described includes all but compositional synthesis.  We don't
include in the formal algorithm the means to which we use previously defined
lenses to synthesize new ones.  The way we do it is we develop equivalence
classes between user defined data types that have lenses, choose a
representative, and transform the user defined data types into that
representative, and convert the strings into elements of that representative
data type.


- p21: Fig 9 "Number of expansions" --> "Number of solutions"??

Number of expansions is the correct phrase.  Figure 9 shows how much random
search through expansions is required before RigidSynth terminates.  In
particular, this shows that full expansion inference performs significantly
better than the partial one that only performs the expansions it knows it must
perform.


- p21.  Also interesting to evaluate would be how time / number of
  solutions varies (e.g. for the full algorithm) as the number of
  examples provided varies.  Is the number of examples small? An active
  approach where the algorithm asks the user for examples might also be
  worth exploring (future work).

The number of examples provided doesn't typically have an impact on runspeed,
only correctness.  The number of valid solutions does vary with the number of
examples provided.  Typically, a small number of examples can greatly reduce the
number of possible solutions (TODO data).  The number of examples is indeed
small, as is shown in Figure 11.  An active approach we agree is an
interesting one, and one we too have considered.


- p24: "because our types do not have full canonical forms" - this is
  the case for the equations presented in the paper, but what about
  e.g. translating to automata and minimizing?

You are correct, regular expressions do have canonical forms in that manner.
We will change the phrasing to more accurately represent our meaning.



Review #18B
===========================================================================
Paper summary
-------------

- However, I’m not sure what exact advantage the proposed approach brings to the
  table. In particular, the user is still required to write exact input and output
  types of the transformations via regular expressions. How hard is to write
  lenses after one has such expressions? ...
  In the reviewer’s opinion, the specification mechanism is not very natural and
  it’s unclear whether it actually simplifies writing bijective transformations.
  This aspect is not evaluated and it would be nice to at least see the difference
  in sizes between the domain/range regexes vs the Boomerang lenses. In general,
  there is no report of the sizes of benchmarks.

See general response.  We also provide data on the sizes below.

---------------------------------------------------
|Test                | SpecSize | LensSize | TODO |
|------------------------------------------|------|
|cust/date-probs     | 85       | 79       |
|cust/cap-prob       | 112      | 108      |
|cust/2-cap-prob     | 122      | 66       |
|ff/extr-fname-err   | 143      | 151      |
|ff/extr-fname       | 149      | 168      |
|ff/extr-quant       | 150      | 145      |
|ff/extr-num         | 171      | 166      |
|aug/activemq        | 194      | 184      |
|cust/bib-prob       | 202      | 181      |
|cust/workitem-probs | 221      | 252      |
|aug/xml-l1          | 235      | 214      |
|cust/addr-probs     | 244      | 239      |
|aug/aptcrngsec      | 265      | 204      |
|aug/alias           | 271      | 210      |
|aug/backuppchosts   | 272      | 249      |
|aug/approx          | 277      | 264      |
|aug/apt-upd-mgr     | 278      | 210      |
|aug/aptsources      | 278      | 238      |
|aug/cachefilesd     | 294      | 233      |
|aug/aptprefs        | 297      | 280      |
|aug/afs-cellalias   | 298      | 246      |
|aug/avahi           | 301      | 234      |
|aug/chrony          | 308      | 289      |
|aug/xml             | 311      | 383      |
|aug/carbon          | 325      | 377      |
|aug/access          | 335      | 253      |
|aug/anacron         | 342      | 315      |
|aug/hosts           | 343      | 328      |
|aug/bootconf        | 350      | 271      |
|aug/auth-keys       | 354      | 424      |
|aug/cgrules         | 378      | 295      |
|aug/cgconfig        | 415      | 347      |
|aug/automaster      | 475      | 377      |
|aug/cron            | 475      | 414      |
|aug/channels        | 512      | 367      |
|aug/automounter     | 535      | 432      |
|aug/aptconf         | 540      | 450      |
|aug/aptconf-l1      | 564      | 503      |
|aug/bbhosts         | 670      | 651      |
--------------------------------------------

We can make sure we can provide at least some description of the sizes of specs
and lenses in the final version of the paper.


- Very limited DSL for transformations. The proposed DSL can only describe
  transformations that use identities and constant functions over input subparts.
  For example, one cannot synthesize the function toUpperCase, which I imagine
  could be useful for the kind of transformations appearing in the motivation.

We can convert between all uppercase and all lowercase.  Quotient lenses can be
used to normalize the data into fully uppercase and fully lowercase data.


- Moreover, the functions can use each word in the input only once: one cannot
  express the transformation abc->abcabc. Most bijective functions I can think of
  (string encoders, compression algorithms, encryption algorithms) require complex
  transformations over the input that go beyond identities. 

See general response for more detailed information about the bijective
restriction.
- On this note, there was a paper this year at PLDI on inverting string encoders
  (Automatic program inversion using symbolic transducers, by Hu et al.), a
  topic which seems very related, but for which I couldn’t find a citation.

Our DSL contains transformations that cannot be expressed by Extended Symbolic
Finite Transducers.  The finite lookahead does not allow for transformations
which swaps data, a common pattern and important pattern in Boomerang lenses. We
will add a citation to this work and a comment detailing the restrictions of
symbolic finite transducers.


- Somewhat limited evaluation. The evaluation is performed on two families of
  benchmarks. The first family is an adaptation of format translation problems
  from Augeas a tool for configuration editing and the second family is from
  FlashFill a tool for synthesis of string transformations. All the benchmarks
  presented are “adaptation” and it’s unclear whether the authors only picked
  benchmarks for which they knew a priori a program in their DSL existed. Based
  on the presented data, I cannot assess how often the presented technique could
  be applied.

See general response.


- Next, the comparison with the tool FlashFill/FlashExtract is somewhat
  confusing. I suspect the authors had to provide some domain and range regular
  expressions for the flash fill benchmarks, but this aspect, which is crucial to
  help the search, is not mentioned.

We do require regular expressions describing the input of FlashFill specs, we
will make sure that is more explicitly stated in the paper.


- What happens if someone provides Sigma* and Sigma* as domains and ranges to
  Optician.

If someone provides Sigma* and Sigma* as domains and ranges to optician it
will merely return the identity between those two.  If a user presents Sigma*
and Sigma* with some examples, we expect it will unroll the iterations until
the number of characters in the largest example has been enumerated, and
return something close to identity, but performing differently on those
examples, and some others to handle the readjustment.

Optician is meant to work on finding mappings between the regular expressions
specified.  It is not intended to find subsets of the provided regular
expressions that can be mapped, as those would be ill-typed programs.


- Also, a better explanation of the
  difference between the DSLs of Lenses and Flash fill is required. For example,
  FlashFill can reverse a string, but the proposed language can’t.

Boomerang doesn't currently provide such capabilities.  However, there is no
technical reason this can't be done by adding in a reverse-and-iterate
operator to Boomerang.  Only a slight adjustment to the synthesis algorithm
would be needed to incorporate this into the algorithm.


- What is the difference in size between the regexes for domain/range spec and
  the full lenses?

On average, the domain and range specs are slightly larger than the lens itself.
See the above chart.  See the general response for a detailed commentary on the
intent of our work.


- What is the difference in size between manually written lenses and synthesized
  ones?

We have not manually written lenses for all our benchmarks.  We find the sizes
are fairly comparable, but the hand-written lenses are more modular: with common
portions taken out and given good names.


- Clarify how the benchmarks were selected and whether any were not selected a
  priori. Especially the flash* ones. Did you omit those that used character
  transformations such as upper-case?

The first three (extr-fname, extr-fname-err and extr-quant) we chose because
they corresponded to the first two examples in the paper.
The problem extr-fname only allowed input paths with a file at the end, where
extr-fname-err provided an error message if no file was present.
The final example, extr-num was used because extracting a phone number was used
as an extended example, so we used it.  We could not find any examples in the
paper which applied a to_upper conversion.


- Can the proposed DSL express any transformation that FlashFill can’t and
  vice-versa?

See the general response.


- P19: maximally factors the concats and ors. What does this mean? Regex
  minimization is a hard problem, what is that one factors exactly? I think it
  would help to show one example of fully synthesized lens in the paper.

Agreed, we will finish our extended example to include a fully synthesized
title field lens.

In the title field, without minimization, the title field transformation would
appear as:

const("<Field Id=2></Field>","")
  | (const("<Field Id=2>","Title: ")
      . Id(text_char)
      . const("","")
      . iterate(const("","") . Id(text_char) . const("",""))
      . const("","")
      . const("</Field>",", "))

With minimization, the title field transformation would appear as:

const("<Field Id=2>","")
  . (Id("")
       | (Id(text_char) . iterate(Id(text_char)) . const("", ",")))
  . const("</Field>",""))

In particular, the useless concatenations of const("","") are removed and
the field boilerplate is removed from being on both sides of the disjunct.
Furthermore, when const(s,s) is present, it is converted into Id(s).

Minor:
- Eval the text says Full synthesized 49 benchmarks, but the plot in fig 8 only
  shows 38/39?

The text is wrong, there are only 39 benchmarks.





Review #18C
===========================================================================

- Overall, this paper looks like a solid and useful contribution to the lens
  literature. However, this reviewer has never used, let alone designed, a lens
  library. As such, I found the paper very hard to read and assess. I would have
  liked to see a clear problem statement (such as an example where it's annoying
  to write the Boomerang code but easy to synthesize the lens using your approach

We provide an extended example in the general response.  We will make the
problem statement more clear in the final version.


- why is there no Boomerang code for your example in Sec. 3?).

We can include example code like this to highlight the frustrations a lens
programmer must encounter while writing their programs.


- It was also not very clear to me what subset of Boomerang your approach
  supports. The introduction says it is a "useful subset of Boomerang" - but
  what does that mean?

The subset our approach supports are the bijective lenses where all regular
expression equivalences used in the typing derivation can be proven with
the star-semiring equivalence rules.  We find this useful in that all lenses can
easily be converted into a bijective lens, and we could not find a lens in
Boomerang or Augeas that requires a courser notion of equivalence than
star-semiring equivalence.


- I was also a bit confused about the preliminaries in Sec. 2. In particular, it
  is not clear whether all or most of those preliminaries are from related work
  (but there are no references) or whether they are contributions of this paper.

The preliminaries are us defining a specific subset of Boomerang that we focus
on.  Boomerang supports a variety of lenses - asymmetric lenses, quotient
lenses, and alignment lenses.  We define which subset of Boomerang we aim to
support.


- p.4, "naively using it in the context of lens synthesis presents several
  problems"? Which problems? At this point I have no clue what "using it" may
  even mean. The "big picture" is not clear at all.

In this context, "using it" refers to allowing retyping on the specified
equivalences.  We are trying to carve out a specific subset of Boomerang that
we want to synthesize, and are not allowing the subset requiring a courser
notion of equivalence to be included. The problems with including full language
equivalence is detailed on pages 8 through 10.


- p. 3, "We have ommitted these theorems for space..." - maybe you mean
  "proofs"?

Correct


- p. 7, "instead of maintaining server code for each endpoint, we envision..."
  but surely the changes to an API involve more than just data format changes.
  For instance, single calls may have to be split into multiple calls. Hence it
  does not seem to be realistic to maintain the old API using _only_ synthesized
  lenses.

    Yes, there are certainly times where more than lenses needs to be added.
    The specific instance of single calls being split into multiple
    calls can be handled by this paradigm if the server allows for batch
    requests.  In particular, APIs of the running example we use, the modern
    format does have batching capabilities,
    https://www.visualstudio.com/en-us/docs/integrate/api/wit/batch .

