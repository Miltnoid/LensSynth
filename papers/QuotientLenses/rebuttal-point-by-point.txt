Thanks for the third review!  Some responses:

---

_The main result is a kind of compositionality theorem: you can compose
QRE lenses freely, and the result is guaranteed to be normalizable.
But I wonder about the lack of compositionality in the construction of
QREs, since the Â· and | combinators cannot be used to combine
arbitrary expressions due to the strong unambiguity constraint
(Section 4.4).  Does your experience say anything about whether this
constraint is a problem in practice?_

  Indeed, unambiguity constraints can be a little fiddly in practice.  As a
  simple example of this, consider writing a regular expression for
  comma-separated lists of strings.  Our first impulse might be to write it
  as

     CSL = anychar+ . ("," . anychar+)*

  (where . is concatenation).  But this is ambiguous, as anychar is a big
  union of a bunch of single characters including comma.  Instead, we need
  to write

     CSL = anycharexceptcomma+ . ("," . anycharexceptcomma+)*

  (assuming anycharexceptcomma denotes a big union of every single character
  string except comma).

  We're not sure whether this should be counted as a "lack of
  compositionality," though.  After all, every type system places
  constraints on how the types of subexpressions must fit together in order
  for a whole expression to be well typed.  (E.g., to type "f a" it must be
  that f has a function type and a has a type that matches the LHS of f's
  type.)  But we don't say that these systems lack compositionality.

---

_you note that your estimate of the burden of writing
canonizers by hand may be inaccurate, as you're actually working
with generated code rather than genuine hand-written code.  Can
you give any estimate of how faithfully the generated code
corresponds to code that might be written by hand?  e.g. whether
the human-written version actually would be smaller, and by how
much?_

  For BS, we think the generated code closely corresponds to code that might be
  written by hand.  We put in some effort to only count common subexpressions once
  (for example, if we define a regular expression and that regular expression
  is used in the generated canonizer, we only count that as one AST node, instead
  of a count corresponding to the size of the regular expression).

  For NS, the generated code probably corresponds less closely to code that
  might be written by hand.  While the original Optician system makes some
  effort to minimize the size of the ASTs, it is imperfect -- e.g., it
  doesn't do common-subexpression elimination.  Furthermore, quotient lenses
  allow for canonizers to be interspersed with other lens combinators.  When
  we move these these canonizers to the edges, additional scaffolding code
  is required, and this gets included in our counts.  We will spell this out
  in more detail in the next draft of the paper.

---

_Fig. 10: What are CS and LS?  Are they supposed to be BS and NS?_

  Right: those should be BS and NS. Due to a version control error, our
  submission had out-of-date graphs.

_Fig. 11: OO, PO, PP are not defined, although I can guess what
they correspond to from the caption.  But what are these 40-50
benchmarks?  and why do the caption and text say "able to
synthesize all quotient lenses in under 10 seconds", while the
graph (b) appears to be still increasing at 15s?_

  Same issue with out-of-date graphs -- sorry.

  We had originally intended to include some additional benchmarks
  corresponding to text transformations from data.gov.  In the end, we felt
  the paper read better without having to explain these additional
  benchmarks, and so removed them from our writeup.  The long-running
  benchmark in the provided graphs was one of these, and it took so long
  because it was a complex tranformation between large formats -- the
  overhead from QREs was comparable to the other benchmarks.

---

_927: I am a bit concerned about "on average" here: is this a
geometric mean?_

  No, we used an arithmetic mean for all these averages.  Using geometric
  means, this would read as follows:

  On average, BS used 38.5% more AST nodes than QS, requiring an average of
  214 more AST nodes. On average, NS used 180% more AST nodes than QS,
  requiring an average of 998 more AST nodes.

