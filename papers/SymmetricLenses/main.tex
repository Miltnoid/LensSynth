\newif\ifdraft\drafttrue  % set true to show comments
%\newif\ifdraft\draftfalse  % set true to show comments
\newif\ifanon\anonfalse    % set true to suppress names, etc.
\newif\iffull\fullfalse   % set true for long version
\newif\ifappendices\appendicestrue

\PassOptionsToPackage{usenames,dvipsnames,svgnames,table}{xcolor}
\documentclass[acmsmall,review,screen,anonymous]{acmart}
\settopmatter{printacmref=false,printccs=false}


\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[capitalise]{cleveref}
\usepackage{amsmath}
\usepackage{makecell}%To keep spacing of text in tables
\usepackage{nccmath}
\usepackage{mathtools}
\usepackage{bussproofs}
\usepackage{varwidth}
\usepackage{amsthm}
\usepackage{csvsimple}
\usepackage{thmtools,thm-restate}
\usepackage{changepage}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multirow,bigdelim}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage{listings}
\usepackage{letltxmacro}
\usepackage{sansmath}
\usepackage{url}
\usepackage{flushend}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage{mathpartir}
\usepackage{empheq}
\usepackage{array}
\usepackage{pgfplots}
\usepackage{stmaryrd}
\usepackage{courier}
\usepackage{qtree}
\usepackage[normalem]{ulem}
\usepackage{relsize}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{tabularx}
\usepackage{stackengine}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{remreset}
\usepackage{tabulary}
\usepackage{xspace}
\usepackage{bbm}

\newtheorem*{theorem*}{Theorem}
\newenvironment{centermath}
 {\begin{center}$\displaystyle}
 {$\end{center}}
\setcellgapes{4pt}%parameter for the spacing

\lstset{ language=Caml, basicstyle=\upshape\sffamily,
keywordstyle=\upshape\sffamily\color{dkpurple}, keepspaces=true,
framexleftmargin=1ex, framexrightmargin=1ex, showstringspaces=true,
commentstyle=\itshape\rmfamily,
emph={rep,iterate,synth,collapse,perm,squash,normalize,using,ins,del,lens,let,get,put,rquot,lquot,id,swap,concat,or,disconnect,merge_left,merge_right,const},
emphstyle=\upshape\sffamily\color{dkpurple}, 
columns=fullflexible,
mathescape, 
xleftmargin=1.5em,
% BCP: I find this distracting:
stringstyle=\sffamily\color{dkblue},
}
\makeatletter
     \let\lst@oldvisiblespace\lst@visiblespace
     \def\lst@visiblespace{\,\lst@oldvisiblespace\,}
\makeatother

\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

\usetikzlibrary{
  er,
  matrix,
  shapes,
  arrows,
  positioning,
  fit,
  calc,
  pgfplots.groupplots,
  arrows.meta
}
\tikzset{>={Latex}}

%%%% Hyperlinks â€“ must come late!
%\usepackage[pdftex,%
%            pdfpagelabels,%
%            linkcolor=blue,%
%            citecolor=blue,%
%            filecolor=blue,%
%            urlcolor=blue]
%           {hyperref}

\input{macros}


\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000

%\setlength{\belowcaptionskip}{-5pt}
%\setlength{\textfloatsep}{15pt}

% Creates a display mode for code in sans serif font
% end

% Macros
  \newcommand{\NameOf}[1]{\CF{#1}}

%%% If you see 'ACMUNKNOWN' in the 'setcopyright' statement below,
%%% please first submit your publishing-rights agreement with ACM (follow link on submission page).
%%% Then please update our instructions page and copy-and-paste the NEW commands into your article.
%%% Please contact us in case of questions; allow up to 10 min for the system to propagate the information.
%%%
%%% The following is specific to POPL'18 and the paper
%%% 'Synthesizing Bijective Lenses'
%%% by Anders Miltner, Kathleen Fisher, Benjamin C. Pierce, David Walker, and Steve Zdancewic.
%%%

  \renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
%\setcopyright{rightsretained}
%\acmPrice{}
%\acmDOI{10.1145/3158089}
%\acmYear{2019}
%\copyrightyear{2019}
%\acmJournal{PACMPL}
%\acmVolume{3}
%\acmNumber{POPL}
%\acmArticle{1}
%\acmMonth{1}
%\startPage{1}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}

  \begin{document}

  %%% The following is specific to POPL'18 and the paper
%%% 'Synthesizing Bijective Lenses'
%%% by Anders Miltner, Kathleen Fisher, Benjamin C. Pierce, David Walker, and Steve Zdancewic.
%%%

%\toappear{}

%\conferenceinfo{POPL '16}{January 20--22, 2016, St. Petersburg, FL, USA} 
%\copyrightyear{2016} 
%\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

%\titlebanner{DRAFT---do not distribute}        % These are ignored unless
%\preprintfooter{DRAFT---do not distribute}   % 'preprint' option specified.

\title{Synthesizing Symmetric Lenses}

\begin{abstract}
%% \saz{This abstract too long and doesn't get to the point quickly enough. We
%%   should tighten it up considerably.}\bcp{+1.  But not just tighten ---
%%   the whole story doesn't feel very compelling.}
%%   Users commonly need to synchronize the data shared between formats, so edits
%%   to the data in one format gets propagated to the data in the other format.
%%   Manually writing the functions for these data synchronizers is tedious and
%%   error prone. Instead of manually writing these synchronizers, bidirectional
%%   languages can be used to express \emph{lenses}, groups of synchronization
%%   functions with guarantees about round-trip behavior. While these bidirectional
%%   languages help make programming these synthesizers less error-prone, they
%%   remain difficult to program in. Synthesizing bidirectional languages allows
%%   users to use lenses without manually programming them. Current
%%   synthesizers work only on the simplest types of lenses, when the two formats
%%   describe exactly the same data; this is often not the case.

%%   Oftentimes, each format may contain information the other lacks. Such
%%   synchronization tasks are described by one of the richest classes of lenses,
%%   symmetric lenses. However, symmetric lenses in their current formulation
%%   require external\bcp{why not ``internal''?} state in the form of a \emph{complement}. This statefulness
%%   makes symmetric lenses both difficult to use and difficult to
%%   synthesize. \bcp{This paragraph seems too dense.}

%%   In this work, we reformulate\bcp{More a restriction than a reformulation.}
%%   symmetric lenses as \emph{simple symmetric 
%%     lenses}. While this formulation is less expressive than symmetric lenses, it
%%   expresses many\bcp{weak} symmetric lenses while requiring \emph{no external state}. We
%%   provide combinators for simple symmetric lenses on string data, and integrate
%%   these combinators into Boomerang\bcp{undefined} while providing full backwards compatibility.

%% \bcp{This bit feels more detailed / technical than needed for an abstract.}
%%   We develop a type-directed synthesis algorithm for generating lenses in this
%%   language from regular expressions describing the data formats. A significant
%%   technical challenge in this work arises from the fact that our target language
%%   permits synchronization between formats that don't have exactly the same data
%%   -- data in one format need not be present in the other format. This gives the
%%   synthesis algorithm much more freedom, as data can be completely unaligned
%%   (edits in one format are never propagated), completely aligned (the formats
%%   are in bijective correspondence), or anywhere in between. Under the assumption
%%   that users typically want to align as much data as possible, we provide an
%%   information theoretic metric for how much data is left unaligned based on the
%%   theory of \emph{stochastic regular expressions}. Furthermore, we use this
%%   metric to develop a greedy synthesis algorithm that tries to minimize
%%   unaligned data. We experimentally demonstrate that our algorithm can
%%   efficiently synthesize simple symmetric lenses on a variety of benchmark
%%   suites consisting of synchronizing file formats from configuration files,
%%   application-specific data storage files, and data cleaning tasks.

{\em Lenses} are programs that can be run both ``front to back'' and ``back
to front,'' allowing data to be transformed in two directions.  Since their
introduction by~\citet{Focal2005-long2}, lenses have been extensively
studied and applied.  Recent work~\cite{optician} has also demonstrated how
techniques from {\em type-directed program synthesis} can be used to
efficiently synthesize a very simple class of lenses---so-called {\em
  bijective lenses} over string data---given a pair of types (regular
expressions) and a small number of examples.

We show how to extend this synthesis algorithm to a much richer class of
lenses, which we call {\em simple symmetric lenses}, including both
bijective lenses and the more widely used ``asymmetric''
lenses~\cite{Focal2005-long2}, as well as a rich subset of the full-blown
``symmetric lenses'' proposed by \citet{symmetric-lenses}.  Simple symmetric
lenses are of independent theoretical interest, being the largest class of
symmetric lenses that do not rely on persistent internal state.

Synthesizing simple symmetric lenses is substantially more challenging that
synthesizing bijective lenses: Since some of the information on each side
can be ``disconnected'' from the other side, there will in general be {\em
  many} lenses that agree with a given example.  To guide the search
process, we use {\em stochastic regular expressions} and ideas from
information theory to estimate the amount of information propagated by a
candidate lens.

We describe an implementation of simple symmetric lenses and our synthesis
procedure as extensions to the Boomerang language~\cite{Boomerang}. We evaluate
its performance on 48 benchmark examples drawn from Flash Fill~\cite{flashfill},
Augeus~\cite{augeas2}, the bidirectional programming literature, and electronic
file format synchronization tasks. Our implementation can synthesize all these
lenses in under 30 seconds.
\end{abstract}

%\begin{CCSXML}
%<ccs2012>
%<concept>
%<concept_id>10011007.10011006.10011050.10011017</concept_id>
%<concept_desc>Software and its engineering~Domain specific languages</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%<concept>
%<concept_id>10011007.10011006.10011066.10011070</concept_id>
%<concept_desc>Software and its engineering~Application specific development environments</concept_desc>
%<concept_significance>300</concept_significance>
%</concept>
%</ccs2012>
%\end{CCSXML}
%
%\ccsdesc[500]{Software and its engineering~Domain specific languages}
%\ccsdesc[300]{Software and its engineering~Application specific development environments}

\ifanon
%\authorinfo{}
%           {}
%           {}
\maketitle
% \vspace*{-6cm}
\else
\author{Anders Miltner}
\affiliation{
  \institution{Princeton University}
  \country{USA}
}
\email{amiltner@cs.princeton.edu}

\author{Solomon Maina}
\affiliation{
  \institution{Princeton University}
  \country{USA}
}
\email{smaina@cis.upenn.edu}

\author{Kathleen Fisher}
\affiliation{
  \institution{Tufts University}
  \country{USA}
}
\email{kfisher@eecs.tufts.edu}

\author{Benjamin C. Pierce}
\affiliation{
  \institution{University of Pennsylvania}
  \country{USA}
}
\email{bcpierce@cis.upenn.edu}

\author{David Walker}
\affiliation{
  \institution{Princeton University}
  \country{USA}
}
\email{dpw@cs.princeton.edu}

\author{Steve Zdancewic}
\affiliation{
  \institution{University of Pennsylvania}
  \country{USA}
}
\email{stevez@cis.upenn.edu}

%\keywords{Bidirectional Programming, Program Synthesis, Type-Directed Synthesis,
%Type Systems}

\maketitle
\fi

% \category{D.3.1}
% {Programming Languages}
% {Formal Definitions and Theory}
% [Semantics]
\ifanon\else
\fi

% begin introduction
\section{Introduction}

\noindent
In the big-data world, similar information is often stored or transmitted in
different formats. For instance, electronic calendars come in iCalendar,
vCalendar, and h-event formats~\cite{calendar-formats}; US taxation data can be
transmitted via Tax XML (used by the US government for e-filing) or TXF (used by
TurboTax)~\cite{tax-formats}; and sewing machines can use embroidery files in
formats with names like PES, DST, and several others~\cite{embroidery-formats}.
\bcp{It would be nice to be able to give a quick example of a truly symmetric
  case---do any of these examples work for that?}\afm{h-event and vCalendar are
  truly symmetric. Even the fields related to location alone are truly
  symmetric (though it is subtle to see this).}

One convenient way to interconvert between these varied data formats is to
use a \emph{lens}~\cite{Focal2005}---a bidirectional program that can
transform data represented in a format $S$ to a format $T$, and vice versa.
offering ``round tripping'' guarantees that help ensure data is not lost or
corrupted as it is transformed back and forth between different
representations.

While domain-specific languages for writing lenses can facilitate building
principled data transformations, \textit{synthesizing} lenses 
can make the task even easier.  Indeed, lens languages offer excellent
targets for synthesis, since their specialized, sub-Turing-complete syntax
and expressive type systems drastically
reduce the space of possible programs, making search-based synthesis easier. 
%
Recent work~\cite{optician} has exploited this
observation, demonstrating that it is feasible to synthesize quite complex
examples, albeit only for a simple form of lenses---so-called bijective
ones. Specifically, given a pair of types describing the intended
source and target formats plus a small number of examples of corresponding
data, the bijective synthesis algorithm developed in these two
papers will find a bijective lens that converts between data stored
in different formats,
such as linux configuration files from different systems that represent the same data in different ways.  
Often, these algorithms can find an appropriate lens
in less than a second without requiring any examples.
%, with just types describing the source and target formats.
% \dpw{I would cite the ICFP paper (cite string:
%   maina+:quotient-synthesis) as to appear but I'm not sure how to do that
%   without possibly violating the spirit of double-blind reviewing. ie, if it
%   hasn't appeared yet, how could we know the content if we aren't the authors?
%   Mentioning it in the 3rd person does not seem to suffice ...} \ksf{The ICFP
%   2018 website lists the paper; I think it is okay to cite it. The reviewer can
%   assume we contacted the authors for a copy. We could ask Stephanie for a
%   ruling if we want to be sure. One of the principles of double blind as adopted
%   by SIGPLAN is not to reduce the quality of the paper; omitting this citation
%   would have that affect.}\bcp{+1}\saz{Stephanie says we should cite it in the
%   third person, even if that's a bit awkward, but otherwise citing it is OK.}
One reason that bijective lens synthesis is so effective, even relative to successful
synthesis projects in other domains, is that there are not very
many bijections between related data formats (unless the
same kind of data appears in the two formats many times). 
Hence, if the synthesis algorithm can
find any bijection at all, then it is very likely to find the one the
user wants.


However, there is a price for narrowing the synthesis domain so
dramatically: Many real data formats are almost, but not quite,
bijections. More often two related data formats have some data in
common, but also contain some differences. For instance, two related
tables might share four of five columns, but each has a different
fifth column. Alternately, one ad hoc configuration file might include
some file-specific meta data, such as a date, a time or a reference
number, whereas the other does not. Indeed of the 48 benchmark problems
described in Section \ref{sec:evaluation}, all of the benchmarks
taken from Flash Fill~\cite{flashfill} and many of the benchmarks that
synchronize between two ad hoc file formats have this 
characteristic, 13 benchmarks in total. Consequently, tools that search
only for strict bijections are often not applicable in practice.

A natural way to expand the scope of such tools is to consider a more
expressive language of lenses.  For example, \emph{symmetric
lenses}~\cite{symmetric-lenses} encompass a broad collection of bidirectional
transformations that include bijections as well as more flexibile transformations that
allow each side to retain information not present
in the other.  If $\ell$ is a symmetric lens between formats $S$ and
$T$, then $\ell$  can transform data from $S$ to $T$ or vice versa
equally well.  A user would typically 
run $\ell$ in the forwards direction (from $S$ to $T$) when a user updates
a string $s \in S$ to propagate those updates to $T$.
However, because data in format $S$ may contain some information not present in format $T$,
the $S \rightarrow T$ transformation takes
\emph{both} the edited string $s \in S$ and a string $t \in T$ as arguments.
Inuitively, the lens extracts the data ``shared'' between the two
formats from $s$
and uses $t$ to supply any missing information.
% required by $T$ that is missing
%as it generates an output $t'$.  If $s$ is missing information, the transformation should
%extract the missing components from $t$.

Initially, we hypothesized that extending the synthesis algorithms
of Miltner \ETAL~\cite{optician} to operate over symmetric rather than
bijective lenses
would be relatively straightforward:  Simply replace the bijective
combinators with symmetric ones 
and search using similar heuristics.  However, 
this na\"ive approach runs into two difficulties. 

The first difficulty is pragmatic. Symmetric lenses usually operate
over three structures: the source $S$, the target $T$ and a complement
$C$ that contains the information not
present in either $S$ or $T$~\cite{symmetric-lenses}. Logistically, the complement must be stored
somewhere and managed. More significantly, complements complicate synthesis
specifications.
Users can no longer just give examples of source and target
pairings; instead they must also indicate how to manage the 
``hidden state.'' To avoid such complexities, we define a new variant
of symmetric lenses: \emph{simple symmetric lenses}. At the price
of some expressiveness, these new lenses do not require complements.
%only the usual source and target.
%
To characterize their expressive power,
we prove that simple symmetric lenses include all (and only)
those symmetric lenses that satisfy an intuitive property called
\emph{forgetfulness}.
%, which we define in Section~\ref{sec:relationship}.
Intuitively, simple symmetric lenses are the complete set of symmetric
lenses that do not require external ``memory'' to recover data from past
instances of $S$ or $T$ when making a round trip. They only need the most
recent instance. 
We justify this loss of expressiveness pragmatically. 
We extend Boomerang~\cite{Boomerang} with simple symmetric lenses and
successfully use them on a range of real-world applications, showing
in the process that simple symmetric lenses integrate smoothly with 
other advanced lenses in Boomerang, including quotient
lenses~\cite{quotientlenses} and matching lenses~\cite{matchinglenses}. 

The second difficulty with synthesizing symmetric lenses is more
fundamental: While the number of bijective lenses between two
related formats is often tiny, the number of simple symmetric lenses is much larger. In
practice, the difference in cardinality means that when a search algorithm
returns the first bijective lens it finds, that lens has a good chance of being
the desired lens. In contrast, and to our initial surprise, experiments showed
that if a na\"ive search algorithm selects the first simple symmetric lens it
finds, it is typically \emph{not} the desired lens.  The flexibility
that such lenses provide in eliding information 
generates an explosion of possible transformations. To disambiguate
between the many possible lenses, we need new 
principles for identifying the ``likely'' ones, and we need new
algorithms guided by those principles to
search the space of program transformations.


To overcome this second difficulty, we turn to information theory 
to characterize the likely and unlikely lenses. 
We consider a ``likely'' lens to be one that propagates a lot of
information from source to 
target and vice versa. Conversely, an ``unlikely'' lens requires a
large amount of additional information to recover the target given a
source and vice versa.  
This categorization follows from the intuition
that users will typically want to synchronise formats with lots
of shared information, and so lenses that preserve 
more information are preferable.
To implement this
intuition, we turn to \emph{stochastic regular expressions}
(SREs)~\cite{stoch-rnn,stoch-def}, which simultaneously define a set of strings \`a la
regular expressions and a probability distribution over those
strings.  Using this information, we can calculate the shared
information content of two formats and our measure of
likeliness. 


\begin{figure}
  \includegraphics[width=.5\textwidth]{high-level-algorithm.pdf}
  \caption{Schematic diagram for the simple symmetric lens synthesis algorithm.
    The user provides regular expressions \BRegex and \BRegexAlt and a set of
    examples \Examples{} as input. \Expand first converts \BRegex and \BRegexAlt
    to stochastic regular expressions \Regex and \RegexAlt with default
    probabilities. It then finds pairs of stochastic regular expressions
    equivalent to \Regex and \RegexAlt and iteratively proposes them to
    \GreedySynth. \GreedySynth finds a lens typed between the supplied SREs.
    When the algorithm determines it has found a likely lens, it returns it.}
  \label{fig:high-level-algorithm}
\end{figure}

With simple symmetric lenses and our SRE-based likeliness measure in
hand, we develop a new algorithm for synthesizing likely lenses.
At its core, the algorithm performs a type-directed search between the 
descriptions of the source and target formats, measuring success using
the likeliness measure.
However, regular expressions enjoy a rich algebraic structure, meaning
there are infinitely many regular expressions equivalent to the
original pair, and the lens returned by a type-directed search depends
upon the chosen representation. 
To tame this complexity, we divide the synthesis algorithm into two communicating
search procedures (Figure~\ref{fig:high-level-algorithm}), following
earlier work~\cite{optician}.
The first algorithm, \Expand, uses rewriting rules to iteratively
propose new pairs of stochastic regular expressions equivalent to the
original pair.
The second algorithm, \GreedySynth, takes a pair of such SREs as input
and uses a greedy, type-directed algoithm to find a simple symmetric
lens between them, returning the lens and its likelihood score
to \Expand.  The algorithm terminates when the likilihood score of the
best lens found so far compared with 
the complexity of newly generated SREs 
suggests that further searching is unlikely to be fruitful. 

%%
%%searches for two \emph{related} SREs $S'$ and $T'$ that are
%%\emph{compatible} (a heuristic that estimates the likelihood our second
%%algorithm will succeed). $S'$ and $T'$ are related in the sense that they define
%%the same regular sets as $\BRegex$ and $\BRegexAlt$ (respectively) and the distribution of
%%strings is identical. Indeed, we guarantee these two properties by implementing
%%a search procedure that obeys the star semi-ring axioms of regular expression
%%equivalence, and which we show does not alter the probability distributions of
%%the languages.

%%Given the two compatible SREs, \GreedySynth uses a greedy, type-directed
%%algorithm find a likely lens between them. If algorithm estimates that the lens
%%it has discovered is more likely than any future lens it can possibly find, the
%%search terminates. Otherwise, this lens is stored away (if it is the best found
%%so far) and the search continues with \Expand again.

We implemented the \GreedySynth and \Expand algorithms and evaluated their
effectiveness at synthesizing lenses on a benchmark suite of 48 problems,
including data cleaning tasks taken from Flash Fill~\cite{gulwani-popl-2014},
view maintenance tasks taken from Augeas~\cite{Augeas}, and ad hoc format
synchronization tasks taken from a variety of other locations\footnote{The
  majority of these format synchronization tasks were taken from the
  bidirectional programming literature.}.

In summary, our contributions are:\bcp{The section references do not proceed
  in order, so this doesn't work very well as an outline of the paper.
  Should we try to reorder the contributions?  Write a separate outline?
  Live with it as-is?}\afm{Personally, I don't see it as a problem.  It's nice
  when the contributions mimic the paper, I am not jarred when they don't.}
\begin{itemize}
\item We define {\em simple symmetric lenses}, with the
  the useful property that they do not maintain any hidden state
  (\S\ref{sec:overview}).  
  We present a collection of combinators for defining these lenses and
  describe how to 
  calculate their likelihoods (\S\ref{sec:ssl}). 
\item  We show that simple symmetric lenses
  fall between asymmetric lenses~\cite{Focal2005-long2} and full
  symmetric lenses~\cite{symmetric-lenses} in expressiveness
  (\S\ref{sec:related}).  We further show that the class of simple
  lenses can be characterized semantically as the subset of full
  symmetric lenses for which a simple ``forgetfulness'' property holds.
\item We show how to synthesize simple symmetric lenses (including all
  asymmetric lenses as a special case), using a novel application of stochastic
  regular expressions to guide the search process (\S\ref{sec:synthesis}). 
  To support that effort, we show that the star semi-ring equivalences on
  regular 
  expressions remain valid when applied to stochastic regular
  expressions, preserving the probability distributions as well as the languages
  (\S\ref{sec:sre}).
\item We extend the Boomerang implementation with simple symmetric lenses,
  demonstrating that they integrate smoothly with 
  other lens extensions such as quotient lenses~\cite{quotientlenses} and matching
  lenses~\cite{matchinglenses}.  We evaluate our
  implementation on a set of 48 lens synthesis benchmarks drawn from
  data cleaning, view maintenance, 
  and file synchronization tasks.  We demonstrate that we can
  synthesize simple symmetric lenses for all of the benchmarks in
  under 30 seconds (\S\ref{sec:evaluation}). 
\end{itemize}
We close with a discussion of related work (\S\ref{sec:related}) and
concluding thoughts (\S\ref{sec:conc}).

%Such synthesis efforts
%make it easier to use lenses as programmers do not need to be familiar with the syntax
%of a new language, and even advanced users can benefit from the productivity boost.

\noindent

% state of the world
% end introduction

% begin overview
\section{Overview}
\label{sec:overview}

\begin{figure}
  % https://tex.stackexchange.com/questions/168741/showing-two-listings-in-a-table-side-by-side
  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}[
stringstyle=\upshape\sffamily
]
Jane Doe: 38000
John Public: 37500
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingA}{\box0}

  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}[
stringstyle=\upshape\sffamily
]
Name,Company
Jane Doe,Healthcare Inc.
John Public,Insurance Co.
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingB}{\box0}

  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}
let salary = number | "unk"
let emp_salary = name . " " . name . ": " salary
let emp_salaries = "" | emp_salary . ("\n" emp_salary)$^*$
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingC}{\box0}

  \setbox0=\hbox{%
    \begin{minipage}{3.5in}
\begin{lstlisting}
let company = (name . ("Co." | "Inc." | "Ltd.")) | "UNK" in
let emp_ins = name . " " . name "," company in
let header = "Name,Company" in
let emp_insurance = header . ("\n" . emp_ins)$^*$
\end{lstlisting}
    \end{minipage}
  }
  \savestack{\listingD}{\box0}
  
  \centering
  \resizebox{\columnwidth}{!}{%
    \begin{tabular}{|>{\columncolor{vlightyellow}}c|>{\columncolor{vlightgreen}}c|}
      \hline
      \texttt{company.mgmt} data file & \texttt{company.hr} data file \\
      \hline
      \listingA & \listingB \\
      \hline
      \cellcolor{lightyellow}\texttt{company.mgmt} regular expression & 
      \cellcolor{lightgreen}\texttt{company.hr}  regular expression\\
      \hline
      \cellcolor{lightyellow}\listingC & \cellcolor{lightgreen}\listingD \\
      \hline
    \end{tabular}
  }
  \caption{Hypothetical example data files and corresponding regular expressions
  used by management and HR at a US company to represent employee salaries and health
  insurance providers, respectively. }  
  \label{fig:minimized-representations}
\end{figure}

In this section, we give an overview of simple symmetric lenses and our
synthesis algorithm for them, using a simplified example drawn from a hypothetical
U.S. company. In this company, management and human resources (HR) store
information about employees in separate text files: management records the
names of 
employees and their salaries while HR stores the names of employees and their
health insurance providers. Figure~\ref{fig:minimized-representations} gives
examples of the two file formats and regular expressions describing them. 

The company uses a simple symmetric lens to keep these files
synchronized. If management adds a new employee, ``Chris Roe: 32500'', a lens
adds the corresponding entry ``Chris Roe, UNK'' to HR's file. The sentinel value
``UNK'' represents the fact that the employee's insurance company is currently
unknown. A similar update happens if HR adds a new employee before management,
in which case the sentinel value ``unk'' reflects the unknown salary information
Furthermore, if HR corrects an error in an employee's name, say changing ``John
Public'' to ``Jon Public'', the lens mirrors that name change in management's
file. Not all the data is mirrored, however. The management file is not updated
in response to insurance changes, and the HR file is oblivious to salary
changes. Simple symmetric lenses are appropriate for keeping these two files
synchronized because the files have a mix of shared and unshared information.

%Consider the previously
%described goal of keeping Linux cron jobs (crontab) and Windows Scheduled Tasks
%(scheduled.job) synchronized. These are each formats specifying when to run
%recurring tasks. For the sake of exposition, we use simplified versions crontab
%and scheduled.job formats, with examples and corresponding regular expressions
%shown in Figure~\ref{fig:minimized-representations}. Each file contains a list
%of tasks set to run at specific times every hour. In both formats, users
%can either provide specific minutes at which they want the program to run, or they
%can specify that the program should run at every minute.
%
%We wish for the jobs to be synchronized across our Windows and Linux devices.
%However, the commands that need to be run are typically different for each
%device. Paths are different in Windows and Linux, and, while there is typically a
%Windows equvialent for a Linux command, that equivalent command is not always
%named the same thing. So, while we want to be able to have the same number of
%commands, with the commands running at the same times, we don't want to
%align the actual commands that are run.

\subsection{Simple Symmetric Lenses}
A simple symmetric lens between formats described by types $X$ and $Y$ is
defined by four functions that collectively satisfy four ``round-tripping'' laws: 

%\begin{enumerate}
%\item $\CreateR \OfType \Regex \rightarrow \RegexAlt$
%\item $\CreateL \OfType \RegexAlt \rightarrow \Regex$
%\item $\PutR \OfType \Regex \rightarrow \RegexAlt \rightarrow \RegexAlt$
%\item $\PutL \OfType \RegexAlt \rightarrow \Regex \rightarrow \Regex$
%\end{enumerate}
\vskip 1.5ex
\begin{minipage}[c]{.3\textwidth}
\begin{gather}
 \tag{1}
 \mbox{$\CreateR \OfType X \rightarrow Y$}\\
 \tag{2}
 \mbox{$\CreateL \OfType Y \rightarrow X$}\\
 \tag{3}
 \mbox{$\PutR \OfType X \rightarrow Y \rightarrow Y$}\\
 \tag{4}
 \mbox{$\PutL \OfType Y \rightarrow X \rightarrow X$}
\end{gather} 
\end{minipage} 
\begin{minipage}[c]{.6\textwidth}
\begin{align}
  \tag{\CreatePutRL}
  \PutLOf{(\CreateROf{x})}{x} = x\\
  \tag{\CreatePutLR}
  \PutROf{(\CreateLOf{y})}{y} = y\\
  \tag{\PutRL}
  \PutLOf{(\PutROf{x}{y})}{x} = x\\
  \tag{\PutLR}
  \PutROf{(\PutLOf{y}{x})}{y} = y
\end{align}
\end{minipage} 
\vskip 1ex
\noindent
The two \KW{create} functions propagate shared information and fill in default
values when introducing new data. (\EG, the ``unk'' salary entry is added
alongside the name to the management file when HR inserts a new employee). The
two \KW{put} functions propagate edits from one format to the other by
combining the change from one file with the previous value from the other file.
The round-tripping laws guarantee that if two formats are already synchronized,
\KW{put}s merely return the second argument, unchanged.
This definition differs from formulations of classic symmetric lenses,
which require a \emph{complement} but only two functions.  These two
functions combine complements with edited data to create updated
complements and synchronized data, one function for each direction.
We provide a detailed comparison to classic symmetric lenses
in \S\ref{sec:relationship}.

%%For synchronization, when the original company.hr or company.mgmt
%%file is created, a synchronized file of the other form is created
%%from it with $\CreateR$ or $\CreateL$ (depending on which file was
%%initially created). On future edits, changes are made with the puts,
%%a \PutR would propagate the shared information from the company.hr
%%file, and knit it together with the information specific to the company.mgmt file.


\subsection{Simple Symmetric Lens Combinators}




Generally, we do not expect programmers to define simple symmetric lenses by
writing the four functions by hand and showing they satisfy the round-tripping
laws. Instead, we provide simple symmetric lens combinators to build up the
requisite lenses from simpler ones. We focus on combinators for defining
lenses between string data formats.

We use regular expressions to denote the types of data formats, and we impose a
typing discipline on our lenses. Specifically, if $\BRegex$ and $\BRegexAlt$ are
regular expressions\footnote{We use \BRegex and \BRegexAlt to denote regular
  expressions. We later use the plain nonterminals \Regex and \RegexAlt for
  stochastic regular expressions.}, then the notation
\lstinline{$\Lens$ : $\BRegex \Leftrightarrow \BRegexAlt$} indicates that $\Lens$ is a simple symmetric lens between $\LanguageOf{\BRegex}$ and $\LanguageOf{\BRegexAlt}$. When clear from context, we use the term \textit{lens} to denote a simple symmetric lens.

We briefly explain a selection of these
combinators by using them to define a lens between the two employee data formats
in Figure~\ref{fig:minimized-representations}. The finished lens, which appears
in Figure~\ref{fig:example_lens}, has the type
\lstinline{emp_salaries} $\Leftrightarrow$
\lstinline{emp_insurance}, where
\lstinline{emp_salaries} and
\lstinline{emp_insurance} are regular expressions defined in Figure~\ref{fig:minimized-representations}.


The simplest combinator is the identity lens \IdentityLens, which takes as an
argument a regular expression $\BRegex$ and performs an identity mapping on data
matching $\BRegex$. The identity lens fully connects the
corresponding data in the two formats: when one format is
updated, the other format gets the exact same value. In our example,
when a \lstinline{name} is updated in one file, the identity lens ensures it is
also updated in the other file. In this manner, both the \CreateR and \CreateL
functions are the identity function ($\CreateR \App s = s$), and the put
functions merely return the first argument ($\PutROf{s_1}{s_2} = s_2$).

%
\begin{lstlisting}
id(name) : name $\Leftrightarrow$ name
\end{lstlisting}
%

In contrast to the identity lens, the \Disconnect lens does not propagate edits
from one format to the other. The disconnect lens takes four arguments: two
regular expressions and two strings. The regular expressions specify the formats
of the corresponding data on the two sides while the strings provide default
values. On creates, the input values are thrown away, and default values are
returned ($\CreateROf{\String} =
\lstinline{"unk"}$), and on puts, the second argument is used, and the first is
thrown away ($\PutROf{\String}{\StringAlt} = \StringAlt$). In our extended
example, the \lstinline{salary} field is only present in management files,
so we use the disconnect lens to ensure salary edits do not cause updates to the
HR file.
The defaults are strings that indicate the information is missing.
%
\begin{lstlisting}
disconnect(salary, "", "unk", "") : salary $\Leftrightarrow$ company
\end{lstlisting}
%
The insert \lstinline{ins} and delete \lstinline{del} lenses are
syntactic sugar for uses of the disconnect lens in which a string
constant is omitted entirely from the source and target formats,
respectively.
\begin{lstlisting}
 ins($t$) = disconnect("", $t$, "", $t$)
 del($s$) = disconnect($s$, "", $s$, "")
\end{lstlisting}

Finally, there are a number of standard lenses that compositionally construct
more complex lenses from simpler ones. These combinators include concatenation
($\ConcatLensOf{\Lens_1}{\Lens_2}$ or $\Lens_1 . \Lens_2$), variation
($\OrLensOf{\Lens_1}{\Lens_2}$), and iteration ($\IterateLensOf{\Lens}$).  For example;
%
\begin{lstlisting}
id(name) . ins(",") . id(name) . del(": ") . ins(",")
\end{lstlisting}
% concat(ins(header),employees_lens) : emp_salaries $\Leftrightarrow$ emp_insurance
%
appears in the definition of the \lstinline{name_lens} in our running example.
%\ksf{I don't think this example is necessary.}
%Data can also appear in multiple forms. For example,
%a list of employees with insurance information can either be empty or
%be a sequence of employee/insurance records: \ksf{This example is
%vacuous as you could eliminate the or in favor of the *.  Do somethign
%else to introduce or?}
%
%\begin{lstlisting}
%or(id(""),employees_lens) : emp_salaries $\Leftrightarrow$ "" | ("\n" emp_ins) . ("\n" emp_ins)*
%\end{lstlisting}
The \IterateLens lens also appears in our running example, where it
synchronizes data for a list of employees when given a
lens \lstinline{employee_lens} that synchronizes  data for a single employee:
%
\begin{lstlisting}
iterate(id("\n") . employee_lens) : ("\n" . emp_salary)$^*$ $\Leftrightarrow$ ("\n" . emp_ins)$^*$
\end{lstlisting}
%

\begin{figure}
\begin{lstlisting}
let name_lens = id(name) . ins(",") . id(name) . del(": ") . ins(",") in
let employee_lens = name_lens . disconnect(salary,"","unk","") 
                                                    . disconnect("",company,"","UNK") in
let employees_lens = ins("\n") . employee_lens . iterate(id("\n") . employee_lens) in
ins(header) . employees_lens : emp_salaries $\Leftrightarrow$ emp_insurance
\end{lstlisting}
%\ksf{I don't think this is necesssary.}
%let emp_lens = or(id(""),employees_lens) in
  \caption{A lens, written in our language for defining simple symmetric lenses
    on string data, that synchronizes management and HR employee files.
    Note that we can annotate lenses with types, ensuring that the lens
    operates on strings that match the regular expressions. In this work, we
    \textit{synthesize} the lens itself from such regular expressions.}
  \label{fig:example_lens}
\end{figure}

% Using these combinators, we can build up a lens that synchronizes
% management and HR employee files. 


We provide typing rules for each of the simple symmetric combinators, most of
which are syntax directed. However, regular expressions have a number of
equivalences on them, and sometimes we must convert one regular expression type
to another, equivalent, regular expression type. Our typing rules include type
equivalence, so if a lens has type $\BRegex \Leftrightarrow \BRegexAlt$, then it
is also has type $\BRegex' \Leftrightarrow \BRegexAlt'$, where $\BRegex$ is
equivalent to $\BRegex'$, and $\BRegexAlt$ is equivalent to $\BRegexAlt'$. The
flexibility this type equivalence rule provides is useful when a different
representation of a regular expression would facilitate synthesis.

%%\ksf{Do we need to use
%%type equivalence to type the employee example?  If so, perhaps we
%%should explain her}
%%
%%This lens uses one typing rule not previously
%%mentioned: type equivalence. While \lstinline{scheduled_job} is a equivalent to
%%a regular expression with an outermost disjunction, it is not syntactically
%%equivalent to one. Without type equivalence, the provided lens wouldn't actually
%%be well-typed, but type equivalence states that if a lens is typed between a
%%pair of regular expressions, it is also typed between an equivalent pair.


\subsection{Synthesizing Simple Symmetric Lenses}

While our example is relatively simple for demonstration, writing such lenses
for real-world formats is quite difficult, as these formats can be large and
represent data in complex and unintuitive ways. To alleviate the difficulty of
manually writing simple symmetric lenses, we wish to synthesize them instead.
Given a pair of regular expressions and a set of input-output examples, we want
to find a simple symmetric lens that is typed by the regular expression pair and
satisfies the input/output examples. We call such a lens a \emph{satisfying
  lens}. In our running example, we wish to synthesize a lens between
\lstinline{emp_salaries} and \lstinline{emp_insurance}, using as an input-output
example the data in Figure~\ref{fig:minimized-representations}. The algorithm
uses such examples to find suitable defaults for \Disconnect lenses and to
figure out how to match data that could be synchronised in multiple ways.

A challenge is that the simple symmetric lens combinators permit many
well-typed lenses
between a given pair of regular expressions. For example, 
Figure~\ref{fig:example_lens} gives one possible lens between regular
expressions  \lstinline{emp_salaries} and \lstinline{emp_insurance},
but 
%
\begin{lstlisting}
disconnect(emp_salaries,emp_insurance,rep(emp_salaries),rep(emp_insurance))
\end{lstlisting}
%
is another valid lens (where \lstinline{rep($\BRegex$)} denotes some string in the
language of $\BRegex$). Furthermore, adding the input-output example in
Figure~\ref{fig:minimized-representations} 
helps, but only a little: It may, in general, require {\em many} examples to rule
out all possible occurrences of nested \Disconnect lenses,
particularly in complex formats. 
%\ksf{I don't understand the following.  We shouldn't explain the issue in
%terms of \PutR and \PutL as we are focused on the combinators rather
%than the raw functions.}
%The default strings given to \Disconnect merely need to be the strings
%in the input-output examples, and the lens will still satisfy the
%specification.  While the disconnect lens is prohibited by two
%examples, or by a carefully chosen input-output example on \PutR
%or \PutL, this problem continues presenting itself for the sublenses,
%and is highlighted even more on larger formats.
While we could ask programmers to provide detailed and precise specifications
for their synthesis tasks, we would prefer an algorithm that can intelligently
choose a lens despite the underspecification. Instead of merely finding
\emph{any} satisfying lens, we wish to synthesize a satisfying lens that is
likely to please the user.

But what is a ``likely'' satisfying lens? We propose the following
heuristic: A satisfying
lens is more likely if it connects more data between the two
formats, \EG, by using an identity rather than a disconnect lens.  The
likeliest satisfying lenses would connect as much data as
possible. More formally, we define the likelihood of a
satisfying lens as the expected number of bits required to recover
data in one format from synchronized data in the other.  Higher
likelihoods correspond to lower numbers of bits. In more
detail, we say that two strings $s$ and $t$ are \emph{synchronized
according to lens $l$} if $l.\PutR\ s\ t = t$ and $l.\PutL\ t\ s = s$.\footnote{
The notation $l.\PutR$ extracts the \PutR function from simple
symmetric lens $l$; similarly for \PutL.}  We say that we
can \emph{recover} $s$ from $t$ using bits $b$ and lens $l$ if we can
reconstruct $s$ from $t$, $b$, and $l$.  For example, given
the \IdentityLens{} lens, we can recover $s$ from $t$ using no bits
because, in this case, $s$ is just $t$.  In contrast, given
the \Disconnect{} lens, we need enough bits to fully encode $s$ in
order to recover it from $t$ because $t$ contains no useful
information.  This calculation shows that if both \IdentityLens{}
and \Disconnect{} are satisfying lenses, then \IdentityLens{} is more
likely.

The expected number of bits required to recover data is the well-known information-theoretic concept 
of the \emph{entropy} of the data~\cite{Shannon1948}.
Calculating entropy requires a probability distribution over the
space of possible values for the data. Specifically, given a set $S$ and a
probability distribution $P \OfType S \rightarrow \Reals$ over $S$, the
entropy is $-\Sigma_{s\in  S}P(s)\Log_2P(s)$.

In our setting, we already have a way of expressing sets of data:
regular expressions.  What we need is a way to express probability
distributions over that data.
To that end, we adopt \emph{stochastic regular expressions}~\cite{stoch-def,stoch-rnn} (SREs), 
which are regular expressions in which each operator is annotated with a
probability.  A stochastic regular expression
specifies both a set of strings and a probability
distribution over that set, enabling us to calculate the
entropy of the SRE. 

%% \ksf{Consider integrating more detailed discussion of SREs that was
%%formerly in the intro.  Commented out here for now.}
%%To implement this intuition, we turn to \emph{stochastic regular
%%expressions} (SREs). Stochastic 
%%regular expressions define a set of strings, as do ordinary regular expressions,
%%but they also provide the expected distribution of strings within that set. Such
%%distributions allow us to compute the amount of information gained when
%%presented an element of the set. For example, the language of the SRE
%%$\lstinline{"a"} |_{0.5}
%%\lstinline{"b"}$ contains two elements (the strings \lstinline{"a"} and \lstinline{"b"}).
%%The probability 0.5 annotating the union indicates that both elements are
%%equally likely to appear. Consequently, if we observe an element of that
%%language (either \lstinline{"a"} or
%%\lstinline{"b"}), we will gain one bit of information. Said another way, one bit, together with
%%the SRE, suffices to recover the string in question. Interestingly, if the
%%probability annotation were anything but 0.5, the expected information content
%%(or entropy) would actually be less than 1 (given a stream of such choices, on
%%average we could encode the the contents of stream in fewer bits than the the
%%number of choices present). On the other hand, consider the language of the SRE
%%\lstinline{c}. It contains just one element (the string $c$). If we observe that
%%our algorithm generates $\lstinline{"c"}$, we gain zero bits of information ---
%%the string was already determined. Using this foundation, a lens $\Lens$ that
%%synchronizes data between $\Regex$ and $\RegexAlt$ is ``likely,''
%%in a technical sense, if given a string $s$ in the source $S$, very little information
%%is needed to determine which synchronized string $t$ is present in the target
%%$T$.


This infrastructure gives us what we need to find likely satisfying lenses from
a collection of satisfying lenses. All such lenses must synchronize data between
the same two SREs $\Regex$ and $\RegexAlt$. For any such lens $\Lens$, we can
calculate the expected number of bits required to recover a string $t$ in
$\LanguageOf{\RegexAlt}$ from a synchronized string $s$ in
$\LanguageOf{\Regex}$. This expectation is the \emph{conditional entropy of
  $\Regex$ given $\RegexAlt$ and $\Lens$}, formally $\sum_{s \in
  \Regex}\ProbabilityOf{\Regex}{s}\EntropyOf{\SetOf{t \SuchThat
    \Lens.\PutROf{s}{t} = t}}$. The likelihood we assign to $\Lens$ is the sum
of the conditional entropy of $\Regex$ given $\RegexAlt$ and $\Lens$ and the
conditional entropy of $\RegexAlt$ given $\Regex$ and $\Lens$. This metric
assigns higher entropy (or cost) to lenses where knowing the string
on one side 
provides little information about the string on the other side. 
It assigns zero entropy to bijections because given a string $s \in \Regex$,
the bijection exactly determines
the corresponding string in 
$\RegexAlt$.

%%As a further example, consider the trivial lens
%%\lstinline{disc(emp_salary,emp_row,rep(emp_salary),rep(emp_row))}. As this is
%%the disconnect lens, the cost of each side is the entropy of the data format, so
%%the total cost is $\EntropyOf{\lstinline{emp_salary} } +
%%\EntropyOf{\lstinline{emp_row}}$. The lens \lstinline{emp_salary} contains strictly more
%%information than $\EntropyOf{\lstinline{": " . salary}}$, and
%%\lstinline{emp_row} contains strictly more information than
%%\EntropyOf{\lstinline{": " . salary}}, so by our metric
%%\lstinline{single_emp_map} is preferable to the disconnect lens.


To obtain SREs from the plain regular expressions that we expect users to
supply, we use a heuristic that attempts to assign probability annotations that
give each string in the language equal probablity. Our algorithm could also take
as input a stochastic regular expression rather than a plain one,
which would allow
the user to specify a data-specific probability distribution, either manually
calculated or inferred from a large dataset. We found our heuristic
works well in practice, so we have not explored these options.

Now that we have a way to calculate likelihood, we need a way to search for
likely lenses. Previous work on
synthesis~\cite{augustsson-2004,osera+:pldi15,feser-pldi-2015,frankle+:popl16}
has shown that we can use types to dramatically restrict the search space and
improve the effectiveness of synthesis. In our setting, types are pairs of
stochastic regular expressions where each regular expression is semantically
equal to infinitely many others. We follow existing work on bidirectional
program synthesis, and split our algorithm into two communicating
synthesizers~\cite{maina+:quotient-synthesis}. The first synthesizer, \Expand,
navigates the space of semantically equivalent regular expressions by applying
rewrite rules that preserve both the semantics and the probability distributions
of those stochastic regular expressions. Our algorithm ranks pairs of stochastic
regular expressions by the number of rewrite rule applications required to
obtain the pair from the stochastic regular expressions given as input. It
passes the pairs off to the second synthesizer, \GreedySynth, in rank order with
the smallest first.

At a high level, \GreedySynth looks for lenses between a given pair of
stochastic regular expressions $\Regex$ and $\RegexAlt$ that have the highest
likelihood by performing a type-directed search. In more detail, \GreedySynth
first normalizes the stochastic regular expressions provided by \Expand into
\emph{stochastic DNF regular expressions}. These stochastic DNF regular
expressions are, intuitively, stochastic regular expressions with disjunctions
distributed over concatenations, where associativity information has been
removed. Then, \GreedySynth uses the syntax of these n-ary DNF regular
expressions to find highly normalized lenses, in a form we call \emph{simple
  symmetric n-ary DNF lenses}. These lenses include neither a composition
operator nor a type equivalence rule. These restrictions mean that each simple
symmetric n-ary DNF lens is typed by a single pair of stochastic n-ary DNF
regular expressions and \GreedySynth's search space for a given pair of regular
expressions is finite. The variations that \GreedySynth considers include
choosing between \IdentityLens{} and \Disconnect lenses and deciding how to
match multiple occurrences of the same kind of data, \EG, the two occurrences of
\lstinline{name} in the management and HR data formats (we want to map first
names to first names and last names to last names). \GreedySynth
converts yields a simple symmetric lens by converting the n-ary
forms into the binary forms provided in the surface language.

As an example of the partnership between \Expand and \GreedySynth,
consider the lens shown in Figure~\ref{fig:example_lens}. 
Inferring this lens requires \Expand to use a star semiring axiom to
rewrite the regular expression \lstinline{("\n" . emp_salary)$^*$} within
\lstinline{emp_salaries} into 
\lstinline{"" | (("\n" . emp_salary). ("\n" . emp_salary)$^*$)} 
so that \GreedySynth can find the appropriate lens.  

Our strategy of communicating synthesizers gives us a way to
enumerate pairs of stochastic regular expressions of increasing
rank and to efficiently search through them, but it poses a
problem: when do we stop? We may have found a promising lens
between a pair of stochastic regular expressions, but a different 
pair we haven't yet discovered may give rise to an even better lens. 
Or, we may have found a promising lens between a given pair of
stochastic regular expressions, but the discovered lens is not 
acceptable to the users. 

Our algorithm must resolve a three-way tension between the quality of
the inferred lens, the number of examples the user must provide to
eliminate unwanted lenses, and the amount of time it takes to return a
result.  For example, if the algorithm has already found the lens in
Figure~\ref{fig:example_lens}, we don't want to spend a lot of time
searching for an even better lens.

To resolve this tension, our algorithm uses heuristics to judge whether to
return the current best satisfying lens to the user or to pass the
next set of unrollings to \GreedySynth.
The heuristics favor stopping if the current best satisfying
lens has relatively high likelihood, indicating the lens is very promising.
The heuristics also favor stopping if \Expand
has delievered to \GreedySynth all pairs of stochastic regular
expressions at a given rank and there is a large number of pairs at the next
rank because searching through all such pairs will take a long time.
With this approach, the algorithm can quickly respond with a satisfying
lens with relatively high likelihood.  If users are unhappy with the result, they can refine the
search by supplying additional examples, which serve both to rule out
the previously proposed lens(es) and to reduce the size of the search
space by cutting down on the number of satisfying lenses.


%Consider the trivial lens
%\lstinline{disc(emp_salary,emp_row,rep(emp_salary),rep(emp_row))}. As this is
%the disconnect lens, the cost of each side is the entropy of the data format, so
%the total cost is $\EntropyOf{\lstinline{emp_salary}} +
%\EntropyOf{\lstinline{emp_row}}}$. \lstinline{emp_salary} contains strictly more
%imformation than \EntropyOf{\lstinline{": " . salary}}, and \lstinline{emp_row}
%contains strictly more information than \EntropyOf{\lstinline{": " . salary}},
%so by our metric \lstinline{single_emp_map} is preferable to the disconnect
%lens.

%Not sure we need this level of detail after all.
%\afm{calculations for cost of various lenses between \lstinline{emp_salary} and
%  \lstinline{emp_row}} Consider the lens \lstinline{single_emp_map} between
%\lstinline{emp_salary} and \lstinline{emp_row}. Given this lens, the expected
%entropy of recovering the left format from the right
%($\EntropyOf{\lstinline{emp_salary} \Given \lstinline{emp_row},
%  \lstinline{single_emp_map} }$) is the sum of the expected entropy of
%recovering each of its subcomponents, $\EntropyOf{\lstinline{emp_salary} \Given
%  \lstinline{emp_row}, \lstinline{single_emp_map} } = \EntropyOf{\lstinline{name
%    . " " . name} \Given \lstinline{name . "," . name}, \lstinline{name_map}
%}$\\ + $\EntropyOf{\lstinline{": " . salary} \Given
%  \lstinline{"," . company}, \lstinline{disc(salary,company,"UNSET","UNSET")}
%}$.
%
%The entropy of the identity lens is zero. As the two formats are in bijective
%correspondence, we know exactly which string is present in the left-hand format.
%The entropy of the disconnect lens is just the entropy of
%\lstinline{": " . salary}.  Knowing which string is present in the right-hand
%format tells us nothing about what string is present in the left-hand format. So
%$\EntropyOf{\lstinline{emp_salary} \Given \lstinline{emp_row},
%  \lstinline{single_emp_map} } = \EntropyOf{\lstinline{": " . salary} }$
%
%Analogously, $\EntropyOf{\lstinline{emp_row} \Given \lstinline{emp_salary},
%  \lstinline{single_emp_map} }$ is just $\EntropyOf{\lstinline{"," . company}
%}$, so the total cost of the lens is $\EntropyOf{\lstinline{": " . salary}} +
%\EntropyOf{\lstinline{"," . company}}$

%Consider the trivial lens
%\lstinline{disc(emp_salary,emp_row,rep(emp_salary),rep(emp_row))}. As this is
%the disconnect lens, the cost of each side is the entropy of the data format, so
%the total cost is $\EntropyOf{\lstinline{emp_salary}} +
%\EntropyOf{\lstinline{emp_row}}$. \lstinline{emp_salary} contains strictly more
%imformation than \EntropyOf{\lstinline{": " . salary}}, and \lstinline{emp_row}
%contains strictly more information than \EntropyOf{\lstinline{": " . salary}},
%so by our metric \lstinline{single_emp_map} is preferable to the disconnect
%lens.
% end overview

% begin stoch-rx
% end stoch-rx

\section{Stochastic Regular Expressions}
\label{sec:sre}
To characterize the likely lenses, we must compute the expected number of bits
needed to recover a string in one data source from a synchronized string in the
other data source. To do this, we must first develop a probabilistic language
model for our language. We do this with \emph{stochastic regular expressions},
regular expressions annotated with probability information. With this, we can
jointly express a language and a probability distribution over that language. In
the following grammar, $\String$ ranges over strings, and $\Probability$ ranges
over real numbers between 0 and 1, exclusive.
$$\Regex{},\RegexAlt{} \GEq{}  \String  \; | \; \emptyset \; | \; \PRegexStar{\Regex}{p} \; | \; \RegexConcat{\Regex_1}{\Regex_2} \; | \; \PRegexOr{\Regex_1}{\Regex_2}{p}$$

In the stochastic regular expression
$\PRegexOr{\Regex_1}{\Regex_2}{\Probability}$, the annotation $\Probability$
represents the likelihood the string is in $\Regex_1$. In the stochastic regular
expression $\PRegexStar{\Regex}{\Probability}$, the annotation \Probability how
much more likely having a string involving more than $n$ iterations is than
having a string involving exactly $n$ iterations. The semantics of SREs is
defined by the function $P$ below.

\begin{center}
  \begin{tabular}{rcl}
    $\ProbabilityOf{\String}{\String''}$
    & =
    & $\begin{cases*}1 & if $\String = \String''$\\ 0 & otherwise\end{cases*}$ \\
     
    $\ProbabilityOf{\emptyset}{\String}$
    & =
    & $0$ \\
    
    $\ProbabilityOf{\RegexConcat{\Regex_1}{\Regex_2}}{s}$

    & =
    & $\Sigma_{\String = \String_1\String_2}\ProbabilityOf{\Regex_1}{\String_1}\ProbabilityOf{\Regex_2}{\String_2}$ \\
    
    $\ProbabilityOf{\PRegexOr{\Regex_1}{\Regex_2}{\Probability}}{\String}$
    & =
    & $\Probability\ProbabilityOf{\Regex_1}{\String} +
      (1-\Probability)\ProbabilityOf{\Regex_2}{\String}$\\
    
    $\ProbabilityOf{\PRegexStar{\Regex}{\Probability}}{\String}$
    & =
    & $\Sigma_n \Sigma_{\String = \String_1 \ldots \String_n}\Probability^n(1-\Probability)\Pi_{i=1}^n\ProbabilityOf{\Regex}{\String_i}$\\
  \end{tabular}
\end{center}

\begin{figure}
  \setlength\extrarowheight{3pt}
  \begin{tabular}{@{\hspace*{5em}}r@{\hspace{1em}}c@{\hspace{1em}}l@{}r@{}}
    \PRegexOr{\Regex}{\emptyset}{1} & $\SSREquiv$ & \Regex{} & \OrIdentityRule{} \\
    $\RegexConcat{\Regex}{\emptyset}$ & $\SSREquiv$ & $\emptyset$ & \EmptyProjectionRightRule{} \\
    $\RegexConcat{\emptyset}{\Regex}$ & $\SSREquiv$ & $\emptyset$ & \EmptyProjectionLeftRule{} \\
    \RegexConcat{(\RegexConcat{\Regex{}}{\Regex'})}{\Regex''} & $\SSREquiv$ & \RegexConcat{\Regex{}}{(\RegexConcat{\Regex'}{\Regex''})} & \ConcatAssocRule{}  \\
    \PRegexOr{(\PRegexOr{\Regex}{\Regex'}{\Probability_1})}{\Regex''}{\Probability_2} & $\SSREquiv$ & \PRegexOr{\Regex}{(\PRegexOr{\Regex'}{\Regex''}{\frac{(1-\Probability_1)\Probability_2}{1 - \Probability_1\Probability_2}})}{\Probability_1\Probability_2} & \OrAssociativityRule{}  \\
    \PRegexOr{\Regex{}}{\RegexAlt{}}{\Probability} & $\SSREquiv$ & \PRegexOr{\RegexAlt{}}{\Regex{}}{1-\Probability} & \OrCommutativityRule{}\\
    \RegexConcat{\Regex{}}{(\PRegexOr{\Regex{}'}{\Regex{}''}{\Probability})} & $\SSREquiv$ & \PRegexOr{(\RegexConcat{\Regex{}}{\Regex{}'})}{(\RegexConcat{\Regex{}}{\Regex{}''})}{\Probability} & \DistributivityLeftRule{} \\
    \RegexConcat{(\PRegexOr{\Regex{}'}{\Regex{}''}{\Probability})}{\Regex{}} & $\SSREquiv$ & \PRegexOr{(\RegexConcat{\Regex{}'}{\Regex{}})}{(\RegexConcat{\Regex{}''}{\Regex{}})}{\Probability} & \DistributivityRightRule{} \\
    \RegexConcat{\EmptyString{}}{\Regex{}} & $\SSREquiv$ & \Regex{} & \ConcatIdentityLeftRule{} \\
    \RegexConcat{\Regex{}}{\EmptyString{}} & $\SSREquiv$ & \Regex{} & \ConcatIdentityRightRule{} \\
    \PRegexStar{\Regex{}}{\Probability} & $\SSREquiv$ & \PRegexOr{\EmptyString{}}{(\RegexConcat{\Regex{}}{\PRegexStar{\Regex{}}{\Probability}})}{1-\Probability} & \UnrollstarLeftRule{} \\
    \PRegexStar{\Regex{}}{\Probability} & $\SSREquiv$ & \PRegexOr{\EmptyString{}}{(\RegexConcat{\PRegexStar{{\Regex{}}}{\Probability}}{\Regex{}})}{1-\Probability} & \UnrollstarRightRule{} 
  \end{tabular}
  \caption{Stochastic Regular Expression Star-Semiring Equivalence}
  \label{fig:ssr-sre}
\end{figure}

\subsection{Stochastic Regular Expression Equivalences}
$\Expand$ needs to be able to find equivalent stochastic regular expressions.
However, existing work does not provide a means to reason about stochastic
regular expression equivalence. We extend the
\emph{star-semiring}~\cite{Droste2009} equivalences to stochastic regular
expressions (Figure~\ref{fig:ssr-sre}).

\begin{theorem}
  If $\Regex \SSREquiv \RegexAlt$ then $\ProbabilityOf{\Regex}{\String} =
  \ProbabilityOf{\RegexAlt}{\String}$, for all strings $\String \in \LanguageOf{\Regex}$.
\end{theorem}
\begin{proof}
  The proofs of this theorem, and subsequent theorems in this paper, appears in
  the appendix present in the full version of the paper accompanying this
  submission.
\end{proof}

We prove these star-semiring equivalences sound, as those are the equivalences
we either traverse (with \Expand), or normalize across (as part of
\GreedySynth).

\subsection{Stochastic Regular Expression Entropy}
The entropy of a data source $S$ is the expected number of bits required to
describe a random element in $S$ ($-\Sigma_{s\in S}P(s)\Log_2P(s)$). The entropy
of a stochastic regular expression can be computed directly from its syntax,
when the stochastic regular expression is unambiguous and contains no empty
subcomponents.
\begin{center}
  \begin{tabular}{rcl}
    $\EntropyOf{s}$
    & =
    & 1\\
    
    $\EntropyOf{\PRegexStar{\Regex}{\Probability}}$
    & =
    & $\frac{\Probability}{1-\Probability}(\EntropyOf{\Regex} - \Log_2\Probability)
      - \Log_2(1-\Probability)$\\
    
    $\EntropyOf{\PRegexConcat{\Regex}{\RegexAlt}}$
    & =
    & \EntropyOf{\Regex} + \EntropyOf{\RegexAlt}\\
    
    $\EntropyOf{\PRegexOr{\Regex}{\RegexAlt}{\Probability}}$
    & =
    & $\Probability(\EntropyOf{\Regex} - \Log_2(\Probability)) + (1-\Probability)(\EntropyOf{\RegexAlt} - \Log_2(1-\Probability))$\\
  \end{tabular}
\end{center}
We have proven that this syntactic computation corresponds to the entropy of the
stochastic regular expression.

\begin{theorem}
  \label{thm:correct_entropy}
  If $\Regex$ is unambiguous and does not contain $\emptyset$ as a subterm,
  $\EntropyOf{\Regex}$ is the entropy of $\Regex$.
\end{theorem}

Without unambiguity constraints it is not easy to calculate the entropy. This
method is certainly incorrect without unambiguity constraints: consider the SRE
$\PRegexOr{\lstinline{"a"}}{\lstinline{"a"}}{.5}$. Using the above computation,s
this SRE has an entropy of $1$, but the entropy should be $0$. These
difficulties become particularlly complex when the languages are ambiguous in
subtle ways, the algorithm must be correct when only some of the two languages
overlap. Similar issues occur when trying to find the entropy when $\emptyset$
is a subterm (what should the entropy of $\PRegexStar{\emptyset}{.5}$ be), so we
do not define the entropy on $\emptyset$.

In our work, these conditions are merely a technicality, we require unambiguous
regular expressions as input to our synthesis procedure, and we can easily
preprocess emptysets out of the stochastic regular expressions that are
themselves nonempty by traversing the correct star-semiring equivalences (\EG,
\PRegexOr{\emptyset}{\lstinline{"s"}}{.5} \SSREquiv \lstinline{"s"}).

% \caption{Regular Expression Equivalences}
% \label{fig:regex-equivalence-rules}

\section{Simple Symmetric String Lenses}
\label{sec:ssl}
We now give a formal description of all the combinators in our symmetric lens
language. While our algorithms perform synthesis on stochastic regular
expressions, lenses themselves are typed between regular expressions. We can
recover a regular expression from a stochastic regular expression by deleting
probability annotations. In a slight abuse of notation, if $\Regex$ is a
stochastic regular expression, $\BRegex$ is the regular expression obtained by
removing probability annotations. The typing judgment $\Lens \OfType \BRegex
\Leftrightarrow \BRegexAlt$ means that $\Lens$ is a well typed lens between
$\LanguageOf{\BRegex}$ and $\LanguageOf{\BRegexAlt}$.

\begin{align*}
\ell ::= &\IdentityLensOf{\BRegex} \; | \; \DisconnectOf{\BRegex}{\BRegexAlt}{\String}{\StringAlt} \; | \; \IterateLensOf{\Lens} \; | \; \ConcatLensOf{\Lens_1}{\Lens_2} \; | \; \SwapLensOf{\Lens_1}{\Lens_2} \; | \; \OrLensOf{\Lens_1}{\Lens_2} \; | \; \ComposeLensOf{\Lens_1}{\Lens_2} \; |\\
&\MergeROf{\Lens_1}{\Lens_2} \; | \; \MergeLOf{\Lens_1}{\Lens_2} \; | \; \InvertOf{\Lens}
\end{align*}

We have already described a number of these lenses in \S\ref{sec:overview}.
The compose lens $\Lens_1 ; \Lens_2$ composes two lenses sequentially, it
transforms from one data format to the other by first transforming to an
intermediate format, shared as the target of $\Lens_1$ and the source of
$\Lens_2$. The \MergeR lens combines two sublenses which share the same target.
Which lens gets used depends on what data is in the left-hand format, if it is
in the domain of $\Lens_1$ then $\Lens_1$ gets used, and similarly for
$\Lens_2$.  The \MergeL lens is symmetric to \MergeR, the two sublenses must
share the same source. Finally, $\InvertOf{\Lens}$ inverts a lens, \CreateR
becomes \CreateL and \PutR becomes \PutL, and vice-versa.

We now provide the typing derivations and semantics for these lenses. We do not
include the semantics for combinators equivalent to those presented in prior
work~\cite{symmetric-lenses,Boomerang}. Furthermore, we only present \CreateR
and \PutR when \CreateL and \PutL are symmetric. Full details are present in the
appendix. For simplicity of presentation, we define the typing derivations and
semantics only over unambiguous regular expressions, even though some lenses can
be defined over ambiguous regular expressions (for example, the identity lens
doesn't need any ambiguity constraints). We believe relaxing this restriction is
unproblematic.

\begin{centermath}
  \begin{tabular}{m{1cm}@{\hspace*{6em}}m{1cm}@{\hspace*{3em}}}
    $
  \inferrule*
  {
  }
  {
    \IdentityLensOf{\BRegex} \OfType \BRegex \Leftrightarrow \BRegex
  }$
&
$\begin{array}[b]{r@{\ }c@{\ }l}
    \CreateR{} \App s & = & s\\
    \PutR{} \App s_1 \App s_2 & = & s_1
  \end{array}$
\end{tabular}
\end{centermath}
Note that the identity lens ignores the second argument in the put functions.
Because the two formats are fully synchronized, no knowledge of the prior data
is needed.

\begin{centermath}
  \begin{tabular}{m{5cm}m{2cm}}
    $
    \inferrule*
    {
    \String \in \LanguageOf{\BRegex}\\
    \StringAlt \in \LanguageOf{\BRegexAlt}
    }
    {
    \DisconnectOf{\BRegex}{\BRegexAlt}{\String}{\StringAlt}
    \OfType \BRegex \Leftrightarrow \BRegexAlt
    }$
    &
      $
  \begin{array}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String'$ & = & $\StringAlt$\\
    $\PutR{} \App \String' \App \StringAlt'$ & = & $\StringAlt'$
  \end{array}$
\end{tabular}
\end{centermath}

Just as the identity lens ignores the second argument in puts, disconnect lenses
ignore the first in both puts and creates.  The data is unsynchronized in these
two formats, information from one format doesn't impact the other.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \ConcatLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_1 \Concat \BRegexAlt_2
  }
$
&
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \SwapLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_2 \Concat \BRegexAlt_1
  }
$
\end{tabular}
\end{centermath}
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \String_1 \String_2$ & = & $(\Lens_1.\CreateROf{\String_1})(\Lens_2.\CreateROf{\String_2})$\\
%    $\CreateL{} \App \StringAlt_1 \StringAlt_2$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
%    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_1\StringAlt_2)$ & = & $(\Lens_1.\PutROf{\String_1}{\StringAlt_1})(\Lens_2.\PutROf{\String_2}{\StringAlt_2})$\\
%    $\PutL{} \App (\StringAlt_1\StringAlt_2) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
%  \end{tabular}
%\end{center}

Concat is similar to concatenation in existing string lens languages like
Boomerang.  For such terms, we do not provide the semantics, and merely refer readers to existing work. The swap combinator is similar to concat, though the second regular expression
is swapped.
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \String_1\String_2$ & = & $(\Lens_2.\CreateROf{\String_2})(\Lens_1.\CreateROf{\String_1})$\\
%    $\CreateL{} \App \StringAlt_2\StringAlt_1$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
%    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_2\StringAlt_1)$ & = & $(\Lens_2.\PutROf{\String_2}{\StringAlt_2})(\Lens_1.\PutROf{\String_1}{\StringAlt_1})$\\
%    $\PutL{} \App (\StringAlt_2\StringAlt_1) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
%  \end{tabular}
%\end{center}
\begin{centermath}
  \begin{tabular}{m{5cm}m{7cm}}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \OrLensOf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
  $
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
        \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
        \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}
The \OrLens lens deals with data that can come in one form or another. If the
data gets changed from one format to the other, information in the old format is
lost.
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \String_1\ldots\String_n$
%    & =
%    & $(\Lens.\CreateROf{\String_1})\ldots(\Lens.\CreateROf{\String_n})$\\
%    
%    $\CreateL{} \App \StringAlt_1\ldots\StringAlt_n$
%    & =
%    & $(\Lens.\CreateLOf{\StringAlt_1})\ldots(\Lens.\CreateLOf{\StringAlt_n})$\\
%    
%    $\PutR{} \App (\String_1\ldots\String_n) \App (\StringAlt_1\ldots\StringAlt_m)$
%    & =
%    & $\StringAlt_1'\ldots\StringAlt_n'$ where $\StringAlt_i' =
%      \begin{cases*}
%        \Lens.\PutROf{\String_i}{\StringAlt_i} & if $i \leq m$\\
%        \Lens.\CreateROf{\String_i} & otherwise
%      \end{cases*}$\\
%    $\PutL{} \App (\StringAlt_1\ldots\StringAlt_m) \App (\String_1\ldots\String_n)$
%    & =
%    & $\String_1'\ldots\String_n'$ where $\String_i' =
%      \begin{cases*}
%        \Lens.\PutROf{\StringAlt_i}{\String_i} & if $i \leq n$\\
%        \Lens.\CreateROf{\StringAlt_i} & otherwise
%      \end{cases*}$
%  \end{tabular}
%\end{center}
\begin{centermath}
  \begin{tabular}{m{5cm}m{6cm}}
$
  \centering
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt
  }
  {
    \MergeROf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \BRegexAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\Lens_1.\CreateLOf{\StringAlt}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2}$
    \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}

The \MergeR lens is interesting because it merges data where one data can be in
two formats, and one data has only one format. In previous
work~\cite{Boomerang}, this was combined into \OrLens{}, where
\OrLens{} could have ambiguous types, but we find it more clear to have explicit
merge operators: it is easier to see what lens the synthesis algorithm is
creating.

\begin{centermath}
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex \Leftrightarrow \BRegexAlt_2
  }
  {
    \MergeLOf{\Lens_1}{\Lens_2} \OfType
    \BRegex
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
\end{centermath}
The \MergeL lens is symmetric to \MergeR.

\begin{centermath}
  \begin{tabular}{m{5cm}m{6cm}}
  $
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegexAlt \Leftrightarrow \BRegexAltAlt\\
  }
  {
    \ComposeLensOf{\Lens_1}{\Lens_2} \OfType
    \BRegex \Leftrightarrow \BRegexAltAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$ & = & $\Lens_2.\CreateROf{(\Lens_1.\CreateROf{\String})}$\\
    $\CreateL{} \App \StringAlt$ & = & $\Lens_1.\CreateLOf{(\Lens_2.\CreateLOf{\StringAlt})}$\\
    $\PutR{} \App \String \App \StringAltAlt$ & = & $\Lens_2.\PutROf{(\Lens_1.\PutROf{\String}{(\Lens_2.\CreateLOf{\StringAltAlt})})}{\StringAltAlt}$\\
    $\PutL{} \App \StringAltAlt \App \String$ & = & $\Lens_1.\PutLOf{(\Lens_2.\PutLOf{\StringAltAlt}{(\Lens_2.\CreateROf{\String})})}{\String}$
  \end{tabular}
\end{tabular}
\end{centermath}
Composing is interesting in the put functions. Because puts require intermediary
data, we recreate that intermediary data with creates.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
\inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \IterateLensOf{\Lens} \OfType
    \StarOf{\BRegex}
    \Leftrightarrow
    \StarOf{\BRegexAlt}
  }
  $
  &
  $
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \InvertOf{\Lens} \OfType \BRegexAlt \Leftrightarrow \BRegex
  }
  $
\end{tabular}
\end{centermath}
%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \StringAlt$ & = & $\Lens.\CreateLOf{\StringAlt}$\\
%    $\CreateL{} \App \String$ & = & $\Lens.\CreateROf{\String}$\\
%    $\PutR{} \App \StringAlt \App \String$ & = & $\Lens.\PutLOf{\StringAlt}{\String}$\\
%    $\PutL{} \App \String \App \StringAlt$ & = & $\Lens.\PutROf{\String}{\StringAlt}$
%  \end{tabular}
%\end{center}
The \IterateLens lens deals with iterated data, while inverting reverses the direction of a lens: creating on the right becomes creating on the left and vice versa, and putting on the right becomes putting on the left and vice versa. The invert combonator is particularly useful when chaining many compositions together, as it can be used to align the central types.
\[
  \centering
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \BRegex \SSREquiv \BRegex'\\
    \BRegexAlt \SSREquiv \BRegexAlt'
  }
  {
    \Lens \OfType \BRegex' \Leftrightarrow \BRegexAlt'
  }
\]

Type equivalence enables a lens of type $S \Leftrightarrow T$ to be used as a
lens of type $S' \Leftrightarrow T'$ if $S$ equivalent to $S'$ and $T$ is
equivalent to $T'$. Type equivalence is useful both for addressing type
annotations, and for making well-typed compositions.

\subsection{Lens Costs}
Our cost metric is based on the expected amount of information required to
recover a string in one data format from the other. We use the function
$\REntropyOf{\RegexAlt \Given \Lens, \Regex}$ to calculate bounds of the
expected amount of information required to recover a string in $\RegexAlt$ from
a string in $\Regex$, synchronized by $\Lens$. We use the function
$\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ to calculate bounds of the
expected amount of information required to recover a string in $\Regex$ from a
string in $\RegexAlt$, synchronized by $\Lens$.
\begin{center}
  \begin{tabular}{rcl}
    $\REntropyOf{\RegexAlt \Given \IdentityLensOf{\RegexAlt}, \RegexAlt}$
    & =
    & [0,0]\\
    
    $\REntropyOf{\RegexAlt \Given \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}, \Regex}$
    & =
    & [\EntropyOf{\RegexAlt},\EntropyOf{\RegexAlt}]\\

    $\REntropyOf{\PRegexStar{\RegexAlt}{\ProbabilityAlt} \Given \IterateLensOf{\Lens}, \PRegexStar{\Regex}{\Probability}}$
    & =
    & $\frac{\Probability}{1-\Probability}\REntropyOf{\RegexAlt \Given \Lens, \Regex}$\\
    
    $\REntropyOf{\RegexAlt_1 \Concat \RegexAlt_2 \Given \ConcatLensOf{\Lens_1}{\Lens_2}, \Regex_1 \Concat \Regex_2}$
    & =
    & $\REntropyOf{\RegexAlt_1 \Given \Lens_1, \Regex_1} + \REntropyOf{\RegexAlt_2 \Given \Lens_2, \Regex_2}$\\
    
    $\REntropyOf{\RegexAlt_2 \Concat \RegexAlt_1 \Given \SwapLensOf{\Lens_1}{\Lens_2}, \Regex_1 \Concat \Regex_2}$
    & =
    & $\REntropyOf{\RegexAlt_2 \Given \Lens_1, \Regex_2} + \REntropyOf{\RegexAlt_1 \Given \Lens_1, \Regex_1}$\\
    
    $\REntropyOf{\PRegexOr{\RegexAlt_1}{\RegexAlt_2}{\ProbabilityAlt} \Given \OrLensOf{\Lens_1}{\Lens_2}, \PRegexOr{\Regex_1}{\Regex_2}{\Probability}}$
    & =
    & $\Probability\REntropyOf{\Regex_1 \Given \Lens_1, \RegexAlt_1} + (1-\Probability)\REntropyOf{\Regex_2 \Given \Lens_2, \RegexAlt_2}$\\
    
    $\REntropyOf{\RegexAlt \Given \MergeROf{\Lens_1}{\Lens_2}, \PRegexOr{\Regex_1}{\Regex_2}{\Probability}}$
    & =
    & $\Probability\REntropyOf{\RegexAlt \Given \Lens_1, \Regex_1} + (1-\Probability)\REntropyOf{\RegexAlt \Given \Lens_2, \Regex_2}$\\
    
    $\REntropyOf{\PRegexOr{\RegexAlt_1}{\RegexAlt_2}{\ProbabilityAlt} \Given \MergeLOf{\Lens_1}{\Lens_2}, \Regex}$
    & =
    & $(0,\REntropyOf{\RegexAlt \Given \Lens_1, \Regex_1}+\REntropyOf{\RegexAlt \Given \Lens_2, \Regex_2}+1)$\\
    
    $\REntropyOf{\Regex \Given \InvertOf{\Lens}, \RegexAlt}$
    & =
    & $\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$\\
  \end{tabular}
\end{center}
$\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ is defined symmetrically. These
functions bound the expected number of bits to recover one data format from a
synchronized string in the other format. Note that we would be able to exactly
calculate the conditional entropy, were it not for \MergeL. If
$\MergeLOf{\Lens_1}{\Lens_2} \OfType \Regex \Leftrightarrow
\PRegexOr{\RegexAlt_1}{\RegexAlt_2}{\ProbabilityAlt}$, given a string in $s$, we
need to determine if the synchronized string is in $\RegexAlt_1$ or $\RegexAlt_2$.
However, this information content is dependent on the how likely the
synchronized string is to be in $\RegexAlt_1$ or $\RegexAlt_2$. Nevertheless, we
typically calculate the conditional entropy exactly, as merges are relatively
uncommon on practice; only 2 of the lenses sythesized in our benchmarks
include merges.

The cost of a lens between two SREs $cost(\Lens, \Regex, \RegexAlt) =
\MaxOf{\LEntropyOf{\Regex \Given \Lens, \RegexAlt}} +
\MaxOf{\REntropyOf{\RegexAlt \Given \Lens, \Regex}}$ is the maximum sum of
recovering the left format from the right, and the right from the left. We have
proven theorems demonstrating the calculated entropy corresponds to the actual
conditional entropy to recover the data.

\begin{theorem}
  Let $\Lens \OfType \Regex \Leftrightarrow \RegexAlt$, where $\Lens$ does not
  include composition, $\Regex$ and $\RegexAlt$ are unambiguous, and neither
  $\Regex$ nor $\RegexAlt$ contain any empty subcomponents.
  \begin{enumerate}
  \item $\REntropyOf{\RegexAlt \Given \Lens, \Regex}$ bounds the entropy of
    $\SetOf{t \SuchThat t \in \LanguageOf{\RegexAlt}}$, given $\SetOf{s
      \SuchThat s \in \LanguageOf{\Regex} \BooleanAnd \Lens.\PutROf{s}{t} = t}$
  \item $\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ bounds the entropy of
    $\SetOf{s \SuchThat s \in \LanguageOf{\Regex}}$, given $\SetOf{t \SuchThat t
      \in \LanguageOf{\RegexAlt} \BooleanAnd \Lens.\PutLOf{t}{s} = s}$
  \end{enumerate}
\end{theorem}

% SAZ: This looks like a bad merge, since the paragraph below is better
% Note we have not defined entropy for lens compositions. Consider the lens
% $\Lens_1 ; \Lens_2$, where both $\Lens_1$ and $\Lens_2$ are non-bijective.
% However, their composition could actually be bijective, for example if the
% intermediary format contains information not present in either the source nor
% the target. While this composition may be a bijection (and should have zero
% cost), it is difficult to see this looking merely at the syntax.

Note that our definition of $\Entropy$ contains no case for sequential
composition $\Lens_1 ; \Lens_2$ and our theorem excludes lenses that contain
such compositions. Unfortunately, defining the entropy of lenses involving
composition is challenging because $\Lens_1$ might, for instance, add some
information that is subsequently projected away in $\Lens_2$. Such operations
can cancel, leaving a zero-entropy bijection composed from two non-zero entropy
transformations. However, detecting such cancellations directly is complicated and
this property is difficult to determine merely from syntax. Fortunately, we are able to
avoid such complication altogether by synthesizing \emph{DNF lenses}---simple symmetric
lenses that inhabit a disjunctive normal form. DNF lenses have a number of
properties that facilitate synthesis: they cut down the program search space
dramatically and they do not contain instances of composition.

%\begin{center}
%  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
%    $\CreateR{} \App \StringAlt$ & = & $\Lens.\CreateLOf{\StringAlt}$\\
%    $\CreateL{} \App \String$ & = & $\Lens.\CreateROf{\String}$\\
%    $\PutR{} \App \StringAlt \App \String$ & = & $\Lens.\PutLOf{\StringAlt}{\String}$\\
%    $\PutL{} \App \String \App \StringAlt$ & = & $\Lens.\PutROf{\String}{\StringAlt}$
%  \end{tabular}
%\end{center}
% end ssl

% begin synthesis
\section{Synthesis}
\label{sec:synthesis}
Algorithm~\ref{alg:synth-sym-lens} presents our synthesis algorithm at a high
level of abstraction. The input regular expressions are first converted into
stochastic regular expressions with \ToStochastic.  
%Once that conversion has
%taken place, the $\RXSearch$ algorithm executes. This algorithm itself is
%defined via five functions: (1) $\PCF{\PQ.Create}$, (2) $\PCF{\PQ.Pop}$, (3)
%$\PCF{Expand}$, (4) $\PCF{\PQ.Push}$, and (5) $\PCF{\Continue}$. First,
This pair of SREs is used to initialize a priority queue ($pq$). The priority of
a SRE pair is the number of rewrites needed to derive the pair from the
originals. Next, $\PCF{SynthSymLens}$ enters a loop that searches for likely
lenses. The loop terminates when the algorithm believes it is unlikely to find a
better lens than the best one it has found so far (a termination condition
defined by $\PCF{\Continue}$). Within each iteration of the loop, it:
\begin{itemize}
\item pops the next class ($S$, $T$) of lenses to
search off of the priority queue ($\PCF{\PQ.Pop}$),
\item executes $\GreedySynth$ to find a best lens in that class if
one exists ($\LC$),
using the examples $exs$ to filter out potential lenses that do not satisfy
the specification,
\item replaces $best$ with $\LC$, if $\LC$ has lower cost according
to our information-theoretic metric, and
\item adds the SREs derived from rewriting $S$ and $T$ ($\Expand(S,T)$)
  to the priority queue.
\end{itemize}
When the loop terminates, the search returns the globally best lens found
($best$).  Each subroutine of this algorithm will be explained in
further depth in the following subsections.

\emph{Stochastic DNF regular expressions} are critical to the success of our
algorithm. Stochastic DNF regular expressions (\SDNFREabbrev{}s) are a
pseudo-normal form for stochastic regular expressions. Of all the star-semiring
equations required to relate two \SDNFREabbrevs, only those relating to Kleene
star (\EG, \emph{Unrollstar$_L$} and \emph{Unrollstar$_R$}) are needed to relate
two \SDNFREabbrevs; other axioms, like associativity, commutativity or
distributivity, are unneeded. This important property makes it possible to
construct an efficient algorithm ($\GreedySynth$), directed by the syntax of two
\SDNFREabbrevs, to synthesize any lenses in the same ``class'' (\IE, any lenses
that have the same type when the Kleene star axioms are unused). This property,
and the resulting efficiency of $\GreedySynth$ is key to the effectiveness of
our core algorithms.



\begin{algorithm}[t]
  \caption{\SynthSymLens}
  \label{alg:synth-sym-lens}
  \begin{algorithmic}[1]
    \Function{SynthSymLens}{$\BRegex,\BRegexAlt,\Examples$}
    \State $\Regex \gets \Call{\ToStochastic}{\BRegex}$
    \State $\RegexAlt \gets \Call{\ToStochastic}{\BRegexAlt}$
    \State $\RXSearchState \gets \Call{\PQ.Create}{\Regex,\RegexAlt}$
    \State $\Best \gets \None$
    \While{$\Call{\Continue}{\RXSearchState,\Best}$}
    \State $(\Regex,\RegexAlt) \gets \Call{\PQ.Pop}{\RXSearchState}$
    \State $\LC \gets \Call{\GreedySynth}{\Examples,\Regex,\RegexAlt}$
    \If{$\Call{Cost}{\LC} < \Call{Cost}{\Best}$}
    \State $\Best \gets \LC$
    \EndIf
    \State $\Call{\PQ.Push}{\RXSearchState,\Expand(\Regex,\RegexAlt)}$
    \EndWhile
    \State \ReturnVal{best}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

%In this work, we aim to quickly find a good lens between two regular expressions
%that satisfies the input-output examples. To this end, we develop an information
%theoretic metric for how much data is synchronized. Information theoretic
%metrics require a notion of probability distributions \emph{how are probability
%  distributions being used, are certain things weighted more etc, assign weights
%  to different subcomponents and parts of the data}. We annotate the regular
%expressions with a reasonable probability distribution, making them
%\emph{stochastic regular expressions}. Armed with probability distributions over
%the languages, we have the capabilities to define information theoretic metrics
%over these probability distributions.
%
%Our overall synthesis algorithm utilizes two synthesizers shown in
%Figure~\ref{fig:high-level-algorithm}. There are an infinite number of possible
%lenses between two regular expressions that can be searched through. Instead of
%searching through all possible lenses, the lenses are grouped into classes of
%lenses based on the syntax of the regular expressions they synchronize. Two
%lenses are in the same class if they can be typed by the same regular
%expressions, using no star equivalences. This works well for synthesis, as
%finding a good lens within these classes permits an efficient synthesis
%procedure.
%
%However, proposing these classes is complicated by stochastic regular
%expressions. While the equivalences on regular expressions are well studied, the
%equivalences on stochastic regular expressions are not. We want to propose
%equivalent stochastic regular expressions, but both the languages and
%probability distributions must be maintained. If the probability distributions
%are not maintained, then the metric by which we compare our lenses changes for
%each class of lenses, we can't compare lenses between classes. To alleviate
%this, we describe the \emph{star-semiring} equivalences on stochastic regular
%expressions, and prove they are sound with respect to language and probability
%distributions. Our \RXSearch proposes stochastic regular expressions by
%traversing a subset of these equivalences, so \RXSearch only proposes regular
%expression pairs equivalent to the originals.
%
%The second algorithm, \GreedySynth, searches within a class for the lowest cost
%lens.  It is a greedy algorithm, and not guaranteed to find the lowest cost
%lens.  However, we haven't found any instances in which \GreedySynth doesn't find
%the optimal lens, due to the partial backtracking we implemented. \GreedySynth
%works by searching, not through symmetric lenses, but through an alternative
%language of Symmetric DNF lenses. After finding such a symmetric DNF lens, that
%symmetric DNF lens is converted into a simple symmetric lens.

\subsection{Searching for $(\Regex,\RegexAlt)$ Candidate Classes}
The first phase of the synthesis algorithm looks for pairs of SREs
$(\Regex,\RegexAlt)$ to drive the \GreedySynth algorithm.  These pairs are
generated using the star unrolling axioms:
\begin{center}
  \begin{tabular}{rcl}
    $\PRegexStar{\Regex}{\Probability}$
    & \Rewrite
    & \PRegexOr{\EmptyString{}}{(\RegexConcat{\Regex{}}{\PRegexStar{\Regex{}}{\Probability}})}{\Probability}\\

    $\PRegexStar{\Regex}{\Probability}$
    & \Rewrite
    & \PRegexOr{\EmptyString{}}{(\RegexConcat{\PRegexStar{\Regex{}}{\Probability}}{\Regex{}})}{\Probability}
  \end{tabular}
\end{center}
as well as the congruence rules that allow these rewrites to be applied on
subexpressions.
The priority queue yields stochastic regular expressions generated using fewer
rewrites first. Only when there are no more proposed regular expressions derived
from $n$ rewrites will \PCF{\PQ.Pop} propose regular expressions derived from
$n+1$ rewrites.

The procedure \PCF{\Continue} returns false based on the how long the search has
been going, and how hard it expects the next class of problems to be. In
particular, if $\PCF{PQ.Peek}(pq) = (\Regex,\RegexAlt)$, that RE pair is at
distance $d$, the number of pairs in $pq$ at distance $d$ is $n$, and the
current best lens has cost $c$, then:
\begin{gather*}
  \Call{Continue}{pq} := c > d + \Log_2(n)
\end{gather*}

When $\Call{Continue}{pq}$ returns $\False$, the algorithm stops proposing
regular expression pairs, and instead returns to the user the best lens found
thus far. If the algorithm finds a bijective lens, which
has zero cost, it will immediately return.
%
\subsection{Stochastic DNF Regular Expressions}
Just as SREs are REs with probability annotations,
\SDNFREabbrevs are \DNFREabbrevs with probability annotations.
As with SREs and regular
expressions, if $\DNFRegex$ is a stochastic DNF regular expression,
$\overline{\DNFRegex}$ is the DNF regular expression generated by erasing
probability annotations.

Syntactically, stochastic DNF regular expressions (\DNFRegex, \DNFRegexAlt) are
lists of stochastic sequences. Stochastic sequences (\Sequence, \SequenceAlt)
themselves are lists of interleaved strings and stochastic atoms. Stochastic
atoms (\Atom,\AtomAlt) are iterated stochastic DNF regular expressions.

\begin{center}
  \begin{tabular}{l@{\ }c@{\ }l@{\ }>{\itshape\/}r}
    % DNF_REGEX
    \Atom{},\AtomAlt{} & \GEq{} & \PRegexStar{\DNFRegex{}}{\Probability}
% & \StarAtomType{}
\\
    \Sequence{},\SequenceAlt{} & \GEq{} &
                                                       $\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n}$ 
%& \MultiConcatSequenceType{} 
\\
    \DNFRegex{},\DNFRegexAlt{} & \GEq{} & $\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}$ %& \MultiOrDNFRegexType{} 
  \end{tabular}
\end{center}

Intuitively, stochastic DNF regular expressions are stochastic
regular expressions with all concatenations fully distributed over all
disjunctions. As such, the language of a stochastic DNF regular expression is a
union of its subcomponents, the language of a stochastic sequence is the
concatenation of its subcomponents, and the language of a stochastic atom is the
iteration of its subcomponent. For
$\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}$
to be a valid stochastic DNF regular expression, the probabilities must sum to
one ($\sum_{i=0}^n\Probability_i = 1$).

\begin{trivlist}
  \centering
\item 
  % \begin{center}
  \begin{tabular}{@{\ }v@{\ }q}
    \LanguageOf{\PRegexStar{\DNFRegex{}}{\Probability}} \ =\  &
                                            \{\String_1\Concat\ldots\Concat\String_n
                                            \SuchThat \forall i,  \String_i\in\LanguageOf{\DNFRegex}\}\\
    \LanguageOf{\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n}}\ =\  & 
    % \\
    % \multicolumn{2}{L}{\ \ \ \ 
    \{\String_0\Concat\StringAlt_1\cdots\StringAlt_n\Concat\String_n \SuchThat \StringAlt_i\in\LanguageOf{\Atom_i}\}
    % }
    \\
    \LanguageOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}\ =\  &
    % \\
    % \multicolumn{2}{L}{\ \ \ \ 
    \{\String \SuchThat \String \in \LanguageOf{\Sequence_i} \text{\ and $i\in\RangeIncInc{1}{n}$}\}
    % }
  \end{tabular}
  % \end{center}
\end{trivlist}

As these DNF regular expressions are \emph{stochastic}, they are annotated with
probabilities to express a probability distribution, in addition to a
language.
\begin{center}
  \begin{tabular}{rcl}
    $\ProbabilityOf{\PRegexStar{\DNFRegex}{\Probability}}{\String}$
    & =
    & $\Sigma_n \Sigma_{\String = \String_1 \ldots \String_n}\Probability^n(1-\Probability)\Pi_{i=1}^n\ProbabilityOf{\DNFRegex}{\String_i}$\\
    
    $\ProbabilityOf{\SequenceOf{\String_0 \SeqSep \Atom_1 \SeqSep \ldots \SeqSep \Atom_n \SeqSep \String_n}}{\String'}$
    & =
    & $\Sigma_{\String' = \String_0\String_1'\ldots\String_n'\String_n}\Pi_{i = 1}^n\ProbabilityOf{\Atom_i}{\String_i'}$ \\
    
    $\ProbabilityOf{\DNFOf{(\Sequence_1,\Probability_1) \DNFSep \ldots \DNFSep (\Sequence_n,\Probability_n)}}{\String}$
    & =
    & $\Sigma_{i=1}^n\Probability_i\ProbabilityOf{\Sequence_i}{\String}$\\
  \end{tabular}
\end{center}

\begin{figure}
  \raggedright
  $\ConcatSequence{} \OfType{} \ArrowTypeOf{\SequenceType{}}{\ArrowTypeOf{\SequenceType{}}{\SequenceType{}}}$\\
  $\ConcatSequenceOf{[\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n]}{[\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]}=
  [\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n\Concat\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]$\\

  \medskip
  
  $\ConcatDNF{} \OfType{} \ArrowTypeOf{\DNFRegexType{}}{\ArrowTypeOf{\DNFRegexType{}}{\DNFRegexType{}}}$\\
  $\ConcatDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}=$\\
      $\DNFLeft (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_1},\Probability_1\ProbabilityAlt_1)\DNFSep \ldots
      \DNFSep
      (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_m},\Probability_1\ProbabilityAlt_m)\DNFSep
      \ldots$\\
      $\DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_1},\Probability_n\ProbabilityAlt_1)\DNFSep
      \ldots \DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_m},\Probability_n\ProbabilityAlt_m) \DNFRight$
  
  \medskip
  
  $\OrDNF{}_{\Probability} \OfType{}
  \ArrowTypeOf{\DNFRegexType{}}{\ArrowTypeOf{\DNFRegexType{}}{\DNFRegexType{}}
  }$ \\
  $\OrDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}{\Probability} =$\\
  $\DNFOf{(\Sequence_1,\Probability_1\Probability)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n\Probability)\DNFSep(\SequenceAlt_1,\ProbabilityAlt_1(1-\Probability))\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m(1-\Probability))}$
  
  \medskip
  
  \AtomToDNF{} \OfType
  \ArrowTypeOf{\AtomType{}}{\DNFRegexType{}}\\
  $\AtomToDNFOf{\Atom} = \DNFOf{(\SequenceOf{\EmptyString \SeqSep \Atom \SeqSep
      \EmptyString},1)}$
  \caption{Stochastic DNF Regular Expression Functions}
  \label{fig:dnf-regex-functions}
\end{figure}

The algorithm for converting a stochastic regular expressions into its
corresponding stochastic DNF regular expressions, written
$\ToDNFRegexOf{\Regex}$, is defined below.
\[
  \begin{array}{rcl@{\hspace*{3em}}rcl}
    \ToDNFRegexOf{\String} 
    & = 
    & \DNFOf{(\SequenceOf{\String},1)}

    & \ToDNFRegexOf{(\RegexConcat{\Regex_1}{\Regex_2})} 
    & = 
    & \ToDNFRegexOf{\Regex_1} \ConcatDNF \ToDNFRegexOf{\Regex_2} \\

    \ToDNFRegexOf{\emptyset} 
    & = 
    & \DNFOf{}

    & \ToDNFRegexOf{(\PRegexOr{\Regex_1}{\Regex_2}{\Probability})} 
    & = 
    & \ToDNFRegexOf{\Regex_1} \OrDNF_{\Probability} \ToDNFRegexOf{\Regex_2} \\

    \ToDNFRegexOf{(\PRegexStar{\Regex}{\Probability})} & = & \AtomToDNFOf{\PRegexStar{(\ToDNFRegexOf{\Regex})}{\Probability}}\\
    
  \end{array}
\]
This conversion relies on operators defined in
Figure~\ref{fig:dnf-regex-functions}. We have proved that this conversion
respects languages and probability distributions.

\begin{theorem}
  $\ProbabilityOf{\Regex}{\String} = \ProbabilityOf{\ToDNFRegex
    \Regex}{\String}$ and $\LanguageOf{\Regex} =
  \LanguageOf{\ToDNFRegexOf{\Regex}}$.
\end{theorem}

\paragraph*{\ToStochastic} With stochastic DNF regular expressions and
\ToDNFRegex defined, it is easier to explain \ToStochastic, the function that converts regular
expressions into stochastic regular expressions. If users
provided stochastic regular expressions themselves (perhaps inferred from
example data), this step could be skipped,
though our implementation does not (yet) permit users to provide such
stochastic regular expressions. If $\Regex$ is a stochastic DNF regular
expression generated by \ToStochastic, then $\ToDNFRegexOf{\Regex} =
\DNFOf{(\Sequence_1,\frac{1}{n}) \DNFSep \ldots \DNFSep
  (\Sequence_n,\frac{1}{n})}$ for some sequences $\Sequence_1\ldots\Sequence_n$,
and every stochastic atom generated by \ToStochastic is
$\PRegexStar{\DNFRegex}{.8}$. In particular, $\ToDNFRegex$ generates regular
expressions whose DNF form gives equal probability to all sequence subcomponents
of the DNF regular expression., and gives iterations a .8 chance to continue
iterating. In our experience generating random strings from regular expressions,
these probabilities provide good distributions of strings---stars are iterated
4 times on average, and no individual choice in a series disjunctions is chosen
disproportionately often. As we have found these distributions generate
reasonable strings, we believe they describe the shape of data well.

\paragraph*{Entropy}
We have developed a syntactic means of finding the entropy of a stochastic DNF
regular expression, like we have for stochastic regular expressions. This
enables us to efficiently find the entropy without first converting a DNF SRE to
a stochastic regular expression.

\begin{center}
  \begin{tabular}{rcl}
    $\EntropyOf{\PRegexStar{\DNFRegex}{\Probability}}$
    & =
    & $\frac{\Probability}{1-\Probability}(\EntropyOf{\DNFRegex} - \Log_2\Probability)
      - \Log_2(1-\Probability)
      $\\
    
    $\EntropyOf{\SequenceOf{\String_0 \SeqSep \Atom_1 \SeqSep \ldots \SeqSep \Atom_n \SeqSep \String_n}}$
    & =
    & $\Sigma_{i = 1}^n\EntropyOf{\Atom_i}$ \\
    
    $\EntropyOf{\DNFOf{(\Sequence_1,\Probability_1) \DNFSep \ldots \DNFSep (\Sequence_n,\Probability_n)}}$
    & =
    & $\Sigma_{i=1}^n\Probability_i(\EntropyOf{\Sequence_i}+\Log_2\Probability_i)$\\
  \end{tabular}
\end{center}

\begin{theorem}
  $\EntropyOf{\DNFRegex}$ is the entropy of $P_{\DNFRegex}$.
\end{theorem}

\subsection{Symmetric DNF Lenses}
Symmetric DNF lenses are an intermediate synthesis target for \GreedySynth.
There are many fewer symmetric DNF lenses than symmetric regular lenses. In
fact, if one does not use the star-unrolling axioms, there are only finitely
many DNF lenses of a given type (though there are still many more symmetric DNF
lenses than there are DNF bijective lenses).

Intuitively, a symmetric DNF lens $sdl$ is a union of symmetric sequence lenses,
$ssql_1 \ldots ssql_p$, a symmetric DNF sequence lens is a concatenation of
symmetric atom lenses, $sal_1 \ldots sal_n$, and a symmetric atom lens $sal$ is
an iteration of a symmetric DNF lens.

Just as we analyzed the information content of ordinary regular expressions, we
can analyze the information content of DNF regular expressions. As before, we
use $\REntropyOf{\DNFRegexAlt \Given \SDNFLens, \DNFRegex}$ to calculate bounds
of the expected amount of information required to recover a string in
$\DNFRegexAlt$ from a string in $\DNFRegex$, synchronized by $\SDNFLens$. We use
the function $\LEntropyOf{\DNFRegex \Given \SDNFLens, \DNFRegexAlt}$ to
calculate bounds on the expected amount of information required to recover a
string in $\DNFRegex$ from a string in $\DNFRegexAlt$, synchronized by
$\SDNFLens$.

The details of these definitions are syntactically tedious, but not
intellectually difficult. We elide them here but include them in the appendix.

\subsection{\GreedySynth}
\label{subsec:greedy-synth}
The synthesis procedure comprises three algorithms: one that greedily finds
symmetric DNF lenses (\GreedySynth), one that greedily finds symmetric sequence
lenses (\GreedySeqSynth), and one that finds symmetric atom lenses
(\AtomSynth{}). These three algorithms are hierarchically structured:
\GreedySynth relies on \GreedySeqSynth, \GreedySeqSynth relies on \AtomSynth,
and \AtomSynth rlies on \GreedySynth. The structure of the algorithms mirrors
the structure of symmetric DNF lenses and \SDNFREabbrevs.

\paragraph*{Symmetric DNF Lenses} Algorithm~\ref{alg:greedysynth} presents
\GreedySynth, which synthesizes symmetric DNF lenses. Its inputs 
are a suite of input-output examples and a pair of stochastic DNF regular expressions.
%
First, \PCF{CannotMap} determines whether there is no lens satisfying the
examples, and if so, \GreedySynth returns \None immediately. Otherwise, \GreedySynth finds
the best lenses (given the examples that match them) between all sequence pairs
$(SQ_i, TQ_j)$ drawn from the left and right DNF regular expressions. (The
function \CartesianMap maps its argument across the cross product of the input
lists). A priority queue containing these sequence lenses, ordered by cost, is
then initialized with $\PCF{PQ.Create}$. The symmetric lens is then built up
iteratively from these sequence lenses, where the state of the partially
constructed lens is tracked in the lens builder, $lb$.

\GreedySynth loops until there are no more sequence lenses in the priority
queue. Within this loop, a sequence lens is popped from the queue and, if it is
``useful,'' it is included in the final DNF lens. The lens is considered to
be useful when its source (or target) is \textit{not} already the source (or target) of
an already chosen sequence lens. If the examples require that two sequences have a
lens between them, then any sequence lens between them is considered useful. We
update the priorities of the sequence lenses as the algorithm proceeds: if two
sequence lenses have the same source, the second one to be popped gets a higher
cost than it originally had, to account for the information that needs to be stored
for including that source of non-bijectivity.

As an example, consider searching for a lens between \lstinline{"" | name.name$^*$} and \lstinline{"" | name}. \GreedySynth might first pop the
sequence pair \lstinline{""} and \lstinline{""}, because there is a bijective
sequence lens between them. As neither \lstinline{""} is involved in a sequence
lens, this lens is considered useful. Next, the sequence lens between
\lstinline{name.name$^*$} and \lstinline{name} would be popped: while that lens
is not bijective: it is still better than the alternatives. As all sequences are
now involved in sequence lenses, and there are no examples to make other lenses
useful, no further sequence lenses would be added to the lens builder.

Finally, after all sequences have been popped, the partial DNF lens $lb$ is
converted into a symmetric DNF lens. This is only possible if all sequences are
involved in some sequence lens: if they are not, \PCF{LensBuilder.ToDNFLens}
instead returns \None.

\begin{algorithm}[t]
  \caption{\GreedySynth}
  \label{alg:greedysynth}
  \begin{algorithmic}[1]
    \Function{GreedySynth}{$\Examples,\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)},\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}$}
    \If{$\Call{CannotMap}{\Examples,\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)},\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}$}
    \State $\ReturnVal{\None}$
    \EndIf
    \State $\SLS \gets
    \Call{\CartesianMap}{\GreedySeqSynth(\Examples),\ListOf{\Sequence_1;\ldots;\Sequence_n},\ListOf{\SequenceAlt_1;\ldots;\SequenceAlt_m}}$
    \State $\GreedyState \gets \Call{PQ.Create}{\SLS}$
    \State $lb \gets \Call{LensBuilder.Empty}{}$
    \While{$\Call{PQ.IsNonempty}{\GreedyState}$}
    \State $\SSQLens \gets
    \Call{PQ.Pop}{\GreedyState}$
    \If{$\Call{LensBuilder.UsefulAdd}{lb,\SSQLens,\Examples}$}
    \State $lb \gets \Call{LensBuilder.AddSeq}{lb,\SSQLens}$
    \EndIf
    \EndWhile
    \State \ReturnVal{\Call{LensBuilder.ToDNFLens}{\GreedyState}}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\paragraph*{Symmetric Sequence lenses} Algorithm~\ref{alg:greedyseqsynth}
presents \GreedySeqSynth, which synthesizes symmetric sequence lenses using an
algorithm whose structure is similar to \GreedySynth{}'s.  It calls \PCF{AtomSynth}, 
which synthesizes atom lenses by iterating a DNF lens between
its subcomponents. 

The inputs to \GreedySeqSynth are a suite of input-output examples and a pair of
stochastic atoms. As in \GreedySynth, \GreedySeqSynth returns \None early if
there is no possible lens. Afterward, \GreedySeqSynth finds the best lenses
between each atom pair of the left and right sequences, and organizes them into
a priority queue ordered by cost with \PCF{PQ.Create}. The symmetric sequence
lens is built up iteratively from these atom lenses, where the state of the
partially built lens is tracked in the sequence lens builder, $slb$.

\GreedySeqSynth then loops until there are no more atom lenses in the priority
queue. Within the loop, a popped atom lens is considered 
``useful'' if adding it to the sequence will lower the
cost of the generated sequence lens, or if examples show that one of its atoms
must not be disconnected. Each atom can be part of only one lens at a time, so
the algorithm must sometimes a previously chosen atom lens in order to connect an
atom that must not be disconnected.
After all atoms have been popped, the sequence lens is validated and
returned. The algorithm succeeds when all atoms that must not be disconnected
are involved in an atom lens, but \PCF{SLensBuilder.ToDNFLens}
returns \None otherwise.

\begin{algorithm}[t]
  \caption{\GreedySeqSynth}
  \label{alg:greedyseqsynth}
  \begin{algorithmic}[1]
    \Function{AtomSynth}{$\Examples,\PRegexStar{\DNFRegex}{\Probability},\PRegexStar{\DNFRegexAlt}{\ProbabilityAlt}$}
    \If{$\Call{CannotMap}{\Examples,\PRegexStar{\DNFRegex}{\Probability},\PRegexStar{\DNFRegexAlt}{\ProbabilityAlt}}$}
    \State $\ReturnVal{\None}$
    \Else
    \State $\ReturnVal{\IterateLensOf{\GreedySynth(\Examples,\DNFRegex,\DNFRegexAlt)}}$
    \EndIf
    \EndFunction

    \Function{GreedySeqSynth}{$\Examples,\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n},\SequenceOf{\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\String_m}$}
    \If{$\Call{CannotMap}{\Examples,\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n},\SequenceOf{\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\String_m}}$}
    \State $\ReturnVal{\None}$
    \EndIf
    \State $\ALS \gets
    \Call{\CartesianMap}{\AtomSynth(\Examples),\ListOf{\Atom_1;\ldots;\Atom_n},\ListOf{\AtomAlt_1;\ldots;\AtomAlt_m}}$
    \State $\GreedyState \gets \Call{PQ.Init}{\ALS}$
    \State $slb \gets \Call{SLensBuilder.Empty}{}$
    \While{$\Call{PQ.IsNonempty}{\GreedyState}$}
    \State $\SAtomLens \gets
    \Call{PQ.Pop}{\GreedyState}$
    \If{$\Call{SLensBuilder.UsefulAdd}{slb,\SAtomLens,\Examples}$}
    \State $\GreedyState \gets \Call{SLensBuilder.AddAtom}{\GreedyState,\SAtomLens}$
    \EndIf
    \EndWhile
    \State \ReturnVal{\Call{SLensBuilder.ToDNFLens}{\GreedyState}}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Optimizations}
\label{subsec:optimizations}

Our implementation includes a number of optimizations not described above:
annotations that guide DNF conversion; an expansion inference
algorithm; hash-consing and memoization; and compositional synthesis. The
implementation also provides for an additional specification parameter that
customizes the termination condition for the synthesis procedure.

\paragraph*{Open and Closed Regular Expressions} While \GreedySynth acts
relatively efficiently, it can suffer from an exponential blowup when converting
regular expressions to DNF form. This problem can be mitigated by avoiding the conversion
of some REs to DNF form and by performing the conversion lazily when necessarily.
More specifically, \Expand labels some uncoverted REs as ``closed,'' which means the
type-directed \GreedySynth algorithm treats them as DNF atoms and does not dig into
them recursively.  In other words,
given a pair of closed REs, \GreedySynth can either construct
the identity lens between them (it will do this if they are the same RE), or it can
construct a disconnect lens between them.
Regular expressions that are not annotated as closed are considered ``open.''

Distinguishing between open and closed regular expressions improves the
efficiency of \GreedySynth, but forces \Expand to decide which closed
expressions to open. At the start of synthesis, all regular expressions are
closed, and \Expand rewrites selected closed regular expressions to open ones
(thereby triggering DNF normalization).
%is allowed to to
%map closed regular expressions to each other, but only by using the identity
%lens---they must parse the same string components in all examples.
%This change is easy
%to support by adding non-DNF stochastic regular expressions as a new type of
%``closed'' atom. When converted into a DNF regular expression, if $\Regex$ is
%annotated as ``closed'', then $\ToDNFRegexOf{\Regex} = \AtomToDNFOf{\Regex}$.

\paragraph*{Expansion Inference} These additional rewrites make the search
through possible regular expressions much harder. Our algorithm automatically
will identify when certain closed regular expressions can \emph{only} be
involved in a disconnect lens.  Such regular expressions will automatically be
opened.

\paragraph*{Hash-consing and Memoization} We further improve \GreedySynth by
hash-consing stochastic DNF regular expressions.  This optimization enables
fast equality checks and saves memory.
%memoizing its results.  However, our stochastic DNF regular expressions are
%quite large and so hashing them is computationally intensive.  We use less
%memory and allow for quick comparisons and hashing of these DNF regular
%expressions by 


\paragraph*{Compositional Synthesis} Compositional synthesis allows us to use
previously defined lenses, whether they are previously defined by users or by
synthesis. As the synthesizer processes a Boomerang file, it accumulates
lens definitions and their types.  It tackles synthesis problems one after another
and there may be many such problems in a given program.
During synthesis, if an existing lens has the right type and agrees with the examples.
\GreedySynth will use it.  Consequently, if a large synthesis problem cannot be solved all
at once, a user can first generate subproblems for parts of a data format, and the
larger problem can subsequently use solutions to those subproblems.  In our experience,
this is a very powerful tool that allows synthesis to tackle problems of arbitrary
complexity.

\paragraph*{Termination Customization}
In this work, there are three competing constraints. The tool should (1) return
lenses quickly to users, (2) return the highest quality lenses, and (3)
not require users to write a large number of examples.
Our termination heuristic works well for most situations, but
there are cases where a large number of expansions must be performed to find the
correct lens.  Users can work around such a problem by providing a large number
of examples, but constructing examples is a chore, especially when formats are
complicated.  We have often found it simpler to allow users to change the
synthesis termination condition to demand \SynthSymLens be more judgemental
when it comes to deciding it has found a ``good enough'' lens.  
Conversely, if the user's desired transformation has a particularly
high cost, the algorithm may spend a long time searching in vain for lenses with
lower cost. By tuning \SynthSymLens to be more permissive, such a search can be
short-circuited.

For these situations, users can provide a number, $t$, that affects
the strictness of the termination condition, adjusting the \Continue formula
as follows. When $\PCF{PQ.Peek}(pq) = (\Regex,\RegexAlt)$, that RE pair is at
distance $d$, the number of pairs in $pq$ at distance $d$ is $n$, and the
current best lens has cost $c$:
\begin{gather*}
  \Call{Continue}{pq} := c > \Min(d + \Log_2(n) - t, 0)
\end{gather*}
With a positive $t$, the termination condition is stricter, and the algorithm
will spend longer searching for more likely lenses. With a negative $t$, the
termination condition is less strict, and the algorithm will spend less time
searching for more likely lenses.  Our default $t$ is $0$.
% end synthesis

% begin evaluation
\section{Evaluation}
\label{sec:evaluation}
We have implemented our symmetric DNF lenses and the synthesis of them as an
extension to Boomerang. We added symmetric lens combinators to Boomerang, and
implemented all of Boomerang's asymmetric lens combinators 
using a combination of the symmetric lens combinators presented in this
paper and symmetric versions of the asymmetric theory extensions
already present in Boomerang, like matching lenses and quotient lenses.
We also integrated our synthesis engine into Boomerang. It allows users to write synthesis tasks
alongside lens combinators, use those synthesis results in the manual writing of
new lenses, and use previously defined lenses in the synthesis of new lenses.

In this evaluation, we aim to answer three primary questions:
\begin{enumerate}
\item Is our synthesis procedure efficient enough to be used in everyday
  development?

\item How much slower is our tool on bijective lens synthesis benchmarks than
  the existing Optician system customized for bijective lenses?
  
\item Which heuristics are useful for reducing the ``specification
  overhead'' for users? In particular, which heuristics are useful in
  synthesizing the desired lens, instead of merely a lens that satisfies the
  specification?
\end{enumerate}

\subsection{Benchmark Suite}
Our benchmarks are drawn from three different sources.
\begin{enumerate}
\item We adapted 8 data cleaning benchmarks from Flash Fill, though, of course, our tool produces bidirectional transformations rather than one-way transformers like Flash Fill.
\item We adapted 29 benchmarks from Augeas. These benchmarks turn the
  ad hoc data present in Linux configuration files into a structured, dictionary
  representation.
\item We used 11 benchmarks from synchronization tasks between a variety of
  formats derived from real-world examples and the bidirectional programming
  literature. These tasks range from synchronizing REST and JSON web resource
  descriptions to synchronizing BibTeX and EndNote citation descriptions.
\end{enumerate}

A realistic benchmarks suite is critical in answering the first research
question. To determine whether our algorithm is fast enough to be used in
everyday development, we need to evaluate whether we can solve real-world
problems efficiently. All three of our benchmark sources test real life
problems: the data cleaning tasks presented in Flash Fill are either derived
from online help forums or taken from the Excel product team; Augeas is a
utility that transforms Linux configuration files into a manageable dictionary
form; the many of the remaining benchmarks are from synchronizing real-life data
formats, like BibTeX and EndNote.

\subsection{Usefulness in Everyday Development}

To begin, we measure the run time of our algorithm in 2 modes:

\begin{tabulary}{\linewidth}{rL}
  \SSOpt{}: & The symmetric synthesis algorithm with all optimizations enabled.\\
  \SSNCOpt{}: & The symmetric synthesis algorithm, but compositional synthesis not enabled.\\
\end{tabulary}\\

Recall that compositional synthesis exploits user annotations to break a
benchmark into a series of smaller synthesis steps. In our experience,
compositional synthesis (SS mode) allows our system to scale to arbitrarily
large and complex formats. However, SSNC mode, which uses no such annotations
and synthesizes a complete lens all at once provides a useful experimental
stress test for the system. 

\begin{figure}
  \includegraphics{generated-graphs/times}
  \caption{Number of benchmarks that can be solved by a given algorithm in a
    given amount of time. \SSOpt{} is the full symmetric synthesis algorithm.
    \SSNCOpt{} is the symmetric synthesis algorithm without using a library of
    existing lenses. Our symmetric synthesis algorithm is able to complete all
    benchmarks in our benchmark suite in under 30 seconds, and is able to
    complete a majority of the benchmarks without using compositional
    synthesis.}
  \label{fig:times}
\end{figure}

For each benchmark in our benchmark suite, we ran every mode on it with a
timeout of 30 seconds, and averaged the result over 5 runs.
Figure~\ref{fig:times} summarizes the results of these tests. We find that our
algorithm is able to synthesize all of the benchmarks in our benchmark suite in
under 30 seconds. Without compositional synthesis, the synthesis algorithm is
able to solve 26 problem instances. Recall from
Section~\ref{subsec:optimizations} that users may tune the termination metric.
Success on this set of benchmarks requires we tune that termination codition
(e.g. for some benchmarks, allowing the system flexibility to spend more time
considering more of the search space). In
Section~\ref{subsec:effect-of-heuristics}, we will consider the effect of fixing
the termination metric. In practice, we found customizing the termination metric
to be quite easy: if manual inspection of the lens showed there were too few
bijections, we would increase the termination parameter. If synthesis took too
long, we would decrease it.

\subsection{Slowdown Compared to Bijective Synthesis}

To compare to the existing bijective synthesis algorithm, we run our symmetric
synthesis algorithm on the original Optician benchmark suite. 4 of these
benchmarks had to be slightly altered to work with our new system. We altered
these benchmarks by either providing additional examples or tuning termination parameters.
Without these alterations, the symmetric synthesis yielded a lens that fit
the specification but that was not the desired lens.

To perform this comparison, we synthesized lenses in 2 modes:

\begin{tabulary}{\linewidth}{rL}
  \SSOpt{}: & The symmetric synthesis algorithm with all optimizations enabled.\\
  \BSOpt{}: & The existing bijective synthesis
              algorithm with all optimizations enabled.\\
\end{tabulary}\\

For each benchmark in our benchmark suite, we ran every mode on it with a
timeout of 60 seconds, and averaged the result over 5 runs.
Figure~\ref{fig:times_bijective} summarizes the results of these tests. On
average, \SSOpt{} took 1.3 times (0.5 seconds) longer to complete than
\BSOpt{}. The slowest completed benchmark for both synthesis algorithms is
\texttt{xml\_to\_augeas.boom}, a benchmark that converts arbitrary XML up to
depth 3 into a serialized version of the structured dictionary representation
used in Augeas. This benchmark takes 18.9 seconds for the symmetric synthesis
algorithm to complete, and 9.3 seconds the bijective synthesis algorithm to
complete. 

\begin{figure}
  \includegraphics{generated-graphs/times_bijective}
  \caption{Number of benchmarks that can be solved by a given algorithm in a
    given amount of time. \SSOpt{} is the full symmetric synthesis algorithm.
    \BSOpt{} is the full bijective lens synthesis algorithm.}
  \label{fig:times_bijective}
\end{figure}

\subsection{The Effects of Our Heuristics}
\label{subsec:effect-of-heuristics}
We evaluate the usefulness of (1) our information-theoretic metric, and (2) our
termination heuristic.  To this end, we run our program in several different
modes:\\
\begin{tabulary}{\linewidth}{rL}
  \AnyOpt{}: & We synthesize lenses without use of the information-theoretic
  preference metric.  Once \GreedySynth finds a lens, the 
  synthesis procedure returns that lens.\\
  \FLOpt{}: &  The first time \GreedySynth finds a lens, the synthesis procedure
              returns that lens. However, \GreedySynth uses the
              information-theoretic preference metric to choose a lens.\\ 
  \CCOpt{}: & We replace our information-theoretic cost metric with one where
              the cost of the lens is the number of disonnects plus the number
              of merges.\\
  \ZTOpt{}: & \ZTOpt{} runs the algorithm with the termination parameter
              universally set to 0 (default). \\
  \TFTOpt{}: & \TFTOpt{} runs the algorithm with the
               termination parameter universally set to 25. \\
  \NTFTOpt{}: & \NTFTOpt{} runs the algorithm with the
                termination parameter universally set to -25. \\
\end{tabulary}

\begin{figure}
  \includegraphics{generated-graphs/metrics_importance}
  \caption{Number of benchmarks that synthesize the correct lens by a given
    algorithm. \AnyOpt{} provides no notion of cost, and merely returns the
    first lens it finds that satisfies the specification. \FLOpt{} provides a
    notion of cost to \GreedySynth, but once a satisfying lens is greedily
    found, that lens is returned. \CCOpt{} synthesizes lenses, where the cost of
    a lens is the number of disconnects plus the number of merges. \ZTOpt{} runs
    the algorithm with the termination parameter universally set to 0 (default).
    \TFTOpt{} runs the algorithm with the termination parameter universally set
    to 25. \NTFTOpt{} runs the algorithm with the termination parameter
    universally set to -25.}
  \label{fig:metric}
\end{figure}

We experimented with the \CCOpt{} mode to determine whether the complexity of the information-theoretic measure was really needed. Related work on string transformations has often used simpler measures such as ``avoid constants'' which align with, but are simpler than our measures. The \CCOpt{} mode is an example of such a simple measure---it operates by counting disconnects, which put a complete stop to information transfer, like constants, and merges, which eliminate the information in a union. Figure~\ref{fig:metric} summarizes the result of this experiment. We find that
our metrics are very important for finding the correct lens. Our
information-theoretic metric is critical for finding the correct lens. Indeed,
only 10 of our benchmarks succeeded when running in \CCOpt{} mode.

Our termination condition is also quite important. When running in \FLOpt{},
only 5 lenses are found. The first cluster in which a lens is found is
rarely the correct cluster. However, our termination condition is not perfect.
Sometimes users must tell the algorithm to ``keep going'' or ``stop early.''
Without termination parameters, our algorithm finds the correct lens for 36 of
our 48 benchmarks, 9 of them need help in the form of a termination parameter
for finding the correct lens. That being said, our default parameter finds a
good middle-ground. Both \TFTOpt{} and \NTFTOpt{} synthesized the correct lens
less often than \ZTOpt.  \TFTOpt{} necessitates too good a lens, so the search
procedure keeps spinning, and \NTFTOpt{} terminates early, not finding the
correct lens.
% end evaluation

% begin related-work
\section{Related Work}
\label{sec:related}

In this paper, we have designed and implemented a new, pragmatic
formulation of symmetric lenses as well as new program synthesis
techniques.  In this section, we analyze the relationship
between our simple symmetric
lenses and two previous lens languages:  classical symmetric lenses
and asymmetric lenses.  We also comment on related
program synthesis techniques.

\subsection{Relationship with Classical Lens Languages}
\label{sec:relationship}
%\paragraph*{Formalization}
%We have reformulated the problem addressed by classical
%symmetric lenses with simple symmetric lenses.

\paragraph*{Symmetric Lenses}
A classical symmetric lens $\Lens$ between $X$ and $Y$ consists of 4 components:
a complement $C$, a designated element $init \in C$, and two functions,
$\PutRSym \OfType X \times C \rightarrow Y \times C$ and $\PutLSym \OfType Y
\times C \rightarrow X \times C$, that propagate changes in one format to the
other.

In this formulation, data unique to each side are stored in the complement. When
one format is edited, the \PutR or \PutL function stitches together the edited
data with data stored in the complement. The $init$ element is the initial value
of $C$ and specifies default behavior when data is missing. For instance, to
implement the scenario in Figure~\ref{fig:minimized-representations}, the
complement would consist of a list of pairs of salary and company name.
Classical symmetric lenses satisfy the following equational laws.
\begin{centermath}
\begin{array}[b]{l@{\qquad \; \qquad}l}
  \begin{mathprooftree}
    \AxiomC{$\PutRSymOf{(x,c)} = (y,c')$}
    \UnaryInfC{$\PutLSymOf{(y,c')} = (x,c')$}
  \end{mathprooftree}
&
  \begin{mathprooftree}
    \AxiomC{$\PutLSymOf{(y,c)} = (x,c')$}
    \UnaryInfC{$\PutRSymOf{(x,c')} = (y,c')$}
  \end{mathprooftree}
\end{array}
\end{centermath}

Two classical symmetric lenses are equivalent if they output the same formats
given any sequence of edits. Formally, given a lens $\Lens \in X \leftrightarrow
Y$, an \emph{edit} for $\Lens$ is a member of $X + Y$. Consider the function
$apply$, which, given a lens and an element of that lens's complement, is a
function from sequences of edits to sequences of edits. If $apply(\Lens,c,es) =
es'$, then given complement $c$ and edits $es_i$, the lens $\Lens$ generates
$es'_i$.
\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule
  {
  }
  {
    apply(\Lens,c,[]) = []
  }
$
&
$
  \inferrule
  {
    \Lens.putr(x,c) = (y,c')\\
    apply(\Lens,c',es) = es'
  }
  {
    apply(\Lens,c,(\InLOf{x})::es) = (\InROf{y})::es'
  }
$
\end{tabular}
\end{centermath}
\[
  \inferrule
  {
    \Lens.putl(y,c) = (x,c')\\
    apply(\Lens,c',es) = es'
  }
  {
    apply(\Lens,c,(\InROf{y})::es) = (\InLOf{x})::es'
  }
\]
\noindent
Two lenses, $\Lens_1$ and $\Lens_2$, are equivalent if
$apply(\Lens_1,\Lens_1.init,es) = apply(\Lens_2,\Lens_2.init,es)$ for all $es$.

%% By describing our lenses in this complement style, we can express an incredibly
%% wide class\bcp{where is the evidence that this class of lenses is {\em
%%     usefully} wider than simple symmetric lenses?} of lenses, as these complements permit storing any amount of
%% information in them.  However, they pose problems when implementing them in
%% real-world systems and in synthesizing them.

%\paragraph*{Issues with Classical Symmetric Lenses}
%\iffalse Using symmetric lenses for synchronization forces us to maintain not
%just two files that we aim to sycnrhonize, but three. \bcp{I don't find it
%  unintuitive, and I think we should be careful not to oversell the difficulty
%  of storing the complements. It requires more engineering, but it's not rocket
%  science.}This is unintuitive, and creates many problems in practice. For
%example, consider the situation where I am synchronizing a crontab and job
%manager file. I am synchronizing across computers, so I must either maintain a
%copy of the complement on each computer, and keep them synchronized, or figure
%out a computer to hold the complement, and make sure all edits go through that
%complement. Furthermore, if I want to change the synchronization to a different
%computer, I don't need to merely make sure that my files are moved to the
%computer, I also have to make sure that I correctly move the complement, and
%hook up that complement to be used for that synchronization task. This is a huge
%divergence from other synchronization utilities\bcp{No. For example, Unison
%  maintains a database on each replica recording, for each file, what its hash
%  was after the last time the two replicas were synchronized.}, where all that
%needs to be done is maintain the files. Using those for synchronization, edits
%can be sent over the wire, and the appropriate function can stitch together
%those edits, no additional state needed. \fi

While classical symmetric lenses
are technically more expressive than simple symmetric lenses, it is unclear
whether this additional expressiveness is useful in practice. In our judgement,
the complications they introduce into synthesis did not justify the potential
additional expressiveness: because each lens has a custom
complement, one can no longer specify the put functions through input/output
examples alone. One alternative would be to enrich specifications with edit
sequentials; another would be to specify the structure of complements explicitly
(though the latter would be somewhat akin to specifying the internal state of a
program). In either case, the complexity of the specifications increases.
%% addition, users would have to specify some auxilary 
%% to specify the behavior through the observable behavior of edit sequences.
%% Second, there are lenses that require arbitrarily long edit sequences to
%% differentiate between: consider the lens that keeps two formats equal for the
%% first $k$ non-identity edits, then keeps them completely unsynchronized for all
%% future edits.  This requires an edit sequence of $k$ edits to differentiate
%% between this lens and the identity lens.  Simple symmetric lenses avoid this
%% problem by disallowing such lenses: we can't keep track of the number of
%% non-identity edits performed unless there are explicit fields in the data
%% formats keeping track of them.  While we are reducing the expressivity of our
%% lenses with this restriction, we feel the benefits outweigh the costs.

\paragraph*{Relation with Simple Symmetric Lenses} To compare classic and simple
symmetric lenses, we define an $apply$ function on simple lenses as well. If
$apply(\Lens,\None,es) = es'$, then starting with no prior data, after edit
$es_i$, the lens \Lens generates $es_i'$ (the right format if $es_i =
\InLOf{x}$, and the left format if $es_i = \InROf{y}$). If
$apply(\Lens,\SomeOf{(x,y)},es) = es'$, then starting with data $x$
and $y$ on the left and right, respectively, after edit $es_i$, the lens \Lens
generates $es_i'$.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule
  {
  }
  {
    apply(\Lens,xyo,[]) = []
  }
$
&
$
  \inferrule
  {
    \Lens.\CreateROf{x} = y\\
    apply(\Lens,\SomeOf{(x,y)},es) = es'
  }
  {
    apply(l,\None,\InLOf{x}::es) = \InROf{y}::es'
  }
$
\end{tabular}
\end{centermath}
\[
  \inferrule
  {
    \Lens.\CreateLOf{y} = x\\
    apply(\Lens,\SomeOf{(x,y)},es) = es'
  }
  {
    apply(l,\None,\InROf{y}::es) = \InLOf{x}::es'
  }
\]
\[
  \inferrule
  {
    \Lens.\PutROf{x'}{y}  = y'\\
    apply(\Lens,\SomeOf{(x',y')},es) = es'
  }
  {
    apply(l,\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'
  }
\]
\[
  \inferrule
  {
    \Lens.\PutLOf{y'}{x}  = x'\\
    apply(\Lens,\SomeOf{(x',y')},es) = es'
  }
  {
    apply(l,\SomeOf{(x,y)},\InROf{y'}::es) = \InLOf{x'}::es'
  }
\]

Next, we define \emph{forgetful symmetric
  lenses} to be symmetric lenses that satisfy the following additional laws.
\begin{equation}
  \tag{\ForgetfulRL}
  \begin{mathprooftree}
    \AxiomC{$\Lens.putr(x,c_1) = (\_,c_1')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putr(x,c_2) = (\_,c_2')$}
    \AxiomC{$\Lens.putl(y,c_1') = (\_,c_1'')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putl(y,c_2') = (\_,c_2'')$}
    \def\extraVskip{2pt}
    \singleLine
    \BinaryInfC{$c_1'' = c_2''$}
  \end{mathprooftree}
\end{equation}
\begin{equation}
  \tag{\ForgetfulLR}
  \begin{mathprooftree}
    \AxiomC{$\Lens.putl(y,c_1) = (\_,c_1')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putl(y,c_2) = (\_,c_2')$}
    \AxiomC{$putr(x,c_1') = (\_,c_1'')$}
    \def\extraVskip{.5pt}
    \noLine 
    \UnaryInfC{$\Lens.putr(x,c_2') = (\_,c_2'')$}
    \def\extraVskip{2pt}
    \singleLine
    \BinaryInfC{$c_1'' = c_2''$}
  \end{mathprooftree}
\end{equation}

Intuitively, these equations state that complements are uniquely determined by
the most recently input $x$ and $y$. Hence, such lenses correspond exactly with
simple symmetric lenses, where all state is maintained by the current state of
the $x$ and $y$ data. Forgetful symmetric lenses express exactly the same
$apply$ function as simple symmetric lenses.

\begin{theorem}
  Let $\Lens$ be a classical symmetric lens. The lens $\Lens$ is equivalent to a forgetful
  lens if, and only if, there exists a simple symmetric lens $\Lens'$ where
  $apply(\Lens,\Lens.init,es) = apply(\Lens',\None,es)$, for all put sequences $es$.
\end{theorem}

\paragraph*{Asymmetric Lenses}
Formally, an {\em asymmetric lens} $ \ell : S \Leftrightarrow V$ is a triple of functions $\ell.\get : S \longrightarrow V$, $\ell.\pput : V \longrightarrow S \longrightarrow S$ and $\ell.\create : V \longrightarrow S$ satisfying the following laws \cite{Focal2005-long2}:
\begin{align*}
\ell.\get \; (\ell.\pput \; s \; v) &= v \tag{PUTGET}\\
\ell.\pput \; s \; (\ell.\get \; s) &= s \tag{GETPUT}\\
\ell.\get \; (\ell.\create \; v) &= v \tag{CREATEGET}
\end{align*}
Despite being less expressive than symmetric lenses, simple symmetric lenses are
strictly more expressive than classical asymmetric lenses.

\begin{theorem}
  Let $\Lens$ be an asymmetric lens. $\Lens$ is also a simple symmetric lens,
  where:
  \begin{center}
    \begin{tabular}{rcl@{\hspace*{3em}}rcl}
      $\Lens.\CreateLOf{y}$ & $=$ & $\Lens.create \App y$
      & $\Lens.\CreateROf{x}$ & $=$ & $\Lens.get \App x$\\
      $\Lens.\PutLOf{y}{x}$ & $=$ & $\Lens.put \App y \App x$
      & $\Lens.\PutROf{x}{y}$ & $=$ & $\Lens.get \App x$
    \end{tabular}
  \end{center}
\end{theorem}

\subsection{Data Transformation Synthesis}
Over the past decade, the programming languages community has explored
the synthesis of programs from a wide variety of angles.  One of
the key ideas is typically to narrow the program search space by focusing
on a specific domain, and imposing constraints on syntax~\cite{sygus} or
typing~\cite{augustsson-2004,gvero-pldi-2013,osera+:pldi15,feser-pldi-2015,scherer-icfp-2015,frankle+:popl16}, or both.
%, and as has been advocated
%more generally under the rubric of syntax-guided synthesis~\cite{sygus}.

Automation of string transformations, in particular, has been the focus
of much prior attention.  For example, Gulwani and others work on FlashFill
generates one-way spreadsheet transformations from input/output
examples~\cite{flashfill,le-pldi-2014}.  On the one hand,
FlashFill is easier to use because one need not specify the type of
the data being transformed.  On the other hand, this type information
makes it possible to transform more complex formats---Flash Fill
does not synthesize programs with nested loops, for instance,
and hence is incapable of synthesizing the majority of our
benchmarks, even in one direction~\cite{flashfill}.
%% Flashfill, designed
%% for transformation of the cells of spreadsheets, does not scale to
%% more complex formats
%% While this provides an easier
%% interaction model with the user than this work, it requires the algorithm to
%% learn the data formats from the examples. This makes the task much more
%% difficult for the synthesis algorithm, particularly in addressing iterations and
%% disjunctions. Prior work has shown that learning from examples and data format
%% descriptions enables synthesis of much more complex transformations than are
%% permitted by examples alone. Recent work has gone into making these algorithms
%% more robust by delaying the selection of program until seeing what further
%% inputs the program is run on~\cite{?}. By doing this, the synthesis algorithm
%% can learn additional information about the formats from the use of the program.

All pragmatic synthesis algorithms use heuristics of one kind or another.  One of the
goals of the current paper is to try to ground those heuristics in a broader theory,
information theory,
with the hope that this theory may inform future design decisions and help us understand
heuristics crafted in other tools and possibly in other domains.  For instance, we
speculate that some of the heuristics used in
FlashFill (to take one well-documented example) may be connected to some of the principles
laid out here.  For instance, Flash Fill prioritizes the substring constructor over the
constant string constructor when ranking possible programs. Such a choice is
consistent with our information-theoretic viewpoint as the constant function
throws away a great deal of information about the source string being
transformed. Likewise, Flash Fill prefers ``wider'' character classes over
``narrower'' ones. Again such a choice is implied by information theory -- the
wider class preserves more information during translation.  More broadly, we
hope our information-theoretic analysis provides a basis for
understanding the heuristic choices made in related work.

%% In many of these synthesis algorithms the correct transformation is chosen by
%% principals like ``minimize constants''~\cite{?,?,?} and ``most specific
%% generalization''~\cite{?,?,?}. We are the first work to our knowledge to use an
%% information-theoretic measure for finding the correct transformation. However,
%% much of our metrics are compatible with existing metrics: avoiding \Disconnect
%% lenses minimizes constants and creates more specfic transformations (\Disconnect
%% lenses permit more synchronized data).

As discussed in the introduction,
the Optician tool~\cite{optician,maina+:quotient-synthesis} was a building block for
our work.  Optician synthesized bijective transformations~\cite{optician} and
bijections modulo quotients~\cite{maina+:quotient-synthesis}, but could
not synthesize more complex bidirectional transformations where one format contains
important information not present in the other---a common situation in the real
world.  From a technical perspective, the first key novelty in our work involves the definition, theory,
analysis, and implementation of a new class of simple symmetric lenses, designed
for synthesis.  The second key technical innovation involves the use of stochastic
regular expressions and information theory to guide the search for program transformations.
As mentioned earlier, we believe such information-theoretic techniques may have broad utility
in helping us understand how to formulate a search for a data transformation function.
%% The central contributions
%% only synchronized transformations between formats in
%% bijective correspondence, but few formats satisfy that constraint. Recent
%% enhancements have permitted synthesis of more expressive lenses, quotient
%% bijective lenses. These enhancements were made by strengthening the
%% specifications from regular expressions to QREs, regular expressions annotated
%% with information on normal forms of the language. This enhancement permits
%% synthesizing transformations between formats whose normal forms are in bijective
%% correspondence. While we have not integrated our system to permit QRE
%% specifications, we see no reason the two systems cannot be integrated.

While our tool uses types and examples to specify invertable transformations, other
tools have been shown to synthesize a backwards transformation from ordinary code designed
to implement the forwards transformation.  For instance, Hu and
D'Antoni~\cite{program-inversion-symbolic-transducers} show how to invert transformations
using symbolic finite automata, and
Voigtl\"{a}nder~\cite{bidirectionalization-for-free} demonstrates how to
construct reverse transformations from forwards transformations
by exploiting parametricity properties.  These kinds of tools are very useful, but in different
circumstances from ours (namely, when one already has the code to implement one direction of
the transformation).

More broadly, information theory and probabilistic languages are common tools in
natural language understanding, machine translation, information retrieval, data
extraction and grammatical inference (see Pereira~\cite{pereira:info-theory},
for an introduction). Indeed, our work was inspired, in part, by the PADS format
inference tool~\cite{pads:synthesis}, which was in turn inspired by earlier work
on probabilistic gramatical inference and information
extraction~\cite{kushmerick-thesis,arasu:extracting}. PADS did not synthesize
data transformers, and we are not aware of the use of information-theoretic
principles in type-directed or syntax-guided synthesis of DSL programs.

%% Other work synthesizing invertible transformations was done by inverting a
%% previously defined transformation.  This has been done by exploiting
%% parametricity to invert transformations~\cite{}, and by inverting symbolic
%% finite automata~\cite{?}.

%% \subsection{Type-Directed Synthesis}

%% Type-directed synthesis uses type information to tighten specifications and
%% reduce the number of possible programs. Typically, type-directed synthesis
%% techniques use the types to orient the search space.  Our work interestingly
%% deals with types with many semantic equivalences on them. InSynth~\cite{?}
%% deals with the same problem when trying to synthesize transformations involving
%% library functions. InSynth addresses this in a similar manner to this work: by
%% normalizing the types we don't need to search through the equivalences on those
%% types.

% end related-work

% begin conclusion
\section{Conclusion}
\label{sec:conc}
We have developed a synthesis algorithm for synthesizing synchronization
functions between data formats that may not be in bijective correspondence. More
specifically, we identify a subset of symmetric lenses, simple symmetric lenses,
develop new combinators for them, and show how to synthesize them from regular
expression specifications. In order to guide the search for ``likely'' lenses,
we introduce new search principles based on information theory. Based on these
principles, we designed, implemented, and evaluated a new tool for lens
synthesis.

% end conclusion

% begin acknowledgements
\begin{acks}
\end{acks}
% end acknowledgements

\ifanon\else
\fi

% We recommend abbrvnat bibliography style.

% The bibliography should be embedded for final submission.

\bibliography{local,bcp}

\ifappendices
\appendix


\onecolumn

\paragraph*{Symmetric Lenses full Detail}
\begin{centermath}
\begin{array}[b]{l@{\qquad \; \qquad}l}
\begin{array}[b]{c}
\quad\\
  \inferrule*
  {
  }
  {
    \IdentityLensOf{\BRegex} \OfType \BRegex \Leftrightarrow \BRegex
  }
  \\
  \quad
  \end{array}
&
\begin{array}[b]{r@{\ }c@{\ }l}
    \CreateR{} \App s & = & s\\
    \CreateL{} \App s & = & s\\
    \PutR{} \App s_1 \App s_2 & = & s_1\\
    \PutL{} \App s_1 \App s_2 & = & s_1\\
  \end{array}
\end{array}
\end{centermath}
Note that the identity lens ignores the second argument in the put functions.
Because the two formats are fully synchronized, no knowledge of the prior data
is needed.

\begin{centermath}
\begin{array}[b]{l@{\qquad \; \qquad}l}
  \inferrule*
  {
    \String \in \LanguageOf{\BRegex}\\
    \StringAlt \in \LanguageOf{\BRegexAlt}
  }
  {
    \DisconnectOf{\BRegex}{\BRegexAlt}{\String}{\StringAlt}
    \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
&
  \begin{array}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String''''$ & = & $\StringAlt$\\
    $\CreateL{} \App \StringAlt'''''$ & = & $\String$\\
    $\PutR{} \App \String''' \App \StringAlt'$ & = & $\StringAlt'$\\
    $\PutL{} \App \StringAlt' \App \String'$ & = & $\String'$
  \end{array}
\end{array}
\end{centermath}

Just as the identity lens ignores the second argument in puts, disconnect lenses
ignore the first in both puts and creates.  The data is unsynchronized in these
two formats, information from one format doesn't impact the other.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad \; \qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \ConcatLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_1 \Concat \BRegexAlt_2
  }
$
&
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \SwapLensOf{\Lens_1}{\Lens_2} \OfType \BRegex_1 \Concat \BRegex_2
    \Leftrightarrow
    \BRegexAlt_2 \Concat \BRegexAlt_1
  }
$
\end{tabular}
\end{centermath}
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String_1 \String_2$ & = & $(\Lens_1.\CreateROf{\String_1})(\Lens_2.\CreateROf{\String_2})$\\
    $\CreateL{} \App \StringAlt_1 \StringAlt_2$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_1\StringAlt_2)$ & = & $(\Lens_1.\PutROf{\String_1}{\StringAlt_1})(\Lens_2.\PutROf{\String_2}{\StringAlt_2})$\\
    $\PutL{} \App (\StringAlt_1\StringAlt_2) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
  \end{tabular}
\end{center}

Concat is similar to concatenation in existing string lens languages like
Boomerang.  For such terms, we do not provide the semantics, and merely refer readers to existing work. The swap combinator is similar to concat, though the second regular expression
is swapped.
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String_1\String_2$ & = & $(\Lens_2.\CreateROf{\String_2})(\Lens_1.\CreateROf{\String_1})$\\
    $\CreateL{} \App \StringAlt_2\StringAlt_1$ & = & $(\Lens_1.\CreateLOf{\StringAlt_1})(\Lens_2.\CreateLOf{\StringAlt_2})$\\
    $\PutR{} \App (\String_1\String_2) \App (\StringAlt_2\StringAlt_1)$ & = & $(\Lens_2.\PutROf{\String_2}{\StringAlt_2})(\Lens_1.\PutROf{\String_1}{\StringAlt_1})$\\
    $\PutL{} \App (\StringAlt_2\StringAlt_1) \App (\String_1\String_2)$ & = & $(\Lens_1.\PutLOf{\StringAlt_1}{\String_1})(\Lens_2.\PutLOf{\StringAlt_2}{\String_2})$\\
  \end{tabular}
\end{center}
\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt_2
  }
  {
    \OrLensOf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
  $
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
      \Lens_2.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
      \end{cases*}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
        \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
        \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_2}$\\
        \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2} \BooleanAnd \StringAlt\in\LanguageOf{\BRegexAlt_1}$
      \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1} \BooleanAnd \String\in\LanguageOf{\BRegex_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2} \BooleanAnd \String\in\LanguageOf{\BRegex_2}$\\
        \Lens_1.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1} \BooleanAnd \String\in\LanguageOf{\BRegex_2}$\\
        \Lens_2.\CreateLOf{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2} \BooleanAnd \String\in\LanguageOf{\BRegex_1}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}
The \OrLens lens deals with data that can come in one form or another. If the
data gets changed from one format to the other, information in the old format is
lost.
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String_1\ldots\String_n$
    & =
    & $(\Lens.\CreateROf{\String_1})\ldots(\Lens.\CreateROf{\String_n})$\\
    
    $\CreateL{} \App \StringAlt_1\ldots\StringAlt_n$
    & =
    & $(\Lens.\CreateLOf{\StringAlt_1})\ldots(\Lens.\CreateLOf{\StringAlt_n})$\\
    
    $\PutR{} \App (\String_1\ldots\String_n) \App (\StringAlt_1\ldots\StringAlt_m)$
    & =
    & $\StringAlt_1'\ldots\StringAlt_n'$ where $\StringAlt_i' =
      \begin{cases*}
        \Lens.\PutROf{\String_i}{\StringAlt_i} & if $i \leq m$\\
        \Lens.\CreateROf{\String_i} & otherwise
      \end{cases*}$\\
    $\PutL{} \App (\StringAlt_1\ldots\StringAlt_m) \App (\String_1\ldots\String_n)$
    & =
    & $\String_1'\ldots\String_n'$ where $\String_i' =
      \begin{cases*}
        \Lens.\PutROf{\StringAlt_i}{\String_i} & if $i \leq n$\\
        \Lens.\CreateROf{\StringAlt_i} & otherwise
      \end{cases*}$
  \end{tabular}
\end{center}
\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
  \centering
  \inferrule*
  {
    \Lens_1 \OfType \BRegex_1 \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegex_2 \Leftrightarrow \BRegexAlt
  }
  {
    \MergeROf{\Lens_1}{\Lens_2} \OfType
    \RegexOr{\BRegex_1}{\BRegex_2}
    \Leftrightarrow
    \BRegexAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\CreateROf{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\Lens_1.\CreateLOf{\StringAlt}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_1}$\\
      \Lens_2.\PutROf{\String}{\StringAlt} & if $\String\in\LanguageOf{\BRegex_2}$
    \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\String\in\LanguageOf{\BRegex_2}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}

The \MergeR lens is interesting because it merges data where one data can be in
two formats, and one data has only one format. In previous
work~\cite{Boomerang}, this was combined into \OrLens{}, where
\OrLens{} could have ambiguous types, but we find it more clear to have explicit
merge operators: it is easier to see what lens the synthesis algorithm is
creating.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt_1\\
    \Lens_2 \OfType \BRegex \Leftrightarrow \BRegexAlt_2
  }
  {
    \MergeLOf{\Lens_1}{\Lens_2} \OfType
    \BRegex
    \Leftrightarrow
    \RegexOr{\BRegexAlt_1}{\BRegexAlt_2}
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$
    & =
    & $\Lens_1.\CreateROf{\String}$\\
    
    $\CreateL{} \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
      \Lens_2.\CreateLOf{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
      \end{cases*}$\\
    
    $\PutR{} \App \String \App \StringAlt$
    & =
    & $\begin{cases*}
      \Lens_1.\PutROf{\String}{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
      \Lens_2.\PutROf{\String}{\StringAlt} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
    \end{cases*}$\\
    
    $\PutL{} \App \StringAlt \App \String$
    & =
    & $\begin{cases*}
        \Lens_1.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_1}$\\
        \Lens_2.\PutLOf{\StringAlt}{\String} & if $\StringAlt\in\LanguageOf{\BRegexAlt_2}$
      \end{cases*}$\\
  \end{tabular}
\end{tabular}
\end{centermath}
The \MergeL lens is symmetric to \MergeR.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
  $
  \inferrule*
  {
    \Lens_1 \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \Lens_2 \OfType \BRegexAlt \Leftrightarrow \BRegexAltAlt\\
  }
  {
    \ComposeLensOf{\Lens_1}{\Lens_2} \OfType
    \BRegex \Leftrightarrow \BRegexAltAlt
  }
$
&
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \String$ & = & $\Lens_2.\CreateROf{(\Lens_1.\CreateROf{\String})}$\\
    $\CreateL{} \App \StringAlt$ & = & $\Lens_1.\CreateLOf{(\Lens_2.\CreateLOf{\StringAlt})}$\\
    $\PutR{} \App \String \App \StringAltAlt$ & = & $\Lens_2.\PutROf{(\Lens_1.\PutROf{\String}{(\Lens_2.\CreateLOf{\StringAltAlt})})}{\StringAltAlt}$\\
    $\PutL{} \App \StringAltAlt \App \String$ & = & $\Lens_1.\PutLOf{(\Lens_2.\PutLOf{\StringAltAlt}{(\Lens_2.\CreateROf{\String})})}{\String}$
  \end{tabular}
\end{tabular}
\end{centermath}
Composing is interesting in the put functions. Because puts require intermediary
data, we recreate that intermediary data with creates.

\begin{centermath}
\begin{tabular}[b]{l@{\qquad}l}
$
\inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \IterateLensOf{\Lens} \OfType
    \StarOf{\BRegex}
    \Leftrightarrow
    \StarOf{\BRegexAlt}
  }
  $
  &
  $
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt
  }
  {
    \InvertOf{\Lens} \OfType \BRegexAlt \Leftrightarrow \BRegex
  }
  $
\end{tabular}
\end{centermath}
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
    $\CreateR{} \App \StringAlt$ & = & $\Lens.\CreateLOf{\StringAlt}$\\
    $\CreateL{} \App \String$ & = & $\Lens.\CreateROf{\String}$\\
    $\PutR{} \App \StringAlt \App \String$ & = & $\Lens.\PutLOf{\StringAlt}{\String}$\\
    $\PutL{} \App \String \App \StringAlt$ & = & $\Lens.\PutROf{\String}{\StringAlt}$
  \end{tabular}
\end{center}
The \IterateLens lens deals with iterated data, while inverting reverses the direction of a lens: creating on the right becomes creating on the left and vice versa, and putting on the right becomes putting on the left and vice versa. The invert combonator is particularly useful when chaining many compositions together, as it can be used to align the central types.
\[
  \centering
  \inferrule*
  {
    \Lens \OfType \BRegex \Leftrightarrow \BRegexAlt\\
    \BRegex \SSREquiv \BRegex'\\
    \BRegexAlt \SSREquiv \BRegexAlt'
  }
  {
    \Lens \OfType \BRegex' \Leftrightarrow \BRegexAlt'
  }
\]

Type equivalence enables a lens of type $S \Leftrightarrow T$ to be used as a
lens of type $S' \Leftrightarrow T'$ if $S$ equivalent to $S'$ and $T$ is
equivalent to $T'$. Type equivalence is useful both for addressing type
annotations, and for making well-typed compositions.

\paragraph*{Symmetric DNF Lenses: Syntax, Cost, Typing, and Semantics}

\paragraph*{Syntax}
Roughly speaking, symmetric DNF lenses are an n-ary union of symmetric sequence
lenses, which are, in turn, an n-ary sequence of atomic lenses. Atomic lenses
are iterations of symmetric DNF lenses. In the following syntax, the
nonterminals $i$, $j$, $p$, $q$, $r$, $c$, and $d$ all represent natural
numbers. The nonterminals $\String$ and $\StringAlt$ represent strings.
\begin{center}
  \begin{tabular}{@{}r@{\ }c@{}l@{}}
    % REGEX
    \SAtomLens{} & \GEq{} & $\StarOf{\SDNFLens}$ \\
    \SSQLens{} & \GEq{} & $(\SSQLensOf{(i_1,j_1,\SAtomLens_1)\SeqLSep
                          \ldots\SeqLSep
                          (i_p,j_p,\SAtomLens_p)}
                          ,\ListOf{(\String_1,\Atom_1);\ldots;(\String_q,\Atom_q)}
                          ,\ListOf{(\StringAlt_1,\AtomAlt_1);\ldots;(\StringAlt_r,\AtomAlt_r)})$ \\
    \SDNFLens{} & \GEq{} & $(\SDNFLensOf{(i_1,j_1,\SSQLens_1)\DNFLSep
                           \ldots\DNFLSep
                           (i_p,j_p,\SSQLens_p)}
                           ,\ListOf{c_1;\ldots;c_q}
                           ,\ListOf{d_1;\ldots;d_r})$ \\
  \end{tabular}
\end{center}

\paragraph*{Information-Theoretic Cost Metric}
Much like we defined a syntactic means to find the expected number of bits to
recover string from a synchronized string in another format for simple symmetric
string lenses, we do the same for symmetric DNF lenses. Unlike simple symmetric
string lenses, DNF lenses do not have composition, so the entropy can be defined
over all terms. $\LEntropyOf{\DNFRegex \Given \SDNFLens, \DNFRegexAlt}$ is the
expected number of bits required to recover a string in $\DNFRegex$ from a
synchronized string in $\DNFRegexAlt$.

\[
  \begin{array}{rl}
    & \LEntropyOf{\DNFOf{\Sequence_1 \DNFSep \ldots \DNFSep \Sequence_n}\\
    & \hspace*{1.21em}\Given
      (\SDNFLensOf{(i_1,j_1,\SSQLens_1)\DNFLSep
      \ldots\DNFLSep
      (i_p,j_p,\SSQLens_p)}
      ,\ListOf{c_1;\ldots;c_q}
      ,\ListOf{d_1;\ldots;d_r})\\
    & \hspace*{1.21em},~\DNFOf{\SequenceAlt_1 \DNFSep \ldots \DNFSep \SequenceAlt_m}}\\
    = & \frac{\Sigma_{j=1}^m(H_j)}{m}\\
    & \text{where } H_j = (0,\Sigma_{\SetOf{k\SuchThat j_k = j}}
      \LEntropyOf{\Sequence_{i_k}\Given\SequenceLens_k,\SequenceAlt_j})
  \end{array}
\]

This entropy calculation for symmetric DNF lenses requires a similar entropy
calculation for symmetric sequence lenses and symmetric atom lenses.

\[
  \begin{array}{rl}
      & \REntropyOf{
        \SequenceOf{\String_0,\Atom_1,\ldots,\Atom_n,\String_n}\\
      & \hspace*{1em}\Given
        (\SSQLensOf{(i_1,j_1,\SAtomLens_1)\SeqLSep
        \ldots\SeqLSep
        (i_p,j_p,\SAtomLens_p)}
        ,\ListOf{(k_1,\String_1);\ldots;(k_q,\String_q)}
        ,\ListOf{(l_1,\StringAlt_1);\ldots;(l_r,\StringAlt_r)})\\
      & \hspace*{1.21em},~
        \SequenceOf{\StringAlt_0,\AtomAlt_1,\ldots,\AtomAlt_m,\StringAlt_m}}\\
      =
      & \Sigma_{x=1}^p\REntropyOf{\Atom_{i_x} \Given \AtomAlt_{i_x},\AtomLens_x} +
        \Sigma_{x=1}^q\REntropyOf{\Atom_{k_x}}
  \end{array}
\]

The entropy calculation for symmetric sequence lenses requires a similar entropy
calculation for symmetric atom lenses, which in turn relies on the entropy
calculation for symmetric DNF lenses.

\[\begin{array}{rl}
      & \REntropyOf{\PRegexStar{\DNFRegexAlt}{\ProbabilityAlt} \Given \PRegexStar{\DNFRegex}{\Probability},\StarOf{\SDNFLens}}\\
      =
      & \frac{\Probability}{1-\Probability}\REntropyOf{\DNFRegexAlt\Given\DNFRegex,\SDNFLens}
  \end{array}
\]
The expected number of bits required to recover a string in $\DNFRegexAlt$ from
a synchronized string in $\DNFRegex$, $\REntropyOf{\DNFRegexAlt \Given
  \SDNFLens, \DNFRegex}$ is defined symmetrically.


The typing judgment is a 3-ary relation over a single DNF lens, and two DNF
regular expressions. If $\SDNFLens \OfType \DNFRegex \Leftrightarrow
\DNFRegexAlt$, then the $\SDNFLens.\CreateR$, $\SDNFLens.\CreateL$,
$\SDNFLens.\PutR$, and $\SDNFLens.\PutL$ functions form a symmetric lens.

The typing judgement has 3 components. The first is the sublens components,
confirming that the sequence lenses the DNF lens is comprised of are all
well-typed. The second guarantees that if each sequence on the left has a
sequence lens that can be used for \CreateR{}s and \PutR{}s. The last guarantees
the same for sequences on the right, with \CreateL{} and \PutL{}.

\[
  \inferrule*
  {
    \SSQLens_1 \OfType \Sequence_{i_1} \Leftrightarrow \SequenceAlt_{j_1}\\
    \ldots\\
    \SSQLens_p \OfType \Sequence_{i_p} \Leftrightarrow \SequenceAlt_{j_p}\\\\
    i_{c_1} = 1\\
    \ldots\\
    i_{c_q} = q\\\\
    j_{d_1} = 1\\
    \ldots\\
    j_{d_r} = r
  }
  {
    (\SDNFLensOf{(i_1,j_1,\SSQLens_1)\DNFLSep
      \ldots\DNFLSep
      (i_p,j_p,\SSQLens_p)}
    ,\ListOf{c_1;\ldots;c_q}
    ,\ListOf{d_1;\ldots;d_r})
    \OfType\\\\
    \DNFOf{(\Sequence_1,\Probability_1) \DNFSep \ldots \DNFSep (\Sequence_q,\Probability_q)}
    \Leftrightarrow
    \DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1) \DNFSep \ldots \DNFSep (\SequenceAlt_r,\ProbabilityAlt_q)}
  }
\]

The \CreateR{} function looks for the sequence the provided string matches. If
the string matches sequence $\Sequence_x$, then the lens will look in the create
list at position $x$ to find which sequence lens to use. Then, the sequence lens
transforms the given string using that sequence lens.

The \PutR{} function finds what pairs sequences the input source and view
strings match.  If there that pair of sequences have a sequence lens between
them, then the DNF lens merely performs that sequence lens on the provided
strings.  If there isn't a pair of sequence lenses between them, then \CreateR{}
is performed on the source, with the view forgotten.

The \CreateL{} and \PutL{} functions are defined symmetrically.

\begin{tabular}{@{}r@{\ }c@{\ }l@{}}
  $\CreateR{} \App s$ & = & $\SSQLens_{c_x}.\CreateR{} \App s$ if $s \in \Sequence_x$\\
  $\CreateL{} \App v$ & = & $\SSQLens_{d_y}.\CreateL{} \App v$ if $v \in \SequenceAlt_y$\\
  $\PutR{} \App s \App v$ & = &
                               $\begin{cases*}
                                 \SSQLens_x.\PutR{} \App s \App v & if $s \in \Sequence_{i_x}$ and $v \in \SequenceAlt_{j_x}$\\
                                 \CreateR{} \App s & if $\nexists x.$ $s \in \Sequence_{i_x}$ and $v \in \SequenceAlt_{j_x}$
                               \end{cases*}$\\
  $\PutL{} \App v \App s$ & = &
                               $\begin{cases*}
                                 \SSQLens_y.\PutL{} \App v \App s & if $v \in \SequenceAlt_{j_y}$ and $s \in \Sequence_{i_y}$\\
                                 \CreateL{} \App v & if $\nexists y.$ $v \in \SequenceAlt_{j_y}$ and $s \in \Sequence_{i_y}$
                               \end{cases*}$
\end{tabular}

\paragraph*{Symmetric Sequence Lenses: Typing and Semantics}
The typing judgment is a 3-ary relation over a single Sequence lens, and two
sequences. If $\SSQLens \OfType \Sequence \Leftrightarrow \SequenceAlt$, then
the $\SSQLens.\CreateR$, $\SSQLens.\CreateL$, $\SSQLens.\PutR$, and
$\SSQLens.\PutL$ functions form a symmetric lens.

The typing judgement has 4 components. The first is the sublens components,
confirming that the atom lenses the sequence lens is comprised of all are
well-typed. The second guarantees that if each string that will be used for
\CreateR{}s are members of the correct atoms.  The third guarantees
the same for strings and atoms on the right, with \CreateL.  The last guarantees
that each atom is mapped by at most one atom lens.

\[
  \inferrule* {
    \SAtomLens_1 \OfType \Atom_{i_1} \Leftrightarrow \AtomAlt_{j_1}\\
    \ldots\\
    \SAtomLens_p \OfType \Atom_{i_p} \Leftrightarrow \AtomAlt_{j_p}\\\\
    \String_{c_1} \in \Atom_{c_1}\\
    \ldots\\
    \String_{c_{q'}} \in \Atom_{c_{q'}}\\\\
    \StringAlt_{d_1} \in \AtomAlt_{d_1}\\
    \ldots\\
    \StringAlt_{d_{r'}} \in \AtomAlt_{d_{r'}}\\\\
    i_x = i_y \BooleanImplies x = y\\
    j_x = j_y \BooleanImplies x = y } {
    (\SSQLensOf{(i_1,j_1,\SAtomLens_1)\SeqLSep \ldots\SeqLSep
      (i_p,j_p,\SAtomLens_p)}
    ,\ListOf{(\String_{c_1},\Atom_{c_1});\ldots;(\String_{c_{q'}},\Atom_{c_{q'}})}
    ,\ListOf{(\StringAlt_{d_1},\Atom_{d_1});\ldots;(\StringAlt_{d_r},\Atom_{d_r})})\\
    \OfType \SequenceOf{\String_0'''' \SeqSep \Atom_1 \SeqSep \ldots \SeqSep
      \Atom_{q'} \SeqSep \String_{q}'} \Leftrightarrow \SequenceOf{\StringAlt_0'
      \SeqSep \AtomAlt_1 \SeqSep \ldots \SeqSep \AtomAlt_r \SeqSep
      \StringAlt_{r}'} }
\]

For each component of the string matching an atom, the \CreateR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the sequence lens puts the provided string into the
default string for the target atom. If there is no such atom lens, then the
sequence lens merely uses the default string.

For each component of the string matching an atom, the \PutR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the atom lens puts the provided string of the source atom into the
string of the target atom. If there is no such atom lens, then the
sequence lens merely recovers the target's string.

The \CreateL{} and \PutL{} functions are defined symmetrically.

\begin{tabular}{@{}r@{\ }c@{\ }l@{}}
  $\CreateR{} \App \String_0'\Concat \String_1'' \Concat \ldots \Concat \String_q'' \Concat \String_q'$
  & = 
  & $\StringAlt_0' \Concat \StringAlt_1'' \Concat \ldots \Concat
    \StringAlt_r'' \Concat \StringAlt_r'$\\
  & & where $\StringAlt_y'' =
    \begin{cases*}
      \SAtomLens_k.\PutROf{\String_{i_k}''}{\StringAlt_y} & if $j_k = y$\\
      \StringAlt_y & if $\nexists k. j_k = y$\\
    \end{cases*}$\\
  $\CreateL{} \App \StringAlt_0'\Concat \StringAlt_1'' \Concat \ldots \Concat \StringAlt_q''
  \Concat \StringAlt_q'$
  & = 
  & $\String_0' \Concat \String_1'' \Concat \ldots \Concat
    \String_r'' \Concat \String_r'$\\
  & & where $\String_x'' =
    \begin{cases*}
      \SAtomLens_k.\PutROf{\StringAlt_{j_k}''}{\String_x} & if $i_k = x$\\
      \String_x & if $\nexists k. i_k = x$\\
    \end{cases*}$\\
  $\PutR{} \App (\String_0'\Concat \String_1'' \Concat \ldots \Concat \String_q'' \Concat \String_q') \App (\StringAlt_0'\Concat \StringAlt_1'' \Concat \ldots \Concat \StringAlt_q'' \Concat \StringAlt_q')$
  & =
  & $\StringAlt_0'\Concat \StringAlt_1''' \Concat \ldots \Concat \StringAlt_q''' \Concat \StringAlt_q'$\\
  & & where
      $t_y''' =
      \begin{cases*}
        \SAtomLens_k.\PutROf{\String_{i_k}''}{\StringAlt_{y}''} & if $j_k = y$\\
        \StringAlt_y'' & if $\nexists k. j_k = y$\\
      \end{cases*}$\\
  $\PutL{} \App (\StringAlt_0'\Concat \StringAlt_1'' \Concat \ldots \Concat \StringAlt_q'') \Concat (\StringAlt_q' \App \String_0'\Concat \String_1'' \Concat \ldots \Concat \String_q'' \Concat \String_q')$
  & =
  & $\String_0'\Concat \String_1''' \Concat \ldots \Concat \String_r''' \Concat \String_r'$\\
  & & where
      $s_x''' =
      \begin{cases*}
        \SAtomLens_k.\PutLOf{\StringAlt_{j_k}''}{\String_{x}''} & if $i_k = x$\\
        \String_x'' & if $\nexists k. i_k = x$\\
      \end{cases*}$\\
\end{tabular}

\paragraph*{Symmetric Atom Lenses: Typing and Semantics}
The typing judgment is a 3-ary relation over a single atom lens, and two
atoms. If $\SAtomLens \OfType \Atom \Leftrightarrow \AtomAlt$, then
the $\SAtomLens.\CreateR$, $\SAtomLens.\CreateL$, $\SAtomLens.\PutR$, and
$\SAtomLens.\PutL$ functions form a symmetric lens.

The typing judgement just confirms that the DNF lens that comprises the
sequence lens is also well typed.

\[
  \inferrule*
  {
    \SDNFLens \OfType \DNFRegex \Leftrightarrow \DNFRegexAlt
  }
  {
    \StarOf{\SDNFLens}
    \OfType \PRegexStar{\DNFRegex}{\Probability}
    \Leftrightarrow \PRegexStar{\DNFRegexAlt}{\ProbabilityAlt}
  }
\]

For each component of the string matching an atom, the \CreateR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the sequence lens puts the provided string into the
default string for the target atom. If there is no such atom lens, then the
sequence lens merely uses the default string.

For each component of the string matching an atom, the \PutR function looks
for the atom lens that maps on the atom. If there is such an atom lens,
\SAtomLens, then that the atom lens puts the provided string of the source atom into the
string of the target atom. If there is no such atom lens, then the
sequence lens merely recovers the target's string.

The \CreateL{} and \PutL{} functions are defined symmetrically.

\begin{tabular}{@{}r@{\ }c@{\ }l@{}}
  $\CreateR{} \App \String_0 \Concat \ldots \Concat \String_n$
  & = 
  & $\StringAlt_1 \Concat \ldots \Concat \StringAlt_n$
  where $\StringAlt_i = \SDNFLens.\CreateR \App \String_i$\\
  $\CreateL{} \App \StringAlt_0 \Concat \ldots \Concat \StringAlt_m$
  & = 
  & $\String_1 \Concat \ldots \Concat \String_m$
  where $\String_i = \SDNFLens.\CreateL \App \StringAlt_i$\\
  $\PutR{} \App (\String_0 \Concat \ldots \Concat \String_n) \App
  (\StringAlt_1 \Concat \ldots \Concat \StringAlt_m)$
  & = 
  & $\StringAlt_1' \Concat \ldots \Concat \StringAlt_n'$
    where $\StringAlt_i' =
    \begin{cases*}
      \SDNFLens.\PutR \App \String_i \App \StringAlt_i & if $i \leq m$\\
      \SDNFLens.\CreateR \App \String_i & otherwise
    \end{cases*}$\\
  $\PutL{} \App (\StringAlt_1 \Concat \ldots \Concat \StringAlt_m) \App
  (\String_0 \Concat \ldots \Concat \String_n)$
  & = 
  & $\String_1' \Concat \ldots \Concat \String_m'$
    where $\String_i' =
    \begin{cases*}
      \SDNFLens.\PutL \App \StringAlt_i \App \String_i & if $i \leq n$\\
      \SDNFLens.\CreateL \App \StringAlt_i & otherwise
    \end{cases*}$\\
\end{tabular}


\section{Forgetful Symmetric Lenses}

\begin{property}[Starting Forgetfulness RL]
  \label{prop:forget-rl}
  Let $\Lens$ be a forgetful symmetric lens.  If $(x_1',c_1') = \Lens.\PutL \App
  (y,\Snd \App (\Lens.\PutR \App (x,c_1)))$, and
  $(x_2',c_2') = \Lens.\PutL \App
  (y,\Snd \App (\Lens.\PutR \App (x,c_2)))$, then $x_1' = x_2'$.
\end{property}
\begin{proof}
  By \ForgetfulRL, $c_1' = c_2'$. We know $(y,c_1') = \Lens.\PutR \App
  (x_1',c_1')$ and $(y,c_1') = \Lens.\PutR \App (x_2',c_1')$ by \PutLR. By
  \PutRL, we know $(x_1' = \Lens.\PutL \App (y,c_1'))$ and $(x_2' = \Lens.\PutL
  \App (y,c_1')))$. Therefore, by transitivity of equality, $x_1' = x_2'$.
\end{proof}

\begin{property}[Starting Forgetfulness LR]
  \label{prop:forget-lr}
  Let $\Lens$ be a forgetful symmetric lens.  If $(y_1',c_1') = \Lens.\PutR \App
  (x,\Snd \App (\Lens.\PutL \App (y,c_1)))$, and
  $(x_2',c_2') = \Lens.\PutL \App
  (x,\Snd \App (\Lens.\PutR \App (y,c_2)))$,
  then $x_1' = x_2'$.
\end{property}
\begin{proof}
  Symmetric to Starting Forgetfulness RL.
\end{proof}

\begin{definition}[S]
  Let $\Lens$ be a forgetful lens.

  Consider the following four functions $S(\Lens)$, that we wish to satisfy the
  simple symmetric lens laws.

  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
      $\CreateR{} \App s$
      & =
      & $\Fst \App (\Lens.\PutR{} \App (s,\Lens.init))$\\
      
      $\CreateL{} \App v$
      & =
      & $\Fst \App (\Lens.\PutL{} \App (v,\Lens.init))$\\
      
      $\PutR{} \App s \App v$
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutL \App (v,\Lens.init)}$\\
      &
      & $\LetIn{(s',\_)}{\Lens.\PutR \App (s,c)}$\\
      &
      & $s'$\\
      
      $\PutL{} \App v \App s$
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutR \App (s,\Lens.init)}$\\
      &
      & $\LetIn{(y',\_)}{\Lens.\PutL \App (v,c)}$\\
      &
      & $y'$\\
    \end{tabular}
  \end{centering}
\end{definition}

\begin{mylemma}
  If $\Lens$ is a forgetful symmetric lens, then $S(\Lens)$ is a simple symmetric
  lens.
\end{mylemma}
\begin{proof}
  
  \CreatePutRL{}:
  
  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
      $S(\Lens).\PutLOf{(S(\Lens).\CreateROf{x})}{x}$
      & =
      & $S(\Lens).\PutLOf{(\Fst \App (\Lens.\PutR{(x,\Lens.init)}))}{x}$
      & By unfolding definitions
      \\
      
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutR \App (x,\Lens.init)}$\\
      &
      & $\LetIn{(y',\_)}{\Lens.\PutL \App (\Fst \App (\Lens.\PutR{(x,\Lens.init)}),c)}$\\
      &
      & $y'$
      & By unfolding definitions\\
      
      & =
      & $\LetIn{(y',\_)}{\Lens.\PutL \App (\Lens.\PutR \App (x,\Lens.init))}$\\
      &
      & $y'$
      & By tuple harmony \\
      
      & =
      & $x$
      & By \PutRL \\
    \end{tabular}
  \end{centering}

  \CreatePutLR{}:  Symmetric to \CreatePutRL{}

  \PutRL{}:

  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
      $S(\Lens).\PutLOf{(S(\Lens).\PutROf{x}{y})}{x}$
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutL \App (y,\Lens.init)}$\\
      & & $\LetIn{(y',c')}{\Lens.\PutR \App (x,c)}$\\
      & & $S(\Lens).\PutLOf{y'}{x}$
      & By unfolding definitions
      \\
      
      & =
      & $\LetIn{(\_,c)}{\Lens.\PutL \App (y,\Lens.init)}$\\
      & & $\LetIn{(y',c')}{\Lens.\PutR \App (x,c)}$\\
      & & $\LetIn{(\_,c'')}{\Lens.\PutR \App (x,\Lens.init)}$\\
      & & $\LetIn{(x',c''')}{\Lens.\PutL \App (y',c'')}$\\
      & & $x'$
      & By unfolding definitions
    \end{tabular}
  \end{centering}

  At this point, we know from \PutRL that $(x,c') = \Lens.\PutL \App (y',c')$.
  By Property~\ref{prop:forget-rl}, this means that $x' = x$, as desired.

  \PutLR{}:  Symmetric to \PutRL{}
\end{proof}

\begin{definition}
  Fix a symmetric lens $\Lens$ beteween $X$ and $Y$. Consider the
  function, $\SingleApp_{\Lens} \OfType (X + Y) \times \Lens.C
  \rightarrow ((X + Y) \times \Lens.C)$, defined as:

  \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
    $\SingleApp_{\Lens}(\InLOf{x},c)$
    & =
    & $\LetIn{(y,c')}{\Lens.\PutRSymOf{(x,c)}}$\\
    &
    & $(\InROf{y},c')$\\
    
    $\SingleApp_{\Lens}(\InROf{y},c)$
    & =
    & $\LetIn{(x,c')}{\Lens.\PutLSymOf{(y,c)}}$\\
    &
    & $(\InLOf{x},\SomeOf{(x,y)})$
  \end{tabular}
\end{definition}

\begin{definition}
  Fix a simple symmetric lens $\Lens$ beteween $X$ and $Y$. Consider the
  function, $\SingleApp_{\Lens} \OfType ((X + Y) \times \OptionOf{(X \times Y)})
  \rightarrow ((X + Y) \times \OptionOf{(X \times Y)})$, defined as:

  \begin{tabular}{@{}r@{\ }c@{\ }l@{\ }l}
    $\SingleApp_{\Lens}(\InLOf{x},\None)$
    & =
    & $\LetIn{y}{\Lens.\CreateROf{x}}$\\
    &
    & $(\InROf{y},\SomeOf{(x,y)})$\\
    
    $\SingleApp_{\Lens}(\InROf{y},\None)$
    & =
    & $\LetIn{x}{\Lens.\CreateLOf{y}}$\\
    &
    & $(\InLOf{x},\SomeOf{(x,y)})$\\
    
    $\SingleApp_{\Lens}(\InLOf{x'},\SomeOf{(x,y)})$
    & =
    & $\LetIn{y'}{\Lens.\PutROf{x'}{y}}$\\
    &
    & $(\InROf{y'},\SomeOf{(x',y')})$\\
    
    $\SingleApp_{\Lens}(\InROf{y'},\SomeOf{(x,y)})$
    & =
    & $\LetIn{x'}{\Lens.\PutLOf{y'}{x}}$\\
    &
    & $(\InROf{x'},\SomeOf{(x',y')})$\\
  \end{tabular}
\end{definition}

\begin{definition}
  Fix a symmetric lens \Lens over $X$ and $Y$. We define the relation $R_\Lens$
  over $\Lens.C$ and $\OptionOf{(X \times Y)}$ as the largest relation such
  that:
  \begin{enumerate}
  \item $R_\Lens(c,None) \BooleanImplies c = \Lens.init$
  \item $R_\Lens(c,Some (x,y)) \BooleanImplies
    \Lens.\PutRSymOf{(x,c)} = (y,c) \BooleanAnd
    \Lens.\PutLSymOf{(y,c)} = (x,c)$
  \end{enumerate}
\end{definition}

\begin{mylemma}
  \label{lem:s-equiv}
  Let $\Lens$ be a symmetric lens.  Let $c \in \Lens.C$ be a complement, and
  $xyo \in \OptionOf{(X \times Y)}$.  If $R_{\Lens}(c,xyo)$, then
  $apply(\Lens,c,es) = apply(S(\Lens),xyo,es)$.
\end{mylemma}
\begin{proof}
  By induction on the derivation the application of $apply(S(\Lens),xyo,es)$
  \begin{case}[empty list]
    So by the case, $apply(S(\Lens),xyo,[]) = []$. Furthermore,
    $apply(\Lens,c,[]) = []$, as desired.
  \end{case}
  \begin{case}[first edit is a create right]
    So by the case, $apply(S(l),\None,\InLOf{x}::es) = \InROf{y}::es'$, where
    $S(\Lens).\CreateROf{x} = y$ and $apply(S(\Lens),\SomeOf{(x,y)},es) = es'$.

    As $R_{\Lens}(None,c)$, $c = \Lens.init$. So, performing $apply$ on
    $\Lens.init$, we get $apply(\Lens,\Lens.init,(\InLOf{x})::es) =
    (\InROf{y'})::es''$ where $\Lens.putr(x,c) = (y',c')$ and $apply(\Lens,c',es)
    = es'$.

    So, by definition, $S(\Lens).\CreateROf{x} = \Fst \App (\Lens.\PutRSymOf{(x,\Lens.init)})$, so $y = y'$.

    Furthermore, by \PutRL, $\Lens.\PutLSymOf{(y,c')} = (x,c')$, and by another
    application of \PutLR, $\Lens.\PutRSymOf{(x,c')} = (y,c')$.  This means
    that $R_{\Lens}(c',Some (x,y))$.

    So, by induction assumption, $apply(\Lens,c',es) = apply(S(\Lens),xyo,es)$, so
    $es' = es''$.  This means, $apply(S(l),\None,\InLOf{x}::es) =
    \InROf{y}::es'$ and $apply(\Lens,\Lens.init,(\InLOf{x})::es) =
    (\InROf{y})::es'$, so they are equal, as desired.
  \end{case}
  \begin{case}[first edit is a create left]
    Symmetric to previous case
  \end{case}
  \begin{case}[first edit is a put right]
    So by the case, $apply(S(\Lens),\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'$, where
    $S(\Lens).\PutROf{x}{y} = y'$ and $apply(S(\Lens),\SomeOf{(x',y')},es) = es'$.

    Performing $apply$ on $c$, we get $apply(\Lens,c,(\InLOf{x'})::es) =
    (\InROf{y'})::es''$ where $\Lens.\PutRSymOf{(x',c)} = (y',c')$ and
    $apply(\Lens,c',es) = es''$.

    So, by definition, $S(\Lens).\PutROf{x}{y} = \Fst \App (\Lens.\PutRSymOf{(x,c'')})$, where $c'' = \Snd \App (\Lens.\PutLSymOf{(y,\Lens.init)})$.

    By assumption, $R_{\Lens}(c,\SomeOf{(x,y)})$, so $\Lens.\PutLSymOf{(y,c)}
    = (x,c)$.  So, by Property~\ref{prop:forget-lr}, we know $y' = y''$.

    Furthermore, by \PutRL, $\Lens.\PutLSymOf{(y',c')} = (x',c')$, and by another
    application of \PutLR, $\Lens.\PutRSymOf{(x',c')} = (y',c')$.  This means
    that $R_{\Lens}(c',Some (x',y'))$.

    So, by induction assumption, $apply(\Lens,c',es) = apply(S(\Lens),xyo,es)$, so
    $es' = es''$.  This means, $apply(S(l),\SomeOf{(x,y)},\InLOf{x'}::es) =
    \InROf{y'}::es'$ and $apply(\Lens,c,(\InLOf{x'})::es) =
    (\InROf{y'})::es'$, so they are equal, as desired.
  \end{case}
  \begin{case}[first edit is a put left]
    Symmetric to previous case
  \end{case}
\end{proof}

\begin{definition}[F]
  Let $\Lens$ be a simple symmetric lens between $X$ and $Y$.

  Consider the following set $C$, distinguished element of that set, $init$, and
  pair of functions $\PutRSym$ and $\PutLSym$, that we wish to satisfy the
  symmetric lens laws, and that we also wish to be forgetful.

  \begin{centering}
    \begin{tabular}{@{}r@{\ }c@{\ }l@{}}
      $C$
      & =
      & $\OptionOf{(X \times Y)}$\\
      
      $init$
      & =
      & $\None$\\
      
      $\PutRSymOf{(x,c)}$
      & =
      & $(y,\SomeOf{(x,y)})$ where $y = \begin{cases*}
        \Lens.\CreateROf{x} & if $c = \None$\\
        \Lens.\PutROf{x}{y'} & if $c = \SomeOf{(x',y')}$\\
        \end{cases*}$\\
      
      $\PutLSymOf{(y,c)}$
      & =
      & $(x,\SomeOf{(x,y)})$ where $x = \begin{cases*}
        \Lens.\CreateLOf{y} & if $c = \None$\\
        \Lens.\PutLOf{y}{x'} & if $c = \Some{(x',y')}$\\
        \end{cases*}$\\
    \end{tabular}
  \end{centering}
\end{definition}

\begin{mylemma}
  \label{lem:f-sym}
  If $\Lens$ is a simple symmetric lens, then $F(\Lens)$ is a symmetric lens.
\end{mylemma}
\begin{proof}
  \PutRL: There are two cases, $c = \None$, and $c = \SomeOf{(x,y)}$.

  \begin{case}[c = \None]
    Let $(y',c') = F(\Lens).\PutRSymOf{(x',\None)}$. This means that $y' =
    \Lens.\CreateROf{x'}$, and $c' = \SomeOf{(x',y')}$.
    
    Now, consider $(x'',c'') = F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$. By
    unfolding definitions, $x'' = \Lens.\PutLOf{y'}{x'}$. By \CreatePutRL, $x''
    = x'$, meaning $c'' = \SomeOf{(x',y')}$. This means $(x',c') =
    F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$, as desired.
  \end{case}

  \begin{case}[c = \SomeOf{(x,y)}]
    Let $(y',c') = F(\Lens).\PutRSymOf{(x',\SomeOf{(x,y)})}$. This means that $y' =
    \Lens.\PutROf{x'}{y}$, and $c' = \SomeOf{(x',y')}$.
    
    Now, consider $(x'',c'') = F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$. By
    unfolding definitions, $x'' = \Lens.\PutLOf{y'}{x'}$. By \PutRL, $x''
    = x'$, meaning $c'' = \SomeOf{(x',y')}$. This means $(x',c') =
    F(\Lens).\PutLSymOf{(y',\SomeOf{(x',y')})}$, as desired.
  \end{case}

  The second requirement, \PutLR, is symmetric.
\end{proof}


\begin{mylemma}
  If $\Lens$ is a simple symmetric lens, then $F(\Lens)$ is a forgetful symmetric lens.
\end{mylemma}
\begin{proof}
  By Lemma~\ref{lem:f-sym}, we know $F(\Lens)$ is symmetric, so we merely need
  to show it is forgetful.  We will tackle merely \ForgetfulRL, as the proof for
  \ForgetfulLR is symmetric.

  Let $c_1$ and $c_2$ be two arbitrary complements, and $x$ and $y$ two
  arbitrary values of $X$ and $Y$, respectively.
  
  We know that $c_1' = \Snd \App (F(\Lens).\PutRSymOf{(x,c_1)})$ and $c_2' =
  \Snd \App (F(\Lens).\PutRSymOf{(x,c_2)})$.  Now, by inversion on
  $F(\Lens).\PutRSym$, we know that both $c_1' = Some(x,y_1')$ and $c_2' =
  Some(x,y_2')$ for some values of $y_1$ and $y_2$ (though we don't actually
  care about the values of $y_1$ and $y_2$).

  Now by unfolding definitions we know, $\Snd \App
  (F(\Lens).\PutLSymOf{(y,\SomeOf{(x,y_1')})}) =
  \SomeOf(\Lens.\PutLOf{x}{y},y) = c_1''$. Similarly, we know $\Snd \App
  (F(\Lens).\PutLSymOf{(y,\SomeOf{(x,y_2')})}) =
  \SomeOf(\Lens.\PutLOf{x}{y},y) = c_2''$, so $c_1'' = c_2''$, as intended.
\end{proof}

\begin{mylemma}
\label{lem:f-equiv}
  If $\Lens$ be a simple symmetric lens, then $apply(\Lens,xyo,es) =
  apply(F(\Lens),xyo,es)$.
\end{mylemma}
\begin{proof}
  By induction on the derivation of $apply$ on $\Lens$!

  \begin{case}[empty list]
    So by the case, $apply(S(\Lens),xyo,[]) = []$. Furthermore,
    $apply(\Lens,xyo,[]) = []$, as desired.
  \end{case}

  \begin{case}[first edit is a create right]
    So by the case, $apply(\Lens,\None,\InLOf{x}::es) = \InROf{y}::es'$, where
    $\Lens.\CreateROf{x} = y$ and $apply(\Lens,\SomeOf{(x,y)},es) = es'$.

    Performing $apply$ on
    $\None$, we get $apply(F(\Lens),\None,(\InLOf{x})::es) =
    (\InROf{y'})::es''$ where $F(\Lens).putr(x,\None) = (y',c)$ and $apply(\Lens,c,es)
    = es'$.

    Unfolding definitions, $F(\Lens).putr(x,\None) = \Lens.\CreateROf{x} =
    (y,\SomeOf{(x,y)})$, so $c = \SomeOf{(x,y)}$ and $y = y'$

    So, by induction assumption, $apply(\Lens,\SomeOf{(x,y)},es) = apply(F(\Lens),\SomeOf{(x,y)},es)$, so
    $es' = es''$.  This means, $apply(\Lens,\None,\InLOf{x}::es) =
    \InROf{y}::es'$ and $apply(F(\Lens),\None,(\InLOf{x})::es) =
    (\InROf{y})::es'$, so they are equal, as desired.
  \end{case}

  \begin{case}[first edit is a create left]
    Symmetric to previous case
  \end{case}

  \begin{case}[first edit is a put right]
    So by the case, $apply(\Lens,\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'$, where
    $\Lens.\PutROf{x}{y} = y'$ and $apply(\Lens,\SomeOf{(x',y')},es) = es'$.

    Performing $apply$ on $F(\Lens)$, we get
    $apply(F(\Lens),\SomeOf{(x,y)},(\InLOf{x'})::es) = (\InROf{y'})::es''$ where
    $F(\Lens).\PutRSymOf{(x',\SomeOf{(x,y)})} = (y'',\SomeOf{(x',y'')})$ and
    $apply(\Lens,c',es) = es''$.
    
    So, by definition, $\Fst \App (F(\Lens).\PutRSymOf{(x',\SomeOf{(x,y)})})
    = \Lens.PutROf{x'}{y'}$, so also by definition, $c' = \SomeOf{(x',y')}$.

    So, by induction assumption, $apply(\Lens,\SomeOf{(x',y')},es) =
    apply(F(\Lens),\SomeOf{(x',y')},es)$, so $es' = es''$. This means,
    $apply(\Lens,\SomeOf{(x,y)},\InLOf{x'}::es) = \InROf{y'}::es'$ and
    $apply(F(\Lens),\SomeOf{(x,y)},(\InLOf{x'})::es) = (\InROf{y'})::es'$, so
    they are equal, as desired.
  \end{case}

  \begin{case}[first edit is a put left]
    Symmetric to previous case
  \end{case}
\end{proof}

\begin{theorem}
  Let $\Lens$ be a symmetric lens. The lens $\Lens$ is equivalent to a forgetful
  lens if, and only if, there exists a simple symmetric lens $\Lens'$ where
  $apply(\Lens,\Lens.init,es) = apply(\Lens',\None,es)$, for all put sequences
  $es$.
\end{theorem}

\begin{proof}
  \begin{case}[$\Rightarrow$]
    Let $\Lens$ be equivalent to a forgetful lens $\Lens'$.  Consider the
    simple symmetric lens, $S(\Lens')$.  By Lemma~\ref{lem:s-equiv},
    $apply(\Lens',\Lens'.init,es) = apply(S(\Lens'),\None,es)$.  As $\Lens$ is
    equivalent to $\Lens'$, $apply(\Lens,\Lens.init,es) =
    apply(\Lens',\Lens'.init,es)$.  So, by transitivity,
    $apply(\Lens,\Lens.init,es) = apply(S(\Lens),\None,es)$.
  \end{case}

  \begin{case}[$\Leftarrow$]
    Let $\Lens'$ be a simple symmetric lens where $apply(\Lens,\Lens.init,es) =
    apply(\Lens',\None,es)$, for all put sequences $es$.

    Consider $F(\Lens')$, a forgetful symmetric lens where $apply(\Lens',\None,es) =
    apply(F(\Lens'),\Lens'.init,es)$, for all put sequences $es$, as
    $\Lens'.init = \None$, by Lemma~\ref{lem:f-equiv}.  By transitivity, $apply(\Lens,\Lens.init,es) =
    apply(\Lens',\Lens'.init,es)$, so $\Lens$ and $\Lens'$ are equivalent.
  \end{case}
    
\end{proof}

\section{Forgetful Symmetric Lenses}
\begin{theorem*}
  If $\Regex \SSREquiv \RegexAlt$ then $\ProbabilityOf{\Regex}{\String} =
  \ProbabilityOf{\RegexAlt}{\String}$, for all strings $\String \in \LanguageOf{\Regex}$.
\end{theorem*}
The following lemma is
\begin{proof}
\begin{enumerate}

\item
($S \; |_1 \; \varnothing \equiv^S S$)

For all $s \in \mathcal{L}(S \; | \; \varnothing)$, then $P_{S \; |_1 \; \varnothing} = 1 * P_S(s) = P_S(s)$.
\item
($S \cdot \varnothing \equiv^S \varnothing$)

For all $s \in \mathcal{L}(S \cdot \varnothing)$, the $P_{S \cdot \varnothing}(s) = \sum_{s_1 \cdot s_2}P_S(s_1) * P_{\varnothing}(s_2)$, but this sum is empty, hence $P_{S \cdot \varnothing}(s) = 0 = P_{\varnothing}(s)$.
\item
($\varnothing \cdot S \equiv^S \varnothing$)

Similar to the previous case.
\item
($(S \cdot S') \cdot S'' \equiv^S S \cdot (S' \cdot S'')$). Let $s \in \mathcal{L}(S \cdot S' \cdot S'')$

Then
\begin{align*}
P_{(S \cdot S') \cdot S''}(s) &= \sum_{s=s_4 \cdot s_3}P_{S \cdot S'}(s_4) * P_{S''}(s_3)\\
&= \sum_{s=s_4 \cdot s_3}\left(\sum_{s_4=s_1 \cdot s_2} P_{S}(s_1) * P_{S'}(s_2)\right)* P_{S''}(s_3)\\
&= \sum_{s=s_1\cdot s_2 \cdot s_3} P_{S}(s_1) * P_{S'}(s_2) * P_{S''}(s_3)\\
P_{S \cdot (S' \cdot S'')}(s) &= \sum_{s=s_1\cdot s_4} P_{S}(s) * \left(\sum_{s_4=s_2\cdot s_3}P_{S'}(s_2) * P_{S''}(s_3)\right)
\end{align*}
\item
($(S \; |_{p_1} \; S') \; |_{p_2} \; S'' \equiv^S S \; |_{p_1 * p_2} \; (S' \; |_{\frac{(1-p_1)*p_2}{1-p_1*p_2}} \; S'')$)

Let $s \in \mathcal{L}(S \; |\; S' \; | \; S'')$. Then
\begin{align*}
P_{(S \; |_{p_1} \; S') \; |_{p_2} \; S''}(s) &= p_2 * P_{S \; |_{p_1} \; S'}(s) + (1-p_2)P_{S''}(s)\\
&= (p_2 * (p_1 * P_S(s) + (1-p_1) * P_{S'}(s))) + (1-p_2)P_{S''}(s)\\
&= (p_2 * (p_1 * P_S(s) + P_{S'}(s)-p_1* P_{S'}(s))) + (1-p_2)P_{S''}(s)\\
&= p_2*p_1 * P_S(s) + p_2*P_{S'}(s)-p_2*p_1* P_{S'}(s) + (1-p_2)P_{S''}(s)\\
&= p_2*p_1 * P_S(s) + (1-p_1) * p_2 * P_{S'}(s)+ (1-p_2)P_{S''}(s)\\
S \; |_{p_1 * p_2} \; (S' \; |_{\frac{(1-p_1)*p_2}{1-p_1*p_2}} \; S'') &= (p_1p_2)  P_S(s) + (1-p_1p_2)  \left(\frac{(1-p_1)p_2}{1-p_1p_2}  P_{S'}(s) + \left(1-\frac{(1-p_1)p_2}{1-p_1p_2}\right)P_{S''}(s)\right)
\end{align*}
\item
($S \; |_p \; T \equiv^S T \; |_{1-p} \; S$)

For all $s \in \mathcal{L}(S \; | \; T)$, we have
$$P_{S \; |_p \; T}(s) = p*P_S(s) + (1-p)*P_T(s) = (1-p) * P_T(s) + (1-(1-p))*P_s(s) = P_{T \; |_{1-p} \; S}(s)$$
\item
($S \cdot (S' \; |_p \; S'' ) \equiv^S (S \cdot S') \; |_p \; (S \cdot S'')$)

For all $s \in \mathcal{L}(S \cdot (S' \sep S''))$ we have
\begin{align*}
P_{S \cdot (S' \; |_p \; S'' )} &= \sum_{s_1 \cdot s_2 = s}P_S(s_1) * P_{S' \; |_p \; S''}(s)\\
&= \sum_{s_1 \cdot s_2 = s}P_S(s_1) * (p * P_{S'}(s_2) + (1-p) * P_{S''}(s_2))\\
&= \sum_{s_1 \cdot s_2 = s}p * P_S(s_1) * P_{S'}(s_2) + \sum_{s_1 \cdot s_2 = s}(1-p) * P_S(s_1) * P_{S''}(s_2)\\
P_{(S \cdot S') \; |_p \; (S \cdot S'')}(s) &= p*P_{S \cdot S'}(s) + (1-p)*P_{S \cdot S''}(s)
\end{align*}
\item
$((S' \; |_p \; S'') \cdot S \equiv^S (S' \cdot S) \; |_p \; (S'' \cdot S))$

For all $s \in \mathcal{L}((S' \; | \; S'') \cdot S)$,  we have
\begin{align*}
P_{(S' \; |_p \; S'') \cdot S}(s) &= \sum_{s_1 \cdot s_2 = s}P_{S' \; |_p \; S''}(s_1) * P_S(s_2)\\
&= \sum_{s_1 \cdot s_2 = s}(p * P_{S'}(s_1) + (1-p) * P_{S''}(s_1))* P_S(s_2)\\
&= \sum_{s_1 \cdot s_2=s}p*P_{S'}(s_1) * P_S(s_2) + \sum_{s_1 \cdot s_2 = s}(1-p) * P_{S''}(s_1) * P_S(s_2)\\
P_{(S' \cdot S) \; |_p \; (S'' \cdot S)}&= p * P_{S' \cdot S}(s) + (1-p) * P_{S'' \cdot S}(s)
\end{align*}
\item
($\varepsilon \cdot S \equiv^S S$)

For all $s \in \mathcal{L}(S)$, we have
$$P_{\epsilon \cdot S}(s) = \sum_{s_1 \cdot s_2 = s}P_{\epsilon}(s_1) * P_S(s_2) = P_{\epsilon}(\epsilon) * P_S(s_2) = P_S(s)$$
since $s_2 = s$ in the computation above.
\item
($S \cdot \epsilon \equiv^S S$)

Similar to the previous case.
\item
($S^{*p} \equiv^S \epsilon \; |_{(1-p)} \; (S^{*p} \cdot S)$)

Let $s \in \mathcal{L}(S^*)$, in which case we have
\begin{align*}
P_{\epsilon \; |_{1-p} \; (S^{*p} \cdot S)}(s) &= (1-p) * P_{\epsilon}(s) + p * P_{S^{*p} \cdot S}(s)\\
&= (1-p) * P_{\epsilon}(s) + p * \sum_{a \cdot b = s}\left(\sum_n \sum_{s_1 \ldots \cdot s_n=a} p^n (1-p) \prod_{i=1}^n P_S(s_i)\right) * P_S(b)\\
&= (1-p) * P_{\epsilon}(s) + \sum_{a \cdot b = s}\left(\sum_n \sum_{s_1 \cdot \ldots \cdot s_n=s} p^{n+1} (1-p) \prod_{i=1}^n P_S(s_i) * P_S(b)\right)\\
&= (1-p) * P_{\epsilon}(s) + \sum_n \sum_{s_1 \cdot \ldots \cdot s_{n+1}=s} p^{n+1} (1-p) \prod_{i=1}^{n+1} P_S(s_i)\\
&= (1-p) * P_{\epsilon}(s) + \left(\sum_n \sum_{s_1 \cdot \ldots \cdot s_n = s} p^n * (1-p) * \prod_{i=1}^n P_S(s_i)\right) - (1-p) * (\mathbbm{1}_{s = \varepsilon})
\end{align*}
Since
$$
P_{S^{*p}}(s) = \sum_n \sum_{s_1 \cdot \ldots \cdot s_n = s} p^n * (1-p) * \prod_{i=1}^n P_S(s_i)
$$
then if $s = \epsilon$, the terms $(1-p) * P_{\epsilon}(s)$ and $(1-p) * \mathbbm{1}_{s=\varepsilon}$ cancel each other out. Otherwise, if $s \neq \epsilon$, then $(1-p) * P_{\epsilon}(s) = 0 = (1-p) * (\mathbbm{1}_{s = \varepsilon})$ from which the result follows.
\item
($S^{*p} \equiv^S \epsilon \; |_{(1-p)} \; (S \cdot S^{*p})$)

Similar to the previous case.
\end{enumerate}
\end{proof}
\begin{mylemma}[Equivalence of \ConcatSequence{} and \Concat{}]
  If $\LanguageOf{\Regex}=\LanguageOf{\Sequence}$,
  and $\LanguageOf{\RegexAlt}=\LanguageOf{\SequenceAlt}$,
  then $\LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}=\LanguageOf{\ConcatSequenceOf{\Sequence}{\SequenceAlt}}$.
\end{mylemma}
\begin{proof}
  Let $\Sequence=\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots
    \SeqSep\Atom_n\SeqSep\String_n}$, and
  let $\SequenceAlt=[\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots
  \SeqSep\AtomAlt_m\SeqSep\StringAlt_m]$. Then
  \begin{align*}  
    \LanguageOf{\ConcatSequenceOf{\Sequence}{\SequenceAlt}} & = 
                                                              \LanguageOf{\SequenceOf{\String_0\SeqSep\Atom_1\SeqSep\ldots
                                                              \SeqSep\Atom_n\SeqSep\String_n\Concat\StringAlt_0\SeqSep{}
                                                              \AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m}} \\
                                                            & = 
                                                              \{\String_0\Concat\String_1'\Concat\ldots\Concat\String_n'\Concat\String_n
                                                              \Concat\StringAlt_0\Concat\StringAlt_1'\Concat\ldots
                                                              \Concat\StringAlt_m'\Concat\StringAlt_m\SuchThat{} \String_i'\in\LanguageOf{\Atom_i} \BooleanAnd{}
                                                              \StringAlt_i'\in\LanguageOf{\AtomAlt_i}\}\\
                                                            & = 
                                                              \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Sequence}
                                                              \BooleanAnd{} \StringAlt\in\LanguageOf{\SequenceAlt}\}\\
                                                            & =
                                                              \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Regex}
                                                              \BooleanAnd{} \StringAlt\in\LanguageOf{\RegexAlt}\}\\
                                                            & =
                                                              \LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}
\end{align*}
\end{proof}

\begin{mylemma}[Equivalence of \ConcatDNF{} and \Concat{}]
  \label{lem:cdnfeq}
  If $\LanguageOf{\Regex}=\LanguageOf{\DNFRegex}$,
  and $\LanguageOf{\RegexAlt}=\LanguageOf{\DNFRegexAlt}$,
  then $\LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}=
  \LanguageOf{\ConcatDNFOf{\DNFRegex}{\DNFRegexAlt}}$.
\end{mylemma}
\begin{proof}
  Let $\DNFRegex=\DNFOf{\Sequence_0\DNFSep\ldots\DNFSep\Sequence_n}$, and
  let $\DNFRegexAlt=\DNFOf{\SequenceAlt_0\DNFSep\ldots\DNFSep\SequenceAlt_m}$
  \begin{align*}
    \LanguageOf{\ConcatDNFOf{\DNFRegex}{\DNFRegexAlt}} & = 
                                                         \LanguageOf{\DNFOf{\ConcatSequenceOf{\Sequence_i}{\SequenceAlt_j}
                                                         \text{ for $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}}} \\
                                                       & = 
                                                         \{\String\SuchThat \String\in\ConcatSequenceOf{\Sequence_i}{\SequenceAlt_j} \text{ where $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}\}\\
                                                       & = 
                                                         \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Sequence_i}
                                                         \BooleanAnd{} \StringAlt\in\LanguageOf{\SequenceAlt_j}\} \text{ where $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}\}\\
                                                       & =
                                                         \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\DNFRegex}
                                                         \BooleanAnd{} \StringAlt\in\LanguageOf{\DNFRegexAlt}\}\\
                                                       & =
                                                         \{\String\Concat\StringAlt{} \SuchThat{} \String\in\LanguageOf{\Regex}
                                                         \BooleanAnd{} \StringAlt\in\LanguageOf{\RegexAlt}\}\\
                                                       & =
                                                         \LanguageOf{\RegexConcat{\Regex}{\RegexAlt}}
\end{align*}
\end{proof}

\begin{mylemma}[Equivalence of $\Atom$ and $\AtomToDNFOf{\Atom}$]
  \label{lem:atomtodnfeq}
  $\LanguageOf{\Atom} = \LanguageOf{\AtomToDNFOf{\Atom}}$
\end{mylemma}
\begin{proof}
\begin{align*}
  \LanguageOf{\AtomToDNFOf{\Atom}} &=
  \LanguageOf{\DNFOf{\SequenceOf{\EmptyString \SeqSep \Atom \SeqSep \EmptyString}}}\\
  & =
  \SetOf{\String \SuchThat \String \in
    \LanguageOf{\SequenceOf{\EmptyString \SeqSep \Atom \SeqSep \EmptyString}}} \\
  & =
  \SetOf{\EmptyString\Concat\String\Concat\EmptyString \SuchThat \String \in
    \LanguageOf{\Atom}} \\
   & = \SetOf{\String \SuchThat \String \in
    \LanguageOf{\Atom}} \\
    &= \LanguageOf{\Atom}
    \end{align*}
\end{proof}

\begin{mylemma}[Equivalence of \OrDNF{} and \Or{}]
  \label{lem:odnfeq}
  If $\LanguageOf{\Regex}=\LanguageOf{\DNFRegex}$,
  and $\LanguageOf{\RegexAlt}=\LanguageOf{\DNFRegexAlt}$,
  then $\LanguageOf{\RegexOr{\Regex}{\RegexAlt}}=
  \LanguageOf{\OrDNFOf{\DNFRegex}{\DNFRegexAlt}}$.
\end{mylemma}
\begin{proof}
  Let $\DNFRegex=\DNFOf{\Sequence_0\DNFSep\ldots\DNFSep\Sequence_n}$, and
  let $\DNFRegexAlt=\DNFOf{\SequenceAlt_0\DNFSep\ldots\DNFSep\SequenceAlt_m}$
  
  \begin{align*}
    \mathcal{L}(DS \oplus DT)& = 
                                                     \LanguageOf{\DNFOf{\Sequence_0\DNFSep\ldots\DNFSep\Sequence_n\DNFSep
                                                     \SequenceAlt_1\DNFSep\ldots\DNFSep\SequenceAlt_m}}\\
                                                   & = 
                                                     \{\String\SuchThat{} \String\in\Sequence_i\vee\String\in\SequenceAlt_j \text{ where $i\in\RangeIncInc{1}{n}$, $j\in\RangeIncInc{1}{m}$}\}\\
                                                   & = 
                                                     \{\String{} \SuchThat{} \String\in\LanguageOf{\DNFRegex}
                                                     \BooleanOr{} \String\in\LanguageOf{\DNFRegexAlt}\}\\
                                                   & =
                                                     \{\String \SuchThat{} \String\in\LanguageOf{\Regex}
                                                     \BooleanOr{} \String\in\LanguageOf{\RegexAlt}\}\\
                                                   & =
                                                     \LanguageOf{\RegexOr{\Regex}{\RegexAlt}}
  \end{align*}
\end{proof}

\begin{theorem}\label{ConversionPreservesSemantics}
  For all regular expressions \Regex{},
  $\LanguageOf{\ToDNFRegexOf{\Regex}}=\LanguageOf{\Regex{}}$.
\end{theorem}
\begin{proof}
  By structural induction.

  Let $\Regex=\String$.
  $\LanguageOf{\ToDNFRegex(\String)}=\LanguageOf{\DNFOf{\SequenceOf{\String}}}=
  \{\String\}=\LanguageOf{\String}$

  Let $\Regex=\emptyset$.
  $\LanguageOf{\ToDNFRegex(\emptyset)}=\LanguageOf{\DNFOf{}} =
  \{\} = \LanguageOf{\emptyset}$.

  Let $\Regex=\StarOf{\Regex'}$.
  By induction assumption, $\LanguageOf{\ToDNFRegex(\Regex')}=
  \LanguageOf{\Regex'}$.
  \begin{align*}
    \LanguageOf{\ToDNFRegex(\StarOf{\DNFRegex'})} & =
                                                    \LanguageOf{\DNFOf{\SequenceOf{\StarOf{\ToDNFRegex(\Regex')}}}}\\
                                                  & =
                                                    \{\String\SuchThat\String\in
                                                    \LanguageOf{\SequenceOf{\StarOf{\ToDNFRegex(\Regex')}}}\}\\
                                                  & = 
                                                    \{\String\SuchThat{} \String\in\LanguageOf{\StarOf{\ToDNFRegex(\Regex')}}\}\\
                                                  & =
                                                    \{\String_1\Concat\ldots\Concat\String_n\SuchThat{}
                                                    n\in\Nats \BooleanAnd\String_i\in\LanguageOf{\ToDNFRegex(\Regex')}\}\\
                                                  & =
                                                    \{\String_1\Concat\ldots\Concat\String_n\SuchThat{}
                                                    n\in\Nats\BooleanAnd\String_i\in\LanguageOf{\Regex'}\}\\
                                                  & = \LanguageOf{\StarOf{\Regex'}}
  \end{align*}

  Let $\Regex=\RegexConcat{\Regex_1}{\Regex_2}$.
  By induction assumption,
  $\LanguageOf{\ToDNFRegex(\Regex_1)}=\LanguageOf{\Regex_1}$, and
  $\LanguageOf{\ToDNFRegex(\Regex_2)}=\LanguageOf{\Regex_2}$.
  $\ToDNFRegex(\RegexConcat{\Regex_1}{\Regex_2})=
  \ConcatDNFOf{\ToDNFRegex(\Regex_1)}{\ToDNFRegex(\Regex_2)}$.
  By Lemma~\ref{lem:cdnfeq},
  $\RegexConcat{\Regex_1}{\Regex_2}=
  \ConcatDNFOf{\ToDNFRegex(\Regex_1)}{\ToDNFRegex(\Regex_2)}$.


  Let $\Regex=\RegexOr{\Regex_1}{\Regex_2}$.
  By induction assumption,
  $\LanguageOf{\ToDNFRegex(\Regex_1)}=\LanguageOf{\Regex_1}$, and
  $\LanguageOf{\ToDNFRegex(\Regex_2)}=\LanguageOf{\Regex_2}$.

  $\Downarrow(S \; | \; T) = (\Downarrow S) \oplus (\Downarrow T)$. By Lemma~\ref{lem:odnfeq},
  $\mathcal{L}(S \; | \; T) = \mathcal{L}((\Downarrow S) \oplus (\Downarrow T))$.
  
\end{proof}
\begin{theorem*}
  $\ProbabilityOf{\Regex}{\String} = \ProbabilityOf{\ToDNFRegex
    \Regex}{\String}$ and $\LanguageOf{\Regex} =
  \LanguageOf{\ToDNFRegexOf{\Regex}}$
\end{theorem*}
\begin{proof}
By \cref{ConversionPreservesSemantics}, $\LanguageOf{\Regex} =
  \LanguageOf{\ToDNFRegexOf{\Regex}}$, so we will prove the result $\ProbabilityOf{\Regex}{\String} = \ProbabilityOf{\ToDNFRegex
    \Regex}{\String}$.
\begin{enumerate}
\item
$(S = s)$

By definition, $\Downarrow s = \langle ([s],1) \rangle$ and $P_{\langle ([s], 1) \rangle}(s') = 
\begin{cases}
1 & \text{if } s = s'\\
0 & \text{otherwise}
\end{cases}$ hence $P_{\langle ([s],1) \rangle}(s') = P_s(s')$.
\item
$(S = \varnothing)$

By definition, $\Downarrow \varnothing = \langle \rangle$ and $P_{\langle \rangle}(s) = 0 = P_{\varnothing}(s)$
\item
$(S = S^{*p})$

By definition, $\Downarrow (S^{*p}) = \langle [\epsilon \cdot (\Downarrow S)^{*p} \cdot \epsilon] \rangle $. By the induction hypothesis, $P_{(\Downarrow S)} = P_{S}$, hence
\begin{align*}
P_{[\epsilon \cdot (\Downarrow S)^{*p}] \cdot \epsilon}(s) &= P_{(\Downarrow S)^{*p}}(s)\\
&= \sum_n \sum_{s_1 \cdot \ldots \cdot s_n=s} p^n * (1-p) * \prod_{i=1}^n P_{(\Downarrow S)}(s_i)\\
&= \sum_n \sum_{s_1 \cdot \ldots \cdot s_n=s} p^n * (1-p) * \prod_{i=1}^n P_{S}(s_i)\\
&= P_{S^{*p}}(s)
\end{align*}
\item
$(S = S_1 \cdot S_2)$

By definition, $\Downarrow (S_1 \cdot S_2) = (\Downarrow S_1) \odot (\Downarrow S_2)$. By the induction hypothesis, $P_{S_1} = P_{(\Downarrow S_1)}$, and $P_{S_2} = P_{(\Downarrow S_2)}$. Assume that $\Downarrow S_1 = \langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_m, p_n)\rangle$ and $\Downarrow S_2 = \langle (TQ_1,q_1) \; | \; \ldots \; | \; (TQ_n, q_m) \rangle$. Then
\begin{align*}
P_{S_1}(s) &= \sum_{i=1}^n p_i P_{SQ_i}(s)\\
P_{S_1}(s) &= \sum_{j=1}^m q_i P_{TQ_j}(s)\\
\end{align*}
hence
\begin{align*}
P_{S_1 \cdot S_2}(s) &= \sum_{s_1 \cdot s_2 = s} P_{S_1}(s_1)* P_{S_2}(s_2)\\
&= \sum_{s_1 \cdot s_2 = s} \left(\sum_{i=1}^n p_i P_{SQ_i}(s_1)\right)* \left(\sum_{j=1}^m q_i P_{TQ_j}(s_2)\right)\\
&= \sum_{s_1 \cdot s_2 = s} \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j) * (P_{SQ_i}(s_1) *  P_{TQ_j}(s_2))\\
&= \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j)\sum_{s_1 \cdot s_2 = s} (P_{SQ_i}(s_1) *  P_{TQ_j}(s_2))
\end{align*}
By definition,
$\ConcatDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}=$\\
      $\DNFLeft (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_1},\Probability_1*\ProbabilityAlt_1)\DNFSep \ldots
      \DNFSep
      (\ConcatSequenceOf{\Sequence_1}{\SequenceAlt_m},\Probability_1*\ProbabilityAlt_m)\DNFSep
      \ldots$\\
      $\DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_1},\Probability_n*\ProbabilityAlt_1)\DNFSep
      \ldots \DNFSep
      (\ConcatSequenceOf{\Sequence_n}{\SequenceAlt_m},\Probability_n * \ProbabilityAlt_m) \DNFRight$
      
where
$$\ConcatSequenceOf{[\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n]}{[\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]}=
  [\String_0\SeqSep\Atom_1\SeqSep\ldots\SeqSep\Atom_n\SeqSep\String_n\Concat\StringAlt_0\SeqSep\AtomAlt_1\SeqSep\ldots\SeqSep\AtomAlt_m\SeqSep\StringAlt_m]$$
Hence
$$P_{\langle (SQ_1, p_1) \; | \; \ldots \; | \;(SQ_n,p_n)\rangle \odot \langle (TQ_1, q_1) \; | \; \ldots \; | \;(TQ_m,q_m)\rangle}(s) = \sum_{i=1}^n \sum_{j=1}^m(p_i * q_j) * P_{SQ_i \odot_{SQ} TQ_j}(s)$$
Since $P_{[s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]}(s) = \sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n = s} \prod_{i=1}^n P_{A_i}(s'i)$, then
\begin{align*}
P_{[s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n] \odot_{SQ} [t_0 \cdot B_1 \cdot \ldots \cdot B_m \cdot t_m]}(s) &= \sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n \cdot t_0 \cdot t'_1 \cdot \ldots t'_m \cdot t_m =s } \prod_{i=1}^n P_{A_i}(s'_i) \prod_{j=1}^m P_{B_j}(t'_j)\\
&= \sum_{a \cdot b = s} \sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n = a} \sum_{t_0 \cdot t'_1 \cdot \ldots \cdot t'_m \cdot t_m = b} \prod_{i=1}^n P_{A_i}(s'_i) \prod_{j=1}^m P_{B_j}(t'_j)\\
& \sum_{a \cdot b = s} \left(\sum_{s_0 \cdot s'_1 \cdot \ldots \cdot s'_n \cdot s_n = a} \prod_{i=1}^n P_{A_i}(s'_i)\right) \left(\sum_{t_0 \cdot t'_1 \cdot \ldots \cdot t'_m \cdot t_m = b} \prod_{j=1}^m P_{B_j}(t'_j)\right)\\
&= \sum_{a \cdot b = s}P_{[s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]}(a) * P_{[t_0 \cdot B_1 \cdot \ldots \cdot B_m \cdot t_m]}(b)
\end{align*}
In other words, $P_{SQ \odot_{SQ} TQ}(s) = \sum_{a \cdot b = s}P_{SQ}(a) * P_{TQ}(b)$. Hence, 
\begin{align*}
P_{S_1 \cdot S_2}(s) &= \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j)\sum_{s_1 \cdot s_2 = s} (P_{SQ_i}(s_1) *  P_{TQ_j}(s_2))\\
&= \sum_{i=1}^n \sum_{j=1}^m (p_i * q_j)\sum_{s_1 \cdot s_2 = s} P_{SQ_i \odot_{SQ} TQ_j}(s)\\
&= P_{\langle (SQ_1, p_1) \; | \; \ldots \; | \;(SQ_n,p_n)\rangle \odot \langle (TQ_1, q_1) \; | \; \ldots \; | \;(TQ_m,q_m)\rangle}(s)\\
&= P_{(\Downarrow S_1) \odot (\Downarrow S_2)}(s)
\end{align*}
which is what we wanted to show.
\item
$(S = S_1 \; |_p \; S_2)$

By definition $\Downarrow (S_1 \; |_p \; S_2) = (\Downarrow S_1) \oplus_p (\Downarrow S_2)$. By the induction hypothesis $P_{S_1} = P_{\Downarrow S_1}$ and $P_{S_2} = P_{\Downarrow S_2}$. Assume that $\Downarrow S_1 = \langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_m, p_n)\rangle$ and $\Downarrow S_2 = \langle (TQ_1,q_1) \; | \; \ldots \; | \; (TQ_n, q_m) \rangle$. By definition, 

  $\OrDNFOf{\DNFOf{(\Sequence_1,\Probability_1)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n)}}{\DNFOf{(\SequenceAlt_1,\ProbabilityAlt_1)\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m)}}{\Probability} =$\\
  $\DNFOf{(\Sequence_1,\Probability_1*\Probability)\DNFSep\ldots\DNFSep(\Sequence_n,\Probability_n*\Probability)\DNFSep(\SequenceAlt_1,\ProbabilityAlt_1*(1-\Probability))\DNFSep\ldots\DNFSep(\SequenceAlt_m,\ProbabilityAlt_m*(1-\Probability))}$
  hence
  \begin{align*}
  P_{(\Downarrow S_1) \; |_p \; (\Downarrow S_2)}(s) &= P_{\langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle \oplus_p \langle (TQ1, q_1) \; | \; \ldots \; | \; (TQ_m, q_m)\rangle}(s) \\
  &= P_{\langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_n, p_n) \; | \; (TQ1, q_1) \; | \; \ldots \; | \; (TQ_m, q_m)\rangle}(s)\\
  &= \sum_{i=1}^m (p * p_i) P_{SQ_i}(s) + \sum_{j=1}^m ((1-p) * q_j) P_{TQ_j}(s)\\
  &= p * \sum_{i=1}^m p_i P_{SQ_i}(s) + (1-p)* \sum_{j=1}^m q_j * P_{TQ_j}(s)\\
&= p * P_{\langle (SQ_1,p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle}(s) + (1-p) * P_{\langle (TQ1, q_1) \; | \; \ldots \; | \; (TQ_m, q_m)\rangle}(s)\\
&= p * P_{\Downarrow S_1}(s) + (1-p) * P_{\Downarrow S_2}(s) 
  \end{align*}
  
  Since $P_{S_1} = P_{\Downarrow S_1}$ and $P_{S_1} = P_{\Downarrow S_1}$, then 
  \begin{align*}
  P_{S_1}(s) &= \sum_{i=1}^n p_i * P_{SQ_i}(s)\\
  P_{S_2}(s) &= \sum_{j=1}^m q_m * P_{TQ_j}(s)
  \end{align*}
  hence
  \begin{align*}
  P_{S_1 \; |_p \; S_2}(s) &= p * (P_{S_1}(s)) + (1-p) * (P_{S_2}(s))\\
  &= p \left(\sum_{i=1}^n p_i * P_{SQ_i}(s)\right) + (1-p)\left(\sum_{j=1}^m q_m * P_{TQ_j}(s)\right)\\
  &= p * P_{\Downarrow S_1}(s) + (1-p) * P_{\Downarrow S_2}(s)\\
  &= P_{(\Downarrow S_1) \; |_p \; (\Downarrow S_2)}(s)
  \end{align*}
  which is what we wanted to show. This completes the proof.
\end{enumerate}
\end{proof}
\begin{theorem}
  \label{CorrectEntropy}
  If $\Regex$ is unambiguous and contains no empty subcomponents,
  $\EntropyOf{\Regex}$ is the entropy of $\mathcal{L}(\Regex)$.
\end{theorem}
\begin{proof}
Given a discrete set $X$ and a probability distribution $P$ on $X$, we define the entropy $H(X)$ of $X$ by
$$H(X) = -\sum_{x \in X}P(x)\log_2{P(x)}$$
We prove the theorem by induction on $S$.
\begin{enumerate}
\item
($S = s$)

Then $\mathbb{H}(s) = 0 = H(\mathcal{L}(s)) = H(\{s\})$
\item
$(S = S^{*p})$

Since $S^{*p}$ is unambiguous, then $S$ is also anambiguous, and for each $s \in \mathcal{L}(S^{*p})$, there exist unique $t_1, \ldots, t_n \in \mathcal{L}(S)$ such that $s = t^s_1 \cdot \ldots \cdot t^s_{n_s}$. By the induction hypothesis, $H(\mathcal{L}(S)) = \mathbb{H}(S)$, thus
\begin{align*}
H(\mathcal{L}(S^{*p})) &= - \sum_{s \in \mathcal{L}(S^{*p})} P_{S^{*p}}(s) \log_2 P_{S^{*p}}(s)\\
&= -(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\log_2 \left(p^n * (1 - p) * \prod_{i=1}^n P_S(s_i)\right)\\
&= -(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\left(n \log_2 p  + \log_2 (1 - p) + \log_2 \left(\prod_{i=1}^n P_S(s_i)\right)\right)\\
&= -(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\left(n \log_2 p  + \log_2 (1 - p) + \log_2 \left(\prod_{i=1}^n P_S(s_i)\right)\right)\\
&= -(1-p) * \log_2 p \sum_n n * p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)
-(1-p) * \log_2 (1 - p) \sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i) \\
&-(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i)\log_2 \left(\prod_{i=1}^n P_S(s_i)\right)\\
&= -\log_2 p * \frac{p}{(1-p)} -\log_2 (1 - p) 
-(1-p)\sum_n p^n H(\mathcal{L}(S^n))\\
&= -\log_2 p * \frac{p}{(1-p)} -\log_2 (1 - p) 
-(1-p)\sum_n p^n n H(\mathcal{L}(S))\\
&= -\log_2 p * \frac{p}{(1-p)} -\log_2 (1 - p) 
-\frac{p}{(1-p)} * H(\mathcal{L}(S))\\
&= \frac{p}{(1-p)}(H(\mathcal{L}(S)) - \log_2 p) -\log_2 (1 - p)\\
&= \frac{p}{(1-p)}(\mathbb{H}(S) - \log_2 p) -\log_2 (1 - p)
\end{align*}
\item
($S = S_1 \cdot S_2$)

Since $S$ is unambigous, then $S_1$ and $S_2$ are also unambiguous, and for each $s \in \mathcal{L}(S_1 \cdot S_2)$ there exists a unique $s_1 \in \mathcal{L}(S_1)$ and a unique $s_2 \in \mathcal{L}(S_2)$ such that $s = s_1 \cdot s_2$. By the induction hypothesis, $H(\mathcal{L}(S_1)) = \mathbb{H}(S_1)$ and $H(\mathcal{L}(S_2)) = \mathbb{H}(S_2)$, hence
\begin{align*}
H(\mathcal{L}(S_1 \cdot S_2))(s) &= -\sum_{s_1 \in S_1} \sum_{s_2 \in S_2}P_{S_1}(s_1)*P_{s_2}(s_2) \log_2(P_{S_1}(s_1)*P_{S_2}(s_2))\\
&= -\sum_{s_1 \in S_1} P_{S_1}(s_1)\sum_{s_2 \in S_2}P_{s_2}(s_2) (\log_2(P_{S_1}(s_1) + \log_2 P_{S_2}(s_2)))\\
&= -\sum_{s_1 \in S_1} P_{S_1}(s_1) \sum_{s_2 \in S_2}P_{S_2}(s_2)\log_2(P_{S_1}(s_1)) + \sum_{s_1 \in S_1} P_{S_1}(s_1)\sum_{s_2 \in S_2} P_{S_2}(s_2)\log_2 P_{S_2}(s_2)\\
&= -\sum_{s_1 \in S_1} P_{S_1}(s_1) \log_2(P_{S_1}(s_1)) + \sum_{s_2 \in S_2} P_{S_2}(s_2)\log_2 P_{S_2}(s_2)\\
&= H(\mathcal{L}(S_1)) + H(\mathcal{L}(S_2))\\
&= \mathbb{H}(S_1) + \mathbb{H}(S_2)
\end{align*}
\item
($S = S_1 \; |_p \; S_2$)

Since $S$ is unambiguous, then $S_1$ and $S_2$ are also unambiguous, and every $s \in \mathcal{L}(S_1 \; |_p \; S_2)$ is either in $\mathcal{L}(S_1)$ or in $\mathcal{L}(S_2)$. By the induction hypothesis, $H(\mathcal{L}(S_1)) = \mathbb{H}(S_1)$ and $H(\mathcal{L}(S_2)) = \mathbb{H}(S_2)$. Then
\begin{align*}
H(\mathcal{L}(S_1 \; |_p \; S_2)) &= -\sum_{s \in \mathcal{L}(S_1)}(p * P_{S_1}(s))\log_2 (p * P_{S_1}(s)) - \sum_{s \in \mathcal{L}(S_2)}((1-p) * P_{S_2}(s))\log_2 ((1-p) * P_{S_2}(s))\\
&=- p\sum_{s \in \mathcal{L}(S_1)}P_{S_1}(s)(\log_2 p + \log_2 P_{S_1}(s)) - (1-p)\sum_{s \in \mathcal{L}(S_2)}P_{S_2}(s)(\log_2 (1-p) + \log_2 P_{S_2}(s))\\
&= p * (\log_2 p +  H(\mathcal{L}(S_1))) + (1-p) * ( \log_2 (1-p) + H(\mathcal{L}(S_2)))\\
&= p * (\log_2 p +  \mathbb{H}(S_1)) + (1-p) * ( \log_2 (1-p) + \mathbb{H}(S_2))\\
\end{align*}
\end{enumerate}
\end{proof}
\begin{theorem*}
  Let $\Lens$ be an asymmetric lens. $\Lens$ is also a simple symmetric lens,
  where
  \begin{center}
    \begin{tabular}{rcl}
      $\Lens.\CreateROf{x}$ & $=$ & $\Lens.get \App x$\\
      $\Lens.\CreateLOf{y}$ & $=$ & $\Lens.create \App y$\\
      $\Lens.\PutROf{x}{y}$ & $=$ & $\Lens.get \App x$\\
      $\Lens.\PutLOf{y}{x}$ & $=$ & $\Lens.put \App y \App x$
    \end{tabular}
  \end{center}
\end{theorem*}
\begin{proof}
Let $\ell$ be an asymmetric lens. Then $\ell$ satisfies the following laws:
\begin{align*}
\ell.\get \; (\ell.\pput \; v \; s) &= v \tag{PUTGET}\\
\ell.\pput \; (\ell.\get \; s) \; s&= s \tag{GETPUT}\\
\ell.\get \; (\ell.\pput \; v \; s) &= v \tag{CREATGET}
\end{align*}
Define the simple symmetric lens $\lceil \ell \rceil$ by 
\begin{align*}
\lceil \ell \rceil.\CreateROf{s} &= \ell.\get \; s\\
\lceil \ell \rceil.\CreateLOf{v} &= \ell.\create \; v\\
\lceil \ell \rceil.\PutROf{s}{v} &= \ell.\get \; s\\
\lceil \ell \rceil.\PutLOf{v}{s} &= \ell.\pput \; v \; s\\
\end{align*}
We now show that $\lceil \ell \rceil$ satisfies the simple symmetric lens laws:
\begin{align*}
\lceil \ell \rceil.\PutLOf{(\lceil \ell \rceil.\CreateROf{s})}{s} &= \ell.\pput \; (\ell.\get \; s) \; s = s\\
\lceil \ell \rceil.\PutROf{(\lceil \ell \rceil.\CreateLOf{v})}{v} &= \ell.\get \; (\ell.\create \; v) = v\\
\lceil \ell \rceil.\PutLOf{(\lceil \ell \rceil.\PutROf{s}{v})}{s} &= \ell.\pput \; (\ell.\get) \; s = s\\
\lceil \ell \rceil.\PutROf{(\lceil \ell \rceil.\PutLOf{v}{s})}{v} &= \ell.\get \; (\ell.\pput \; v \; s) = v
\end{align*}
\end{proof}

\begin{theorem*}
  Let $\Lens \OfType \Regex \Leftrightarrow \RegexAlt$, where $\Lens$ does not
  include composition, $\Regex$ and $\RegexAlt$ and unambiguous, and neither
  $\Regex$ nor $\RegexAlt$ contain any empty subcomponents.
  \begin{enumerate}
  \item $\REntropyOf{\RegexAlt \Given \Lens, \Regex}$ is an upper bound for the expected
    information content of $\SetOf{t \SuchThat t \in \LanguageOf{\RegexAlt}}$,
    given $\SetOf{s \SuchThat s \in \LanguageOf{\Regex} \BooleanAnd
      \Lens.\PutROf{s}{t} = t}$
  \item $\LEntropyOf{\Regex \Given \Lens, \RegexAlt}$ is an upper bound for the expected
    information content of $\SetOf{s \SuchThat s \in \LanguageOf{\Regex}}$,
    given $\SetOf{t \SuchThat t \in \LanguageOf{\RegexAlt} \BooleanAnd
      \Lens.\PutLOf{t}{s} = s}$
  \end{enumerate}
\end{theorem*}
\begin{proof}
Let $H(T \; | \; \ell, S)$ be the expected information content of $\{t \; | \; t \in \mathcal{L}(T)\}$ given $\{s \; | \; s \in \mathcal{L}(S) \wedge \ell.\PutROf{s}{t} = t\}$. Given $s \in S$, let $V^{\rightarrow}_{\ell}(s) = \{t \in \mathcal{L}(T) \; | \; \ell.\PutROf{s}{t} = t\}$. We want to show that
$$H(T \; | \; \ell, S) = \sum_{s \in \mathcal{L}(S)}P_{\mathcal{L}(S)}(s)H(V^{\rightarrow}_{\ell}(s)) \leq \mathbb{H}^{\rightarrow}(T \; | \; \ell, S)$$
(The proofs for $\mathbb{H}^{\leftarrow}(S \; | \; \ell, T)$ will follow the same pattern). We proceed by induction over $\ell$. 
\begin{enumerate}
\item
($\ell = \IdentityLensOf{S}$)

Observe that $V^{\rightarrow}_{\IdentityLensOf{S}}(s) = \{t \in \mathcal{L}(S) \; | \; \IdentityLensOf{S}.\ell.\PutROf{s}{t} = t\} = \{t \in \mathcal{L}(S) \; | \; t = s\} = \{s\}$.

Consequently, $H(V^{\rightarrow}_{\IdentityLensOf{S}}(s)) = H(\{s\}) = 0$, from which it follows that 
$$\sum_{s \in \mathcal{L}(S)} P_{\mathcal{L}(S)}(s) * H(V^{\rightarrow}_{\IdentityLensOf{S}}(s)) = 0 = \mathbb{H}^{\rightarrow}(S \; | \; \IdentityLensOf{S}, T)$$
\item
($\ell = \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}$)

Observe that 
$$V^{\rightarrow}_{\DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}}(s) = \{t \in \mathcal{L}(T) \; | \; \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}.\PutROf{s}{t} = t\} = \{t \in \mathcal{L}(T) \; | \; t = t\} = \mathcal{L}(T)$$
Consequently
\begin{align*}
\sum_{s \in \mathcal{L}(S)}P_{S}(s)H(V^{\rightarrow}_{\DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}}(s)) &= \sum_{s \in \mathcal{L}(S)}P_{S}(s)H(\mathcal{L}(T))\\
&= H(\mathcal{L}(T))\\
&= \mathbb{H}(T)\\
&= \mathbb{H}^{\rightarrow}(T \; | \; \DisconnectOf{\Regex}{\RegexAlt}{\String}{\StringAlt}, S)
\end{align*}
\item
($\ell = \IterateLensOf{\Lens} : S^{*p} \Leftrightarrow T^{*q}$)

Observe that 
\begin{align*}
V^{\rightarrow}_{\IterateLensOf{\Lens}}(s_1 \cdot \ldots \cdot s_n) &= \{t_1 \cdot \ldots \cdot t_m \; | \; \IterateLensOf{\Lens}.\PutROf{(s_1 \cdot \ldots \cdot s_n) }{(t_1 \cdot \ldots \cdot t_m)} = t_1 \cdot \ldots \cdot t_m\}\\
&= \{t_1 \cdot \ldots \cdot t_n \; | \; \ell.\PutROf{s_i}{t_i} = t_i \text{ for }1 \leq i \leq n\}\\
&= V^{\rightarrow}_{\ell}(s_1) \cdot \ldots \cdot V^{\rightarrow}_{\ell}(s_n)
\end{align*}
Consequently
\begin{align*}
\sum_{s \in \mathcal{L}(S^{*p})}P_{S^{*p}}(s) H(V^{\rightarrow}_{\IterateLensOf{\Lens}}(s))
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n)\\s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i) H(V^{\rightarrow}_{\ell}(s_1) \cdot \ldots \cdot V^{\rightarrow}_{\ell}(s_n))\\
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_n)\\s_i \in \mathcal{L}(S)}} \prod_{i=1}^n P_S(s_i) \left(\sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j)) \right)\\
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \sum_{s_n} P_S(s_n) \left(\sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j)) \right)
\end{align*}
We focus on the term $\sum_{s_n} P_S(s_n) \sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j))$:
\begin{align*}
\sum_{s_n} P_S(s_n) \sum_{j=1}^n H(V^{\rightarrow}_{\ell}(s_j)) &= \sum_{s_n} P_S(s_n)H(V^{\rightarrow}_{\ell}(s_n)) + P_S(s_n) \sum_{j=1}^{n-1} H(V^{\rightarrow}_{\ell}(s_j))\\
&= H(T \; | \; \ell, S) + \sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))
\end{align*}
Consequently,
\begin{align*}
\sum_{s \in \mathcal{L}(S^{*p})}P_{S^{*p}}(s) H(V^{\rightarrow}_{\IterateLensOf{\Lens}}(s))
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left( H(S \; | \; \ell, T) + \sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)\\
&= (1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_{n-1})\\s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) H(S \; | \; \ell, T)\\
&+(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left(\sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)\\
&= H(S \; | \; \ell, T) * (1-p)\sum_n p^n \\
&+(1-p)\sum_n p^n \sum_{\substack{(s_1, \ldots, s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left(\sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)
\end{align*}
Unrolling the term 
$$\sum_{\substack{(s_1, \ldots, s_{n-1}) \\ s_i \in \mathcal{L}(S)}} \prod_{i=1}^{n-1}P_S(s_i) \left(\sum_{j=1}^{n-1}H(V^{\rightarrow}_{\ell}(s_j))\right)$$ 
$(n-1)$ more times gives
\begin{align*}
H(T^{*q} \; | \; V^{\rightarrow}_{\IterateLensOf{\Lens}}(s), S^{*p}) &=
\sum_{s \in \mathcal{L}(S^{*p})}P_{S^{*p}}(s) H(V^{\rightarrow}_{\IterateLensOf{\Lens}}(s))\\
&= H(T \; | \; \ell, S) * (1-p)\sum_n n * p^n \\
&= \frac{p}{1-p} * H(T \; | \; \ell, S)\\
&\leq \frac{p}{1-p} * \mathbb{H}^{\rightarrow}(T \; | \; \ell, S)\\
&= \mathbb{H}(T^{*q} \; | \; V^{\rightarrow}_{\IterateLensOf{\Lens}}(s), S^{*p})
\end{align*}

which is what we wanted to show.
\item
($S = \ConcatLensOf{\Lens_1}{\Lens_2}$)

Observe that 
\begin{align*}
V^{\rightarrow}_{ \ConcatLensOf{\Lens_1}{\Lens_2}}(s_1 \cdot s_2) &= \{t_1 \cdot t_2 \in \mathcal{L}(T_1 \cdot T_2) \; | \;  \ConcatLensOf{\Lens_1}{\Lens_2}.\PutROf{(s_1 \cdot s_2)}{(t_1 \cdot t_2)} = t_1 \cdot t_2\}\\
&= \{t_1 \cdot t_2 \in \mathcal{L}(T_1 \cdot T_2) \; | \;  \ell_1.\PutROf{s_1}{t_1 } = t_1  \text{ and } \ell_2.\PutROf{t_2}{t_2} = t_2\}\\
&= V^{\rightarrow}_{\ell_1}(s_1) \cdot V^{\rightarrow}_{\ell_2}(s_2)
\end{align*}
Consequently,
\begin{align*}
&H(T_1 \cdot T_2 \; | \; \ConcatLensOf{\Lens_1}{\Lens_2}, S_1 \cdot S_2)\\
& =\sum_{s \in \mathcal{L}(S_1 \cdot S_2)}P_{S_1 \cdot S_2}(s) H(V^{\rightarrow}_{\ConcatLensOf{\Lens_1}{\Lens_2}}(s))\\
&= \sum_{s_1 \in \mathcal{L}(s_1)} P_{S_1}(s_1)\sum_{s_2 \in \mathcal{L}(s_2)}P_{S_2}(s_2)(H(V^{\rightarrow}_{\ell_1}(s_1)) + H(V^{\rightarrow}_{\ell_2}(s_2)))\\
&= \sum_{s_1 \in \mathcal{L}(s_1)} P_{S_1}(s_1)\sum_{s_2 \in \mathcal{L}(s_2)}P_{S_2}(s_2)H(V^{\rightarrow}_{\ell_1}(s_1)) + \sum_{s_1 \in \mathcal{L}(s_1)} P_{S_1}(s_1)\sum_{s_2 \in \mathcal{L}(s_2)}P_{S_2}(s_2)H(V^{\rightarrow}_{\ell_2}(s_2))\\
&= H(T_1 \; | \; \ell_1, S_1) + H(T_2 \; | \; \ell_2, S_2)\\
&\leq \mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1, S_1) + \mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2, S_2)\\
&= \mathbb{H}(T_1 \cdot T_2 \; | \; \ConcatLensOf{\Lens_1}{\Lens_2}, S_1 \cdot S_2)
\end{align*}
\item
($S = \SwapLensOf{\Lens_1}{\Lens_2}$)

Similar to the previous case.
\item
($S = \OrLensOf{\Lens_1}{\Lens_2}$)

Observe that 
$$
V^{\rightarrow}_{ \OrLensOf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \OrLensOf{\Lens_1}{\Lens_2}.\ell.\PutROf{s}{t} = t\}
$$
If $s \in \mathcal{L}(S_1)$, then
$$
V^{\rightarrow}_{ \OrLensOf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \ell_1.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_1}(s)
$$
while if $s \in \mathcal{L}(S_2)$, then
$$
V^{\rightarrow}_{ \OrLensOf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \ell_2.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_2}(s)
$$
Consequently,
\begin{align*}
H(T_1 \; |_q \; T_2 \; | \; \OrLensOf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) &= \sum_{s \in \mathcal{L}(S_1 \; |_p \; S_2)}P_{S_1 \; |_p \; S_2}(s) H(V^{\rightarrow}_{\OrLensOf{\Lens_1}{\Lens_2}}(s))\\
&= p * \sum_{s \in \mathcal{L}(S_1)}P_{S_1}(s) H(V^{\rightarrow}_{\ell_1}(s)) + (1-p) * \sum_{s \in \mathcal{L}(S_2)}P_{S_2}(s) H(V^{\rightarrow}_{\ell_2}(s))\\
&= p * (H(T_1 \; | \; \ell_1,S_1)) + (1-p) * (H(T_2 \; | \; \ell_2,S_2))\\
&\leq p * (\mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1,S_1)) + (1-p) * (\mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2,S_2))\\
&= \mathbb{H}(T_1 \; |_q \; T_2 \; | \; \OrLensOf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) 
\end{align*}
\item
($S = \MergeROf{\Lens_1}{\Lens_2}$)

Observe that 
$$
V^{\rightarrow}_{ \MergeROf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T) \; | \;  \MergeROf{\Lens_1}{\Lens_2}.\PutROf{s}{t} = t\}
$$
If $s \in \mathcal{L}(S_1)$, then
$$
V^{\rightarrow}_{ \MergeROf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T) \; | \;  \ell_1.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_1}(s)
$$
while if $s \in \mathcal{L}(S_2)$, then
$$
V^{\rightarrow}_{ \MergeROf{\Lens_1}{\Lens_2}}(s) = \{t \in \mathcal{L}(T) \; | \;  \ell_2.\PutROf{s}{t} = t\} = V^{\rightarrow}_{\ell_2}(s)
$$
Consequently,
\begin{align*}
H(T \; | \; \MergeROf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) &= \sum_{s \in \mathcal{L}(S_1 \; |_p \; S_2)}P_{S_1 \; |_p \; S_2}(s) H(V^{\rightarrow}_{\MergeROf{\Lens_1}{\Lens_2}}(s))\\
&= p * \sum_{s \in \mathcal{L}(S_1)}P_{S_1}(s) H(V^{\rightarrow}_{\ell_1}(s)) + (1-p) * \sum_{s \in \mathcal{L}(S_2)}P_{S_2}(s) H(V^{\rightarrow}_{\ell_2}(s))\\
&= p * (H(T_1 \; | \; \ell_1, S_1) ) + (1-p) * (H(T_2 \; | \; \ell_2, S_2) )\\
&\leq p * (\mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1, S_1) ) + (1-p) * (\mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2, S_2) )\\
&= \mathbb{H}(T \; | \; \MergeROf{\Lens_1}{\Lens_2}, S_1 \; |_p \; S_2) 
\end{align*}
\item
($S = \MergeLOf{\Lens_1}{\Lens_2}$)

Observe that 
\begin{align*}
V^{\rightarrow}_{ \MergeLOf{\Lens_1}{\Lens_2}}(s) &= \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \MergeLOf{\Lens_1}{\Lens_2}.\PutROf{s}{t} = t\}\\
&= \{t \in \mathcal{L}(T_1 \; |_q \; T_2) \; | \;  \ell_1.\PutROf{s}{t} = t \text{ or } \ell_2.\PutROf{s}{t} = t\}\\
&= V^{\rightarrow}_{\ell_1}(s) \cup V^{\rightarrow}_{\ell_2}(s)
\end{align*}
To compute $H(V^{\rightarrow}_{ \MergeLOf{\Lens_1}{\Lens_2}}(s))$, we use the formula 
$$H(P_1, P_2) = H(m(P_1), m(P_2)) + m(P_1)H\left(\frac{P_1}{m(P_1)}\right) + m(P_2)H\left(\frac{P_2}{m(P_2)}\right)$$
if the probability space $P$ is the sum of measure spaces $P_1$ and $P_2$, and $m(P_i)$ is the measure of $P_i$:
\begin{align*}
&H(V^{\rightarrow}_{ \MergeLOf{\Lens_1}{\Lens_2}}(s)) =\\
&H \left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}, \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)\\
&+ \frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)} H(V^{\rightarrow}_{\ell_1}(s)) + \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)} H(V^{\rightarrow}_{\ell_2}(s))
\end{align*}
Consequently,
\begin{align*}
&H(T_1 \; |_q \; T_2 \; | \; \MergeLOf{\Lens_1}{\Lens_2}, S) = \\
&\sum_{s \in \mathcal{L}(S)}H \left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}, \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)P_S(s)\\
&+ \sum_{s \in \mathcal{L}(S)}\left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)P_S(s)H(V^{\rightarrow}_{\ell_1}(s))\\
&+ \sum_{s \in \mathcal{L}(S)}\left(\frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right)P_S(s)H(V^{\rightarrow}_{\ell_2}(s))
\end{align*}
Since
\begin{align*}
H \left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}, \frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right) &\leq 1\\
\left(\frac{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right) &\leq 1\\
\left(\frac{(1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}{q * P_{T_1}V^{\rightarrow}_{\ell_1}(s) + (1-q) * P_{T_2}V^{\rightarrow}_{\ell_2}(s)}\right) &\leq 1
\end{align*}
Then
\begin{align*}
H(T_1 \; |_q \; T_2 \; | \; \MergeLOf{\Lens_1}{\Lens_2}, S) & \leq \sum_{s \in \mathcal{L}(s)}P_S(s) + \sum_{s \in \mathcal{L}(s)}P_S(s)H(V^{\rightarrow}_{\ell_1}(s)) + \sum_{s \in \mathcal{L}(s)}P_S(s)H(V^{\rightarrow}_{\ell_2})(s)\\
&= H(T_1 \; | \; \ell_1, S) + H(T_2 \; | \; \ell_2, S)\\
&\leq 1 + \mathbb{H}^{\rightarrow}(T_1 \; | \; \ell_1, S) + \mathbb{H}^{\rightarrow}(T_2 \; | \; \ell_2, S)
\end{align*}
\item
($S = \REntropyOf{\Regex \Given \InvertOf{\Lens}, \RegexAlt}$)

Observe that $$V^{\rightarrow}_{\InvertOf{\Lens}}(t) = \{s \in \mathcal{L}(S) \; | \; \InvertOf{\Lens}.\PutROf{s}{t} = t\} = \{s \in \mathcal{L}(S) \; | \; \ell.\PutLOf{t}{s} = s\} = V^{\leftarrow}_{\ell}(t)$$
Consequently
$$
H(S \; | \; \InvertOf{\Lens}, T) = \sum_{t \in \mathcal{L}(T)}P_T(t) H(V^{\rightarrow}_{\InvertOf{\Lens}}(t))
= \sum_{t \in \mathcal{L}(T)}P_T(t) H(V^{\leftarrow}_{\ell}(t))
\leq \mathbb{H}^{\leftarrow}(S\; | \; \ell, T)
$$
\end{enumerate}

\end{proof}
\begin{theorem}
If $DS$ is unambiguous, then $\EntropyOf{\DNFRegex}$ is the entropy of $P_{\DNFRegex}$.
\end{theorem}
\begin{proof}
By mutual induction over $DS$, $SQ$ and $A$ (the computations of the entropies follow the same pattern as the respective computations in \cref{CorrectEntropy}).
\begin{enumerate}
\item
($A = DS^{*p}$)

By the induction hypothesis $H(DS) = \mathbb{H}(DS)$, from which it follows that
$$H(DS^{*p}) = \frac{p}{1-p}(H(DS) - \log_2 p) - \log_2 (1-p) = \mathbb{H}(DS^{*p})$$
\item
($SQ = [s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]$)

By the induction hypothesis, hence by unambiguity $H(A_i) = \mathbb{H}(A_i)$, thus
$$H([s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n]) = \sum_{i=1}^n H(A_i) = \sum_{i=1}^n \mathbb{H}(A_i) = \mathbb{H}([s_0 \cdot A_1 \cdot \ldots \cdot A_n \cdot s_n])$$
\item
$(DS = \langle (SQ_1, p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle)$

By the induction hypothesis, $H(SQ_i, p_i) = \mathbb{H}(SQ_i, p_i)$. Using the formula
$$H(P) = H(m(P_1), \ldots m(P_n)) + \sum_{i=1}^n m(P_i)H(P_i)$$
if $P$ is a measure space satisfying $P = P_1 + \ldots + P_n$, then
\begin{align*}
H(\langle (SQ_1, p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle)
&= H(p_1, \ldots, p_n) + \sum_{i=1}^n p_i H(SQ_i, p_i)\\
&= \sum_{i=1}^n p_i \mathbb{H}(SQ_i, p_i) + p_i * \log_2 p_i\\
&= \mathbb{H}(\langle (SQ_1, p_1) \; | \; \ldots \; | \; (SQ_n, p_n)\rangle)
\end{align*}
\end{enumerate}
\end{proof}



\fi
\end{document}


% old intro
%\bcp{Not very compelling:}Similar data can come in varieties of formats: scheduled jobs can be stored as
%cron jobs for Linux or as Scheduled Tasks for Windows; web service
%resources can be provided to clients in legacy or modern formats;
%calendar events can be stored in CSV files or ICS files. Oftentimes,
%files should be synchronized across these formats: when I edit a task
%to run more often on my Linux machine, I want this task to run more
%often on my Windows machine; when I update data through a legacy API,
%I want those changes to be reflected when I retrieve it through a
%modern API; when I create a new calendar event in my ICS file, I want
%my CSV calendar files to be updated to reflect this change.
%
%Unfortunately, writing such synchronizers is quite difficult; we must write
%parsers both formats, specify how the parsed data is converted into the other
%format, and specify how to propagate updates from one format to the other.
%Bidirectional languages ease the difficulty of writing such synchronizers,
%because a single, well-typed program expresses a \emph{lens}---a group of
%conversion functions guaranteed to satisfy round-tripping laws. However,
%bidirectional languages are themselves difficult to program in, often requiring
%users to permute data in fiddly ways while satisfying the type system's complex
%unambiguity constraints.
%
%A better approach is to \emph{synthesize} such conversion functions. However,
%prior work on synthesizing lenses assumes a bijection between the source and
%target, which is a severe limitation in practice. Oftentimes, fields present in
%one format are not present in the other: the commands scheduled to run on Linux
%machines are typically different than the commands scheduled to run on Windows
%machines; updated APIs can expose new information, or omit legacy information;
%ICS files contain a URL field that Google Calendar CSV files do not expose.
%
%\emph{Symmetric lenses}~\cite{symmetric-lenses} formalize this richer class of
%non-bijective conversion functions by using additional state, called the
%\emph{complement}, to help with synchronization. While increasing
%expressiveness, the existence of the complement makes symmetric lenses difficult
%to use in real-world synchronization tasks, because lens programs must maintain
%the synchronized files as well as the complements. The complement further
%complicates synthesis, because input-output examples no longer suffice; instead
%edit sequences must be provided.
%
%In this paper, we contrain symmetric lenses to \emph{simple symmetric lenses}.
%These constrained lenses do not use a complement, and only use the files that we
%aim to synchronize as state. We identify a property, \emph{forgetfulness}, that
%identifies the subset of symmetric lenses that can be written as simple
%symmetric lenses. We provide combinators for building simple symmetric lenses on
%string data, and integrate these combinators with Boomerang, a language for
%bidirectional programming on strings. Both Boomerang and our extension type lens
%terms between pairs of regular expressions. The typing judgment $\Lens : \Regex
%\Leftrightarrow \RegexAlt$ means the lens term $\Lens$ encodes synchronizing
%functions between the format described by $\Regex$ and the format described by
%$\RegexAlt$.
%
%We provide a tool for synthesizing simple symmetric lenses when given a suite of
%input-output examples and a pair of regular expressions describing the data
%formats. The synthesis algorithm uses type-directed synthesis
%on the two regular expressions to synthesize a lens that is well-typed between
%the provided regular expressions and satisfies the provided input-output
%examples.
%
%\saz{This paragraph is hard to follow --- maybe introduce $\ell : S
%  \Leftrightarrow T$ and use the names $S$ and $T$?}\bcp{The names make it a
%bit better, but it is all still rather abstract.  Indeed, the whole intro is
%quite abstract---could it not be driven by an example?} A primary difficulty is
%that there are a relatively many well-typed simple symmetric lenses. If we are
%trying to find a lens between $\Regex$ and $\RegexAlt$, there is now a choice:
%do $\Regex$ and $\RegexAlt$ represent the same data, and should be aligned
%(changes to data in the language of $\Regex$ are propagated to synchronized
%strings in the language of $\RegexAlt$), or should it be left unaligned (changes
%to data in $\Regex$ update synchronized strings in $\RegexAlt$). Or instead
%should certain components of $\Regex$ be aligned with certain components of
%$\RegexAlt$, with the other components left unaligned.
%
%Operating under the assumption that users wish to align as much data as
%possible, our algorithm tries to align as much data as the types and examples
%allow. This task gets harder when there are more complex decisions involved. For
%example, if there are two fields in one format, and one in the other, which field
%in the first format should be aligned to the sole field of the second format? Or
%would it be better for the field on the right to be aligneded to a mish-mash
%of subcomponents from each field?\bcp{Wouldn't these questions be answered
%  by examples?} To answer these questions, we develop a cost
%metric for reasoning about which lens aligns the most information.
%
%In particular, the \emph{cost} of a lens is the expected number of bits required to
%recover a string in one format when a synchronized string in the other format is
%provided. In this model, bijective lenses have zero cost, and as more
%information is left unsychronized, the cost is increased.
%
%Our model is based on \emph{stochastic regular expressions}~\cite{?}, which
%represent both a language and a probability distribution over that language
%simultaneously.  We develop a way to syntactically infer the expected
%information content (or \emph{entropy}) of an unambiguous regular
%expression. This entropy is used to calculate the expected information content
%to recover a string, when given a string it is synchronized with.\bcp{I
%know we're going to get to more technical detail later, but at this point I
%am confused: a string matching a RE can in general be arbitrarily long, so
%what kind of sense does it make to talk about its ``expected'' information content?}
%
%\begin{figure}
%  \includegraphics[width=.5\textwidth]{high-level-algorithm.pdf}
%  \caption{Schematic Diagram for \SOptician. Regular expressions \Regex and
%    \RegexAlt, and a set of examples \Examples, are provided as input. \RXSearch
%    searches through stochastic regular expression pairs, equivalent to the
%    originals, and proposes them to \GreedySynth. \GreedySynth finds a lens,
%    typed between the generated equivalent pairs. When \RXSearch determines it
%    has an optimal lens, it returns that lens.}
%  \label{fig:high-level-algorithm}
%\end{figure}
%
%\bcp{It gets rather technical and incomprehensible for the next three
%  paragraphs...} 
%
%We develop an algorithm that synthesizes a low-cost lens, shown in
%Figure~\ref{fig:high-level-algorithm}. This algorithm consists of two
%communicating synthesizers, one that proposes candidate stochastic regular
%expression pairs that it thinks will align well, and one that greedily searches
%for a lens between those two regular expressions that minimizes cost and does
%not traverse star-related equivalences\bcp{???}. When the first algorithm is content with
%the lens it has found, it returns that lens. 
%
%\bcp{Make clear that these algorithms are based on earlier / published ones.}Our first algorithm, \RXSearch, proposes candidate stochastic regular
%expressions. These candidate stochastic regular expressions are generated by
%traversing \emph{star semiring} equivalences on stochastic regular expressions.
%These proposed stochastic regular expression pairs have equivalent languages and
%probability distributions as the original ones: we prove that the star-semiring
%rewrites this synthesizer applies are sound rewrites on stochastic regular
%expressions.
%
%Our second algorithm, \GreedySynth, utilizes alternative languages for
%stochastic regular expressions and lenses, \emph{stochastic DNF regular
%  expressions} and \emph{symmetric DNF lenses}. While these languages are hard
%to read and understand, they are highly normalized and permit an efficient
%type-directed synthesis algorithm. We develop our cost metric on DNF lenses, and
%provide a greedy algorithm that tries to find a symmetric DNF lens of minimal
%cost. The synthesized symmetric DNF lens is then converted to a lens in the
%original simple symmetric lens language.
%
%
%We evaluate our algorithm on a benchmark suite consisting of synchronizing file
%formats from configuration files, application-specific data storage files, and
%data cleaning tasks. We find that our algorithm is able to synthesize each of
%these lenses in under 20 seconds.
%
%In summary, our contributions are:
%\begin{enumerate}
%\item We develop \emph{simple symmetric lenses} a new formulation for
%  bidirectional programs that can project data from both sides~(\S\ref{sec:overview}),
%  and describe a language that expresses such lenses on string
%  data~(\S\ref{sec:ssl}).  \bcp{A new language, or a variant of
%    Hofmann/Pierce/Wagner?} 
%\item We develop a means to traverse stochastic regular expression equivalences,
%  while preserving probability distributions and
%  languages~(\S\ref{subsec:stoch-rx}).
%\item We develop stochastic DNF regular expressions and DNF
%  lenses~(\S\ref{subsec:greedy-synth}). We develop a sound algorithm for
%  converting stochastic regular expressions to stochastic DNF regular
%  expressions and a information-theoretic cost metric on DNF lenses.
%\item We extended Boomerang with our simple symmetric lens combinators, and
%  integrated our algorithm with the Optician synthesis system within Boomerang,
%  allowing synthesis tasks as Boomerang
%  expressions~(\S\ref{sec:implementation}).
%\item We evaluate our algorithm on a benchmark suite consisting of synchronizing
%  file formats from configuration files, application-specific data storage
%  files, and data cleaning tasks (\S\ref{sec:evaluation}).  \bcp{... and
%    conclude what?}
%  \end{enumerate}

%%% Local Variables:
%%% TeX-master: "main"
%%% End:
